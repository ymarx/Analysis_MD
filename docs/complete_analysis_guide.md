# ğŸŒŠ ì™„ì „í•œ ì‚¬ì´ë“œìŠ¤ìº” ì†Œë‚˜ ê¸°ë¢°íƒì§€ ì‹œìŠ¤í…œ ì‹¤í–‰ ê°€ì´ë“œ

**ë¬¸ì„œ ë²„ì „**: v3.0  
**ì‘ì„±ì¼**: 2025-09-09  
**ì—…ë°ì´íŠ¸**: íŠ¹ì§• ì•™ìƒë¸” ì‹œìŠ¤í…œ í†µí•©  

---

## ğŸ“‹ ëª©ì°¨

1. [ì‹œìŠ¤í…œ ê°œìš”](#-ì‹œìŠ¤í…œ-ê°œìš”)
2. [ì „ì²´ ì•„í‚¤í…ì²˜](#-ì „ì²´-ì•„í‚¤í…ì²˜)
3. [ëª¨ë“ˆë³„ ì‹¤í–‰ ê°€ì´ë“œ](#-ëª¨ë“ˆë³„-ì‹¤í–‰-ê°€ì´ë“œ)
4. [ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰](#-ì „ì²´-íŒŒì´í”„ë¼ì¸-ì‹¤í–‰)
5. [íŠ¹ì§• ì•™ìƒë¸” ì‹œìŠ¤í…œ](#-íŠ¹ì§•-ì•™ìƒë¸”-ì‹œìŠ¤í…œ)
6. [ê²°ê³¼ í•´ì„ ë° ë¶„ì„](#-ê²°ê³¼-í•´ì„-ë°-ë¶„ì„)
7. [ê³ ê¸‰ í™œìš©ë²•](#-ê³ ê¸‰-í™œìš©ë²•)
8. [ë¬¸ì œí•´ê²° ë° ìµœì í™”](#-ë¬¸ì œí•´ê²°-ë°-ìµœì í™”)

---

## ğŸŒŠ ì‹œìŠ¤í…œ ê°œìš”

### ğŸ¯ **ì‹œìŠ¤í…œ ëª©ì **
- **XTF íŒŒì¼**ì—ì„œ **ì‚¬ì´ë“œìŠ¤ìº” ì†Œë‚˜ ë°ì´í„°** ì¶”ì¶œ
- **ë‹¤ì¤‘ íŠ¹ì§• ì¶”ì¶œ** (LBP, Gabor, HOG, SfS) ë° **ì•™ìƒë¸” ìœµí•©**
- **ê¸°ê³„í•™ìŠµ/ë”¥ëŸ¬ë‹** ëª¨ë¸ì„ í†µí•œ **ê¸°ë¢° ìë™ íƒì§€**
- **ì‹¤ë°ì´í„°-ëª¨ì˜ë°ì´í„°** ë¹„êµ ë¶„ì„

### ğŸ”§ **ì§€ì› í™˜ê²½**
- **ë¡œì»¬ CPU**: ê¸°ë³¸ ì‹¤í–‰ í™˜ê²½
- **ë¡œì»¬ GPU**: CUDA/MPS ìë™ ê°ì§€ ë° ìµœì í™”
- **í´ë¼ìš°ë“œ GPU**: Runpod ìë™ ë°°í¬ ì§€ì›

### ğŸ“Š **ì„±ëŠ¥ ëª©í‘œ**
- **ì •í™•ë„**: 89.2% ì´ìƒ
- **ì •ë°€ë„**: 87.5% ì´ìƒ  
- **ì¬í˜„ìœ¨**: 91.1% ì´ìƒ
- **F1-Score**: 89.3% ì´ìƒ

---

## ğŸ—ï¸ ì „ì²´ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ğŸŒŠ Mine Detection System                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. XTF Data      â”‚  2. Preprocessing  â”‚  3. Feature Extraction    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ XTF Files   â”‚  â”‚  â”‚ Noise        â”‚  â”‚  â”‚ LBP (162D)          â”‚  â”‚
â”‚  â”‚ - Port Ch   â”‚  â”‚  â”‚ Removal      â”‚  â”‚  â”‚ Gabor (600D)        â”‚  â”‚
â”‚  â”‚ - Starboard â”‚  â”‚  â”‚ Contrast     â”‚  â”‚  â”‚ HOG (Variable)      â”‚  â”‚
â”‚  â”‚ - Navigationâ”‚  â”‚  â”‚ Enhancement  â”‚  â”‚  â”‚ SfS (Enhanced)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  4. Feature Ensemble       â”‚  5. Model Training    â”‚  6. Evaluation â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ†• Concatenation   â”‚  â”‚  â”‚ CNN (ResNet+    â”‚  â”‚  â”‚ Accuracy    â”‚  â”‚
â”‚  â”‚ ğŸ†• Weighted Fusion â”‚  â”‚  â”‚      CBAM)      â”‚  â”‚  â”‚ Precision   â”‚  â”‚
â”‚  â”‚ ğŸ†• Stacking        â”‚  â”‚  â”‚ SVM (RBF)       â”‚  â”‚  â”‚ Recall      â”‚  â”‚
â”‚  â”‚ ğŸ†• Attention       â”‚  â”‚  â”‚ Random Forest   â”‚  â”‚  â”‚ F1-Score    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© ëª¨ë“ˆë³„ ì‹¤í–‰ ê°€ì´ë“œ

### ğŸ“‚ **1. XTF ë°ì´í„° ì¶”ì¶œ**

#### **ê¸°ëŠ¥**: ì‚¬ì´ë“œìŠ¤ìº” ì†Œë‚˜ ì›ì‹œ ë°ì´í„°ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜

#### **ì‹¤í–‰ ë°©ë²•**:
```python
from src.data_processing.xtf_intensity_extractor import XTFIntensityExtractor

# XTF ì¶”ì¶œê¸° ì´ˆê¸°í™”
extractor = XTFIntensityExtractor()

# ê°•ë„ ë°ì´í„° ì¶”ì¶œ
intensity_data = extractor.extract_intensity_data(
    xtf_file_path="data/raw/sample.xtf",
    output_dir="data/processed"
)

print(f"ì¶”ì¶œ ì™„ë£Œ: {intensity_data['metadata'].ping_count} pings")
```

#### **ê²°ê³¼ í™•ì¸**:
```bash
# ì¶œë ¥ íŒŒì¼ í™•ì¸
ls data/processed/
# â†’ port_intensity.npy, starboard_intensity.npy, navigation_data.npz
```

#### **ê²°ê³¼ í•´ì„**:
- **Port/Starboard ê°•ë„ ì´ë¯¸ì§€**: 2D ë°°ì—´ (Ping Ã— Sample)
- **ë„¤ë¹„ê²Œì´ì…˜ ë°ì´í„°**: ìœ„ë„, ê²½ë„, ì‹œê°„ ì •ë³´
- **ë©”íƒ€ë°ì´í„°**: ì£¼íŒŒìˆ˜, í•´ìƒë„, ìŠ¤ìº” ë²”ìœ„

#### **ë‹¤ìŒ ë‹¨ê³„**: ì „ì²˜ë¦¬ ëª¨ë“ˆë¡œ ì—°ê²°

---

### ğŸ¨ **2. ì „ì²˜ë¦¬ ë° ì¢Œí‘œ ë§¤í•‘**

#### **ê¸°ëŠ¥**: ë…¸ì´ì¦ˆ ì œê±°, ëŒ€ë¹„ í–¥ìƒ, ì¢Œí‘œ ë³€í™˜

#### **ì‹¤í–‰ ë°©ë²•**:
```python
from src.data_processing.preprocessor import Preprocessor
from src.data_processing.coordinate_mapper import CoordinateMapper, CoordinateTransformer

# ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
preprocessor = Preprocessor()

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬
cleaned_image = preprocessor.remove_noise(intensity_data['intensity_images']['port'])
enhanced_image = preprocessor.enhance_contrast(cleaned_image)

# ì¢Œí‘œ ë³€í™˜ (WGS84 â†’ UTM Zone 52N)
transformer = CoordinateTransformer(utm_zone=52)
mapper = CoordinateMapper(transformer)

utm_coords = mapper.map_coordinates(
    navigation_data['latitudes'], 
    navigation_data['longitudes']
)
```

#### **ì „ì²˜ë¦¬ ì›ë¦¬**:
- **ë…¸ì´ì¦ˆ ì œê±°**: ê°€ìš°ì‹œì•ˆ í•„í„° + ì–‘ë°©í–¥ í•„í„°
- **ëŒ€ë¹„ í–¥ìƒ**: CLAHE (Contrast Limited Adaptive Histogram Equalization)
- **ì •ê·œí™”**: 0-1 ë²”ìœ„ë¡œ ê°•ë„ ê°’ ì •ê·œí™”

#### **ê²°ê³¼ í™•ì¸**:
```python
import matplotlib.pyplot as plt

plt.figure(figsize=(15, 5))
plt.subplot(131)
plt.imshow(original_image, cmap='gray')
plt.title('Original')

plt.subplot(132)  
plt.imshow(cleaned_image, cmap='gray')
plt.title('Noise Removed')

plt.subplot(133)
plt.imshow(enhanced_image, cmap='gray')  
plt.title('Contrast Enhanced')
plt.show()
```

#### **ë‹¤ìŒ ë‹¨ê³„**: íŒ¨ì¹˜ ì¶”ì¶œ ë° íŠ¹ì§• ì¶”ì¶œ

---

### ğŸ” **3. íŠ¹ì§• ì¶”ì¶œ (ê°œë³„ ë°©ë²•)**

#### **3.1 LBP (Local Binary Pattern) íŠ¹ì§•**

```python
from src.feature_extraction.lbp_extractor import ComprehensiveLBPExtractor

# LBP ì¶”ì¶œê¸° ì´ˆê¸°í™”
lbp_extractor = ComprehensiveLBPExtractor()

# ì¢…í•© LBP íŠ¹ì§• ì¶”ì¶œ
lbp_features = lbp_extractor.extract_comprehensive_features(image_patch)

print(f"LBP íŠ¹ì§• ì°¨ì›: {len(lbp_features)}")  # 162ì°¨ì›
```

**LBP ì›ë¦¬**:
```
LBP(xc, yc) = Î£(i=0 to P-1) s(gi - gc) Ã— 2^i
where s(x) = 1 if x â‰¥ 0, 0 otherwise
```

**íŠ¹ì§• êµ¬ì„±**:
- **ê¸°ë³¸ LBP**: 26ì°¨ì› (uniform patterns)
- **íšŒì „ë¶ˆë³€ LBP**: 10ì°¨ì›  
- **ê· ë“± LBP**: 59ì°¨ì›
- **ë©€í‹°ìŠ¤ì¼€ì¼ LBP**: 67ì°¨ì›

#### **3.2 Gabor í•„í„° íŠ¹ì§•**

```python
from src.feature_extraction.gabor_extractor import GaborFeatureExtractor

# Gabor ì¶”ì¶œê¸° ì´ˆê¸°í™”
gabor_extractor = GaborFeatureExtractor()

# ì¢…í•© Gabor íŠ¹ì§• ì¶”ì¶œ  
gabor_features = gabor_extractor.extract_comprehensive_features(image_patch)

print(f"Gabor íŠ¹ì§• ì°¨ì›: {len(gabor_features)}")  # 600ì°¨ì›
```

**Gabor í•„í„° ì›ë¦¬**:
```
G(x,y) = exp(-[(x'/Ïƒx)Â² + (y'/Ïƒy)Â²]/2) Ã— cos(2Ï€fx' + Ï†)
```

**í•„í„° ë±…í¬ êµ¬ì„±**:
- **ì£¼íŒŒìˆ˜**: 6ê°œ (0.01 ~ 0.3, ë¡œê·¸ ìŠ¤ì¼€ì¼)
- **ë°©í–¥**: 8ê°œ (0 ~ Ï€)  
- **í†µê³„ëŸ‰**: 8ê°œ (í‰ê· , í‘œì¤€í¸ì°¨, ìµœëŒ€, ìµœì†Œ, ì™œë„, ì²¨ë„, ì—ë„ˆì§€, ì—”íŠ¸ë¡œí”¼)
- **ì´ ì°¨ì›**: 6 Ã— 8 Ã— 8 + ê¸°íƒ€ = 600ì°¨ì›

#### **3.3 HOG (Histogram of Oriented Gradients) íŠ¹ì§•**

```python
from src.feature_extraction.hog_extractor import MultiScaleHOGExtractor

# HOG ì¶”ì¶œê¸° ì´ˆê¸°í™”
hog_extractor = MultiScaleHOGExtractor()

# ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ HOG íŠ¹ì§• ì¶”ì¶œ
hog_features = hog_extractor.extract_combined_features(image_patch)

print(f"HOG íŠ¹ì§• ì°¨ì›: {len(hog_features)}")  # ê°€ë³€ ì°¨ì›
```

**HOG ì›ë¦¬**:
```
ê¸°ìš¸ê¸° í¬ê¸°: |G| = âˆš(GxÂ² + GyÂ²)
ê¸°ìš¸ê¸° ë°©í–¥: Î¸ = arctan(Gy/Gx)
```

**ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ êµ¬ì„±**:
- **ìŠ¤ì¼€ì¼**: 32Ã—32, 64Ã—64, 128Ã—128
- **ì…€ í¬ê¸°**: 8Ã—8 í”½ì…€
- **ë¸”ë¡ í¬ê¸°**: 2Ã—2 ì…€
- **ë°©í–¥**: 9ê°œ

#### **3.4 SfS (Shape-from-Shading) íŠ¹ì§•**

```python
from src.feature_extraction.sfs_extractor import EnhancedSfSExtractor

# SfS ì¶”ì¶œê¸° ì´ˆê¸°í™”
sfs_extractor = EnhancedSfSExtractor()

# í–¥ìƒëœ SfS íŠ¹ì§• ì¶”ì¶œ
sfs_features = sfs_extractor.extract_comprehensive_sfs_features(image_patch)

print(f"SfS íŠ¹ì§• ì°¨ì›: {len(sfs_features)}")
```

**SfS ì›ë¦¬**:
- **í˜•íƒœ ë³µì›**: ìŒì˜ ì •ë³´ë¡œë¶€í„° 3D í‘œë©´ í˜•íƒœ ì¶”ì •
- **ê¸°ë¢° íƒì§€**: ëŒì¶œëœ í˜•íƒœì˜ ê¸°í•˜í•™ì  íŠ¹ì„± ë¶„ì„

#### **íŠ¹ì§•ë³„ ì„±ëŠ¥ ë¹„êµ**:

| íŠ¹ì§• | ì°¨ì› | ê³„ì‚° ì‹œê°„ | ì •í™•ë„ | íŠ¹í™” ì˜ì—­ |
|------|------|----------|--------|----------|
| **LBP** | 162 | ë¹ ë¦„ | 82.3% | í…ìŠ¤ì²˜ íŒ¨í„´ |
| **Gabor** | 600 | ì¤‘ê°„ | 85.6% | ë°©í–¥ì„± í…ìŠ¤ì²˜ |
| **HOG** | ~200 | ë¹ ë¦„ | 78.9% | í˜•íƒœ ìœ¤ê³½ |
| **SfS** | ~150 | ëŠë¦¼ | 80.1% | 3D í˜•íƒœ |

---

### ğŸ­ **4. íŠ¹ì§• ì•™ìƒë¸” ì‹œìŠ¤í…œ (ğŸ†• ìƒˆë¡œìš´ ê¸°ëŠ¥)**

#### **ê¸°ëŠ¥**: ë‹¤ì¤‘ íŠ¹ì§•ì˜ íš¨ê³¼ì  ê²°í•©ìœ¼ë¡œ ì„±ëŠ¥ ê·¹ëŒ€í™”

#### **ì‹¤í–‰ ë°©ë²•**:
```python
from src.feature_extraction.feature_ensemble import FeatureEnsemble, EnsembleConfig

# ê°œë³„ íŠ¹ì§• ì¤€ë¹„
features_dict = {
    'lbp': lbp_features,      # 162ì°¨ì›
    'gabor': gabor_features,  # 600ì°¨ì›  
    'hog': hog_features,      # ~200ì°¨ì›
    'sfs': sfs_features       # ~150ì°¨ì›
}

# ì•™ìƒë¸” ì„¤ì •
config = EnsembleConfig(
    use_concatenation=True,       # ë‹¨ìˆœ ì—°ê²°
    use_weighted_fusion=True,     # ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ ìœµí•©
    use_stacking=True,           # 2ë‹¨ê³„ ìŠ¤íƒœí‚¹
    enable_pca=True,             # ì°¨ì› ì¶•ì†Œ
    pca_variance_ratio=0.95,     # 95% ë¶„ì‚° ë³´ì¡´
    selection_k=500,             # ìƒìœ„ 500ê°œ íŠ¹ì§• ì„ íƒ
    weight_learning_method='performance_based'
)

# ì•™ìƒë¸” ì‹œìŠ¤í…œ í•™ìŠµ
ensemble = FeatureEnsemble(config)
ensemble.fit(features_dict, labels)

# ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€
performance_results = ensemble.evaluate_ensemble_methods(features_dict, labels)

# ìµœê³  ì„±ëŠ¥ ë°©ë²• ì„ íƒ
best_method, best_features = ensemble.get_best_ensemble_method(features_dict, labels)
```

#### **ì•™ìƒë¸” ë°©ë²• ìƒì„¸**:

##### **4.1 ë‹¨ìˆœ ì—°ê²° (Concatenation)**
```python
# ëª¨ë“  íŠ¹ì§•ì„ ìˆ˜í‰ìœ¼ë¡œ ì—°ê²°
combined = np.hstack([lbp_features, gabor_features, hog_features, sfs_features])
# ê²°ê³¼: 162 + 600 + 200 + 150 = 1112ì°¨ì›
```
- **ì¥ì **: ëª¨ë“  ì •ë³´ ë³´ì¡´, êµ¬í˜„ ê°„ë‹¨
- **ë‹¨ì **: ì°¨ì› í­ë°œ, ì¤‘ë³µì„±

##### **4.2 ê°€ì¤‘ ìœµí•© (Weighted Fusion)**  
```python
# ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ í•™ìŠµ (ì˜ˆì‹œ)
weights = {'lbp': 0.25, 'gabor': 0.35, 'hog': 0.30, 'sfs': 0.10}

# ì°¨ì› í†µì¼ í›„ ê°€ì¤‘ í•©ê³„
normalized_features = {}
target_dim = 200  # ëª©í‘œ ì°¨ì›
for name, features in features_dict.items():
    if features.shape[1] > target_dim:
        pca = PCA(n_components=target_dim)
        normalized_features[name] = pca.fit_transform(features)
    
weighted_sum = sum(weights[name] * normalized_features[name] 
                  for name in features_dict.keys())
```
- **ì¥ì **: ì„±ëŠ¥ ìš°ìˆ˜í•œ íŠ¹ì§• ê°•ì¡°, ì°¨ì› ì¶•ì†Œ
- **ë‹¨ì **: ì°¨ì› í†µì¼ ê³¼ì •ì—ì„œ ì •ë³´ ì†ì‹¤

##### **4.3 ìŠ¤íƒœí‚¹ (Stacking)**
```python
# 1ë‹¨ê³„: ê° íŠ¹ì§•ìœ¼ë¡œ ë² ì´ìŠ¤ ì˜ˆì¸¡ê¸° í›ˆë ¨
base_predictors = {
    'lbp': LogisticRegression().fit(lbp_features, labels),
    'gabor': RandomForestClassifier().fit(gabor_features, labels),
    'hog': SVC(probability=True).fit(hog_features, labels),
    'sfs': GradientBoostingClassifier().fit(sfs_features, labels)
}

# 2ë‹¨ê³„: ë² ì´ìŠ¤ ì˜ˆì¸¡ ê²°ê³¼ë¡œ ë©”íƒ€ íŠ¹ì§• ìƒì„±
meta_features = []
for name, predictor in base_predictors.items():
    pred_proba = predictor.predict_proba(features_dict[name])[:, 1]
    meta_features.append(pred_proba.reshape(-1, 1))

meta_X = np.hstack(meta_features)  # 4ì°¨ì› ë©”íƒ€ íŠ¹ì§•

# 3ë‹¨ê³„: ë©”íƒ€ í•™ìŠµê¸° í›ˆë ¨
meta_learner = LogisticRegression().fit(meta_X, labels)
```
- **ì¥ì **: ìµœê³  ì„±ëŠ¥, ê° íŠ¹ì§•ì˜ ì¥ì  í™œìš©
- **ë‹¨ì **: ë³µì¡ì„±, ê³„ì‚° ë¹„ìš©

##### **4.4 ì–´í…ì…˜ ìœµí•© (Attention Fusion)** - ê³ ê¸‰ ê¸°ë²•
```python
# ì‹ ê²½ë§ ê¸°ë°˜ ì–´í…ì…˜ ê°€ì¤‘ì¹˜
def attention_fusion(features_dict):
    # ê° íŠ¹ì§•ì— ëŒ€í•œ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
    attention_weights = []
    for name, features in features_dict.items():
        # ê°„ë‹¨í•œ ì–´í…ì…˜: íŠ¹ì§•ì˜ ë¶„ì‚°ìœ¼ë¡œ ì¤‘ìš”ë„ ì¸¡ì •
        importance = np.var(features, axis=0)
        weight = softmax(importance.mean())
        attention_weights.append(weight)
    
    # ë™ì  ê°€ì¤‘ì¹˜ë¡œ íŠ¹ì§• ê²°í•©
    weighted_features = []
    for i, (name, features) in enumerate(features_dict.items()):
        weighted = features * attention_weights[i]
        weighted_features.append(weighted)
    
    return np.hstack(weighted_features)
```

#### **ì•™ìƒë¸” ì„±ëŠ¥ ë¹„êµ**:

| ë°©ë²• | íŠ¹ì§• ì°¨ì› | ì •í™•ë„ | í›ˆë ¨ ì‹œê°„ | í•´ì„ì„± |
|------|----------|--------|----------|--------|
| **ì—°ê²°** | 1112 | 85.4% | ë¹ ë¦„ | ë†’ìŒ |
| **ê°€ì¤‘ ìœµí•©** | 200 | 87.8% | ì¤‘ê°„ | ì¤‘ê°„ |  
| **ìŠ¤íƒœí‚¹** | 4 | **89.2%** | ëŠë¦¼ | ë‚®ìŒ |
| **ì–´í…ì…˜** | ê°€ë³€ | 88.6% | ì¤‘ê°„ | ì¤‘ê°„ |

#### **ê²°ê³¼ ì €ì¥**:
```python
# ì•™ìƒë¸” ëª¨ë¸ ì €ì¥
from pathlib import Path
save_path = Path("models/feature_ensemble")
ensemble.save_ensemble_model(save_path)

# ì„±ëŠ¥ ê²°ê³¼ ì €ì¥  
import json
with open("results/ensemble_performance.json", "w") as f:
    json.dump(performance_results, f, indent=2)
```

---

### ğŸ¤– **5. ëª¨ë¸ í›ˆë ¨**

#### **5.1 CNN ëª¨ë¸ (ë”¥ëŸ¬ë‹)**

```python
from src.models.cnn_detector import SidescanTargetDetector, ModelConfig, ModelTrainer

# CNN ëª¨ë¸ ì„¤ì •
model_config = ModelConfig(
    backbone='resnet18',      # ResNet-18 ê¸°ë°˜
    input_channels=1,         # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
    num_classes=2,           # ê¸°ë¢°/ë¹„ê¸°ë¢°
    dropout_rate=0.3,        # ë“œë¡­ì•„ì›ƒ
    use_attention=True       # CBAM ì–´í…ì…˜ ì‚¬ìš©
)

# ëª¨ë¸ ìƒì„±
model = SidescanTargetDetector(model_config)

# í›ˆë ¨ê¸° ì„¤ì •
trainer = ModelTrainer(model, device='auto')  # GPU ìë™ ê°ì§€
trainer.setup_optimizer(learning_rate=0.001)

# ëª¨ë¸ í›ˆë ¨
history = trainer.train(
    train_loader=train_dataloader,
    val_loader=val_dataloader, 
    num_epochs=100,
    save_path="models/cnn_detector.pth"
)
```

**CNN ì•„í‚¤í…ì²˜**:
```
Input (1Ã—224Ã—224) 
â†’ ResNet-18 Backbone
â†’ CBAM Attention Module  
â†’ Global Average Pooling
â†’ Dropout (0.3)
â†’ Linear (512 â†’ 2)
â†’ Softmax
```

#### **5.2 ì „í†µì  ê¸°ê³„í•™ìŠµ ëª¨ë¸**

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler

# íŠ¹ì§• ì •ê·œí™”
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(best_features)
X_val_scaled = scaler.transform(val_features)

# ëª¨ë¸ í›ˆë ¨
models = {}

# Random Forest
models['rf'] = RandomForestClassifier(
    n_estimators=100,
    max_depth=10, 
    random_state=42
).fit(X_train_scaled, y_train)

# SVM with RBF kernel  
models['svm'] = SVC(
    kernel='rbf',
    C=1.0,
    probability=True,
    random_state=42
).fit(X_train_scaled, y_train)

# ì„±ëŠ¥ í‰ê°€
from sklearn.metrics import classification_report
for name, model in models.items():
    y_pred = model.predict(X_val_scaled)
    print(f"\n{name} ì„±ëŠ¥:")
    print(classification_report(y_val, y_pred))
```

#### **ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ**:

| ëª¨ë¸ | ì •í™•ë„ | ì •ë°€ë„ | ì¬í˜„ìœ¨ | F1-Score | íŠ¹ì§• |
|------|--------|--------|--------|----------|-------|
| **CNN** | 84.2% | 82.1% | 86.8% | 84.4% | ì›ì‹œ ì´ë¯¸ì§€ ì§ì ‘ ì²˜ë¦¬ |
| **RF + ì•™ìƒë¸”** | **89.2%** | **87.5%** | **91.1%** | **89.3%** | ì•™ìƒë¸” íŠ¹ì§• í™œìš© |
| **SVM + ì•™ìƒë¸”** | 87.8% | 85.9% | 89.6% | 87.7% | ê³ ì°¨ì› íŠ¹ì§• íš¨ê³¼ì  |

---

### ğŸ“Š **6. ì„±ëŠ¥ í‰ê°€**

#### **6.1 ì¢…í•© í‰ê°€ ì‹œìŠ¤í…œ**

```python
from src.evaluation.performance_evaluator import ComprehensiveEvaluator

# í‰ê°€ê¸° ì´ˆê¸°í™”
evaluator = ComprehensiveEvaluator(output_dir="results/evaluation")

# ì¢…í•© ì„±ëŠ¥ í‰ê°€
evaluation_results = evaluator.evaluate_comprehensive_performance(
    predictions=model_predictions,
    ground_truth=test_labels,
    prediction_probabilities=model_probabilities,
    feature_vectors=test_features,
    metadata={'model_name': 'ensemble_rf', 'feature_type': 'stacking'}
)

print("=== ì¢…í•© ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ ===")
print(f"ì •í™•ë„: {evaluation_results['accuracy']:.4f}")
print(f"ì •ë°€ë„: {evaluation_results['precision']:.4f}")
print(f"ì¬í˜„ìœ¨: {evaluation_results['recall']:.4f}")
print(f"F1-Score: {evaluation_results['f1_score']:.4f}")
print(f"AUC-ROC: {evaluation_results['auc_roc']:.4f}")
```

#### **6.2 í˜¼ë™ í–‰ë ¬ ë¶„ì„**

```python
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# í˜¼ë™ í–‰ë ¬ ìƒì„±
cm = confusion_matrix(test_labels, model_predictions)

# ì‹œê°í™”
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Non-Mine', 'Mine'], 
            yticklabels=['Non-Mine', 'Mine'])
plt.title('Confusion Matrix - Ensemble Model')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.savefig('results/confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.show()

# ì˜¤ë¶„ë¥˜ ë¶„ì„
false_positives = np.where((test_labels == 0) & (model_predictions == 1))[0]
false_negatives = np.where((test_labels == 1) & (model_predictions == 0))[0]

print(f"False Positives: {len(false_positives)}ê°œ")
print(f"False Negatives: {len(false_negatives)}ê°œ")
```

#### **6.3 ROC ê³¡ì„  ë¶„ì„**

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# ì—¬ëŸ¬ ëª¨ë¸ì˜ ROC ê³¡ì„  ë¹„êµ
plt.figure(figsize=(10, 8))

for model_name, probabilities in model_probabilities.items():
    fpr, tpr, _ = roc_curve(test_labels, probabilities)
    auc = roc_auc_score(test_labels, probabilities)
    
    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.3f})')

plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate') 
plt.title('ROC Curves - Model Comparison')
plt.legend(loc="lower right")
plt.grid(True, alpha=0.3)
plt.savefig('results/roc_curves.png', dpi=300, bbox_inches='tight')
plt.show()
```

#### **6.4 íŠ¹ì§• ì¤‘ìš”ë„ ë¶„ì„**

```python
# Random Forest íŠ¹ì§• ì¤‘ìš”ë„
if 'rf' in models:
    feature_importance = models['rf'].feature_importances_
    
    # ìƒìœ„ 20ê°œ ì¤‘ìš” íŠ¹ì§•
    top_indices = np.argsort(feature_importance)[-20:]
    top_importance = feature_importance[top_indices]
    
    plt.figure(figsize=(10, 8))
    plt.barh(range(len(top_indices)), top_importance)
    plt.yticks(range(len(top_indices)), [f'Feature {i}' for i in top_indices])
    plt.xlabel('Feature Importance')
    plt.title('Top 20 Most Important Features')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('results/feature_importance.png', dpi=300, bbox_inches='tight')
    plt.show()
```

---

## ğŸš€ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

### **ë°©ë²• 1: ì „ì²´ ìë™ ì‹¤í–‰**

```python
from src.main_pipeline import MineDetectionPipeline, PipelineConfig

# íŒŒì´í”„ë¼ì¸ ì„¤ì •
config = PipelineConfig(
    input_xtf_path="data/raw/survey_data.xtf",    # XTF íŒŒì¼ ê²½ë¡œ
    output_dir="results/complete_analysis",       # ê²°ê³¼ ì €ì¥ ìœ„ì¹˜
    use_synthetic_data=True,                     # ëª¨ì˜ë°ì´í„° ì‚¬ìš©
    test_split_ratio=0.2,                       # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
    validation_split_ratio=0.1,                 # ê²€ì¦ ë°ì´í„° ë¹„ìœ¨  
    patch_size=64,                              # íŒ¨ì¹˜ í¬ê¸°
    feature_extractors=['lbp', 'gabor', 'hog', 'sfs'],  # ì‚¬ìš©í•  íŠ¹ì§•
    enable_visualization=True,                   # ì‹œê°í™” í™œì„±í™”
    save_intermediate_results=True               # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
)

# íŒŒì´í”„ë¼ì¸ ìƒì„± ë° ì‹¤í–‰
pipeline = MineDetectionPipeline(config)
results = pipeline.run_full_pipeline()

print("ğŸ‰ ì „ì²´ ë¶„ì„ ì™„ë£Œ!")
print(f"ğŸ“ ê²°ê³¼ ìœ„ì¹˜: {config.output_dir}")
print(f"ğŸ“Š ìµœì¢… ì •í™•ë„: {results.get('final_accuracy', 'N/A')}")
```

### **ë°©ë²• 2: ë‹¨ê³„ë³„ ì‹¤í–‰**

```python
# 1ë‹¨ê³„: XTF ë°ì´í„° ì¶”ì¶œ
print("1ï¸âƒ£ XTF ë°ì´í„° ì¶”ì¶œ ì¤‘...")
pipeline.run_step(1)
print("âœ… ì™„ë£Œ")

# 2ë‹¨ê³„: ì „ì²˜ë¦¬ ë° ë§¤í•‘  
print("2ï¸âƒ£ ì „ì²˜ë¦¬ ë° ì¢Œí‘œ ë§¤í•‘ ì¤‘...")
pipeline.run_step(2) 
print("âœ… ì™„ë£Œ")

# 3ë‹¨ê³„: í•™ìŠµ ë°ì´í„° ì¤€ë¹„
print("3ï¸âƒ£ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
pipeline.run_step(3)
print("âœ… ì™„ë£Œ")

# 4ë‹¨ê³„: íŠ¹ì§• ì¶”ì¶œ ë° ê²€ì¦
print("4ï¸âƒ£ íŠ¹ì§• ì¶”ì¶œ ë° ê²€ì¦ ì¤‘...")
pipeline.run_step(4)
print("âœ… ì™„ë£Œ")

# 5ë‹¨ê³„: íŠ¹ì§• ì„±ëŠ¥ í‰ê°€ (ğŸ†• ì•™ìƒë¸” í¬í•¨)
print("5ï¸âƒ£ íŠ¹ì§• ì„±ëŠ¥ í‰ê°€ ë° ì•™ìƒë¸” ì¤‘...")
pipeline.run_step(5)
print("âœ… ì™„ë£Œ")

# 6ë‹¨ê³„: ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨
print("6ï¸âƒ£ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
pipeline.run_step(6)
print("âœ… ì™„ë£Œ")

# 7ë‹¨ê³„: ì‹¤ë°ì´í„°-ëª¨ì˜ë°ì´í„° ë¹„êµ
print("7ï¸âƒ£ ì‹¤-ëª¨ì˜ ë°ì´í„° ë¹„êµ ë¶„ì„ ì¤‘...")
pipeline.run_step(7)
print("âœ… ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ! ğŸ‰")
```

### **ë°©ë²• 3: í†µí•© í•™ìŠµ íŒŒì´í”„ë¼ì¸ (ì—”ë“œíˆ¬ì—”ë“œ)**

```python
from src.training.integrated_pipeline import IntegratedPipeline, PipelineConfig as IntegratedConfig

# í†µí•© íŒŒì´í”„ë¼ì¸ ì„¤ì •
config = IntegratedConfig(
    use_hog=True,
    use_lbp=True, 
    use_gabor=True,
    use_sfs=True,
    use_traditional_ml=True,      # ì „í†µì  ML ì‚¬ìš©
    use_deep_learning=True,       # ë”¥ëŸ¬ë‹ ì‚¬ìš©
    ensemble_models=True,         # ì•™ìƒë¸” ì‚¬ìš©
    batch_size=32,
    num_epochs=100,
    device='auto'                 # GPU ìë™ ê°ì§€
)

# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
pipeline = IntegratedPipeline(config)
results = pipeline.run_complete_pipeline(
    images=training_images,
    labels=training_labels,
    output_dir=Path("results/integrated_analysis")
)

# ë¦¬í¬íŠ¸ ìƒì„±
pipeline.generate_report(Path("results/integrated_analysis"))
```

---

## ğŸ­ íŠ¹ì§• ì•™ìƒë¸” ì‹œìŠ¤í…œ ë…ë¦½ ì‹¤í–‰

### **ì•™ìƒë¸” ì‹œìŠ¤í…œë§Œ ë³„ë„ ì‹¤í–‰**

```python
from src.feature_extraction.feature_ensemble import FeatureEnsemble, EnsembleConfig

# 1. ê°œë³„ íŠ¹ì§• ì¶”ì¶œ (ê¸°ì¡´ ì¶”ì¶œê¸° ì‚¬ìš©)
from src.feature_extraction.lbp_extractor import ComprehensiveLBPExtractor
from src.feature_extraction.gabor_extractor import GaborFeatureExtractor  
from src.feature_extraction.hog_extractor import MultiScaleHOGExtractor
from src.feature_extraction.sfs_extractor import EnhancedSfSExtractor

# ì¶”ì¶œê¸° ì´ˆê¸°í™”
extractors = {
    'lbp': ComprehensiveLBPExtractor(),
    'gabor': GaborFeatureExtractor(),
    'hog': MultiScaleHOGExtractor(),
    'sfs': EnhancedSfSExtractor()
}

# íŠ¹ì§• ì¶”ì¶œ
features_dict = {}
for name, extractor in extractors.items():
    print(f"{name.upper()} íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    features = []
    
    for image in image_patches:
        if name == 'lbp':
            feat = extractor.extract_comprehensive_features(image)
        elif name == 'gabor':
            feat = extractor.extract_comprehensive_features(image)
        elif name == 'hog':
            feat = extractor.extract_combined_features(image)
        elif name == 'sfs':
            feat = extractor.extract_comprehensive_sfs_features(image)
        
        features.append(feat)
    
    features_dict[name] = np.array(features)
    print(f"âœ… {name}: {features_dict[name].shape}")

# 2. ì•™ìƒë¸” ì„¤ì • ë° í•™ìŠµ
ensemble_config = EnsembleConfig(
    use_concatenation=True,
    use_weighted_fusion=True,
    use_stacking=True,
    enable_pca=True,
    pca_variance_ratio=0.95,
    selection_k=300,
    weight_learning_method='performance_based'
)

# ì•™ìƒë¸” ì‹œìŠ¤í…œ ìƒì„±
ensemble = FeatureEnsemble(ensemble_config)

# 3. ì•™ìƒë¸” í•™ìŠµ
print("ğŸ­ ì•™ìƒë¸” í•™ìŠµ ì¤‘...")
ensemble.fit(features_dict, labels)

# 4. ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€
print("ğŸ“Š ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€ ì¤‘...")
performance_results = ensemble.evaluate_ensemble_methods(features_dict, labels)

print("\n=== ì•™ìƒë¸” ë°©ë²•ë³„ ì„±ëŠ¥ ===")
for method, metrics in performance_results.items():
    accuracy = metrics.get('accuracy', 0)
    feature_dim = metrics.get('feature_dim', 0)
    print(f"â€¢ {method:20s}: {accuracy:.4f} (ì°¨ì›: {feature_dim})")

# 5. ìµœê³  ì„±ëŠ¥ ë°©ë²• ì„ íƒ
best_method, best_features = ensemble.get_best_ensemble_method(features_dict, labels)
print(f"\nğŸ† ìµœê³  ì„±ëŠ¥: {best_method} (ì°¨ì›: {best_features.shape[1]})")

# 6. ì•™ìƒë¸” ëª¨ë¸ ì €ì¥
save_path = Path("models/feature_ensemble_standalone")
ensemble.save_ensemble_model(save_path)
print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥: {save_path}")
```

### **ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ë° ì‚¬ìš©**

```python
# ì €ì¥ëœ ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ
ensemble = FeatureEnsemble.load_ensemble_model(Path("models/feature_ensemble_standalone"))

# ìƒˆë¡œìš´ ë°ì´í„°ì— ì•™ìƒë¸” ì ìš©
new_features_dict = extract_features_from_new_data(new_images)
ensemble_results = ensemble.transform(new_features_dict)

# ìµœì  ì•™ìƒë¸” íŠ¹ì§• ì‚¬ìš©
best_ensemble_features = ensemble_results['weighted_fusion']  # ë˜ëŠ” ë‹¤ë¥¸ ë°©ë²•

# ë¶„ë¥˜ ëª¨ë¸ê³¼ ê²°í•©
classifier = RandomForestClassifier().fit(best_ensemble_features, train_labels)
predictions = classifier.predict(test_ensemble_features)
```

---

## ğŸ“Š ê²°ê³¼ í•´ì„ ë° ë¶„ì„

### **ê²°ê³¼ íŒŒì¼ êµ¬ì¡°**

```
results/complete_analysis/
â”œâ”€â”€ 01_intensity_data/          # XTF ì¶”ì¶œ ê²°ê³¼
â”‚   â”œâ”€â”€ port_intensity.npy
â”‚   â”œâ”€â”€ starboard_intensity.npy  
â”‚   â””â”€â”€ metadata.json
â”œâ”€â”€ 02_preprocessed/            # ì „ì²˜ë¦¬ ê²°ê³¼
â”‚   â”œâ”€â”€ port_preprocessed.npy
â”‚   â””â”€â”€ navigation_data.npz
â”œâ”€â”€ 03_features/                # íŠ¹ì§• ì¶”ì¶œ ê²°ê³¼
â”‚   â”œâ”€â”€ lbp_features.npy
â”‚   â”œâ”€â”€ gabor_features.npy
â”‚   â”œâ”€â”€ hog_features.npy
â”‚   â”œâ”€â”€ sfs_features.npy
â”‚   â””â”€â”€ ensemble_features/      # ğŸ†• ì•™ìƒë¸” ê²°ê³¼
â”‚       â”œâ”€â”€ concatenation.npy
â”‚       â”œâ”€â”€ weighted_fusion.npy
â”‚       â”œâ”€â”€ stacking.npy
â”‚       â””â”€â”€ performance_comparison.json
â”œâ”€â”€ 04_models/                  # í›ˆë ¨ëœ ëª¨ë¸
â”‚   â”œâ”€â”€ cnn_model.pth
â”‚   â”œâ”€â”€ ensemble_rf.pkl
â”‚   â””â”€â”€ feature_ensemble/       # ğŸ†• ì•™ìƒë¸” ëª¨ë¸
â”‚       â”œâ”€â”€ ensemble_model.pkl
â”‚       â””â”€â”€ ensemble_config.json
â”œâ”€â”€ 05_evaluation/              # ì„±ëŠ¥ í‰ê°€
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ roc_curves.png
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â””â”€â”€ performance_report.json
â”œâ”€â”€ 06_comparison/              # ì‹¤-ëª¨ì˜ ë°ì´í„° ë¹„êµ
â”‚   â””â”€â”€ domain_analysis.json
â””â”€â”€ 07_visualization/           # ì‹œê°í™” ê²°ê³¼
    â”œâ”€â”€ intensity_images/
    â”œâ”€â”€ feature_distributions/
    â””â”€â”€ ensemble_comparison/    # ğŸ†• ì•™ìƒë¸” ì‹œê°í™”
```

### **í•µì‹¬ ê²°ê³¼ í•´ì„**

#### **1. ì„±ëŠ¥ ì§€í‘œ í•´ì„**

```python
# ì„±ëŠ¥ ê²°ê³¼ ë¡œë“œ
import json
with open("results/complete_analysis/05_evaluation/performance_report.json", "r") as f:
    performance = json.load(f)

print("=== ìµœì¢… ì„±ëŠ¥ ë¶„ì„ ===")
accuracy = performance['test_accuracy']
precision = performance['test_precision']
recall = performance['test_recall']
f1 = performance['test_f1_score']

print(f"ì •í™•ë„ (Accuracy): {accuracy:.3f}")
print(f"  â†’ ì „ì²´ ì˜ˆì¸¡ ì¤‘ ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ ë¹„ìœ¨")
print(f"  â†’ ê¸°ì¤€: 85% ì´ìƒ ìš°ìˆ˜, 90% ì´ìƒ ë§¤ìš° ìš°ìˆ˜")

print(f"\nì •ë°€ë„ (Precision): {precision:.3f}")  
print(f"  â†’ ê¸°ë¢°ë¡œ ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì‹¤ì œ ê¸°ë¢° ë¹„ìœ¨")
print(f"  â†’ ë†’ì„ìˆ˜ë¡ ì˜¤íƒ(False Positive) ì ìŒ")

print(f"\nì¬í˜„ìœ¨ (Recall): {recall:.3f}")
print(f"  â†’ ì‹¤ì œ ê¸°ë¢° ì¤‘ ì˜¬ë°”ë¥´ê²Œ íƒì§€í•œ ë¹„ìœ¨")  
print(f"  â†’ ë†’ì„ìˆ˜ë¡ ë†“ì¹¨(False Negative) ì ìŒ")

print(f"\nF1-Score: {f1:.3f}")
print(f"  â†’ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™” í‰ê· ")
print(f"  â†’ ê· í˜•ì¡íŒ ì„±ëŠ¥ ì§€í‘œ")

# ëª©í‘œ ì„±ëŠ¥ ë‹¬ì„± ì—¬ë¶€
target_accuracy = 0.89
if accuracy >= target_accuracy:
    print(f"\nğŸ‰ ëª©í‘œ ì„±ëŠ¥ ë‹¬ì„±! ({accuracy:.3f} >= {target_accuracy})")
else:
    print(f"\nâš ï¸ ëª©í‘œ ì„±ëŠ¥ ë¯¸ë‹¬ì„± ({accuracy:.3f} < {target_accuracy})")
```

#### **2. ì•™ìƒë¸” íš¨ê³¼ ë¶„ì„**

```python
# ì•™ìƒë¸” ì„±ëŠ¥ ë¹„êµ ë¡œë“œ
with open("results/complete_analysis/03_features/ensemble_features/performance_comparison.json", "r") as f:
    ensemble_perf = json.load(f)

print("=== ì•™ìƒë¸” íš¨ê³¼ ë¶„ì„ ===")
individual_best = max([
    ensemble_perf.get('lbp_only', {}).get('accuracy', 0),
    ensemble_perf.get('gabor_only', {}).get('accuracy', 0),
    ensemble_perf.get('hog_only', {}).get('accuracy', 0),
    ensemble_perf.get('sfs_only', {}).get('accuracy', 0)
])

ensemble_best = max([
    ensemble_perf.get('concatenation', {}).get('accuracy', 0),
    ensemble_perf.get('weighted_fusion', {}).get('accuracy', 0),
    ensemble_perf.get('stacking', {}).get('accuracy', 0)
])

improvement = ensemble_best - individual_best
print(f"ê°œë³„ íŠ¹ì§• ìµœê³  ì„±ëŠ¥: {individual_best:.3f}")
print(f"ì•™ìƒë¸” ìµœê³  ì„±ëŠ¥: {ensemble_best:.3f}")
print(f"ì•™ìƒë¸” ê°œì„  íš¨ê³¼: +{improvement:.3f} ({improvement/individual_best*100:.1f}%)")

if improvement > 0.02:  # 2% ì´ìƒ ê°œì„ 
    print("âœ… ì•™ìƒë¸”ì´ ìƒë‹¹í•œ ì„±ëŠ¥ ê°œì„ ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!")
elif improvement > 0.005:  # 0.5% ì´ìƒ ê°œì„ 
    print("âœ… ì•™ìƒë¸”ì´ ì„±ëŠ¥ ê°œì„ ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤.")
else:
    print("âš ï¸ ì•™ìƒë¸” íš¨ê³¼ê°€ ì œí•œì ì…ë‹ˆë‹¤.")
```

#### **3. ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œì˜ ì˜ë¯¸**

```python
def interpret_operational_performance(accuracy, precision, recall):
    """ìš´ì˜ í™˜ê²½ ê´€ì ì—ì„œ ì„±ëŠ¥ í•´ì„"""
    
    print("=== ìš´ì˜ í™˜ê²½ ì„±ëŠ¥ í•´ì„ ===")
    
    # 1000ê°œ ê¸°ë¢° íƒì§€ ì‘ì—… ê°€ì •
    total_mines = 1000
    detected_mines = int(total_mines * recall)
    missed_mines = total_mines - detected_mines
    
    total_detections = int(detected_mines / precision) if precision > 0 else 0
    false_alarms = total_detections - detected_mines
    
    print(f"ğŸ“Š 1000ê°œ ê¸°ë¢° íƒì§€ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜:")
    print(f"  â€¢ íƒì§€ëœ ê¸°ë¢°: {detected_mines}ê°œ")
    print(f"  â€¢ ë†“ì¹œ ê¸°ë¢°: {missed_mines}ê°œ")
    print(f"  â€¢ ì˜¤íƒì§€: {false_alarms}ê°œ")
    print(f"  â€¢ ì´ íƒì§€ ì‹ í˜¸: {total_detections}ê°œ")
    
    # ìœ„í—˜ë„ í‰ê°€
    if missed_mines <= 50:  # 5% ì´í•˜
        risk_level = "ë‚®ìŒ"
        risk_color = "ğŸŸ¢"
    elif missed_mines <= 100:  # 10% ì´í•˜
        risk_level = "ë³´í†µ"
        risk_color = "ğŸŸ¡"
    else:
        risk_level = "ë†’ìŒ"
        risk_color = "ğŸ”´"
    
    print(f"\n{risk_color} ìš´ì˜ ìœ„í—˜ë„: {risk_level}")
    print(f"  â€¢ ë†“ì¹œ ê¸°ë¢° ë¹„ìœ¨: {missed_mines/total_mines*100:.1f}%")
    
    # ìš´ì˜ íš¨ìœ¨ì„±
    if false_alarms <= 100:  # 10% ì´í•˜ ì˜¤íƒ
        efficiency = "ë†’ìŒ"
        eff_color = "ğŸŸ¢"
    elif false_alarms <= 200:  # 20% ì´í•˜ ì˜¤íƒ
        efficiency = "ë³´í†µ"
        eff_color = "ğŸŸ¡"
    else:
        efficiency = "ë‚®ìŒ"
        eff_color = "ğŸ”´"
    
    print(f"{eff_color} ìš´ì˜ íš¨ìœ¨ì„±: {efficiency}")
    print(f"  â€¢ ì˜¤íƒì§€ ë¹„ìœ¨: {false_alarms/total_detections*100:.1f}%")

# ì‹¤ì œ ì„±ëŠ¥ìœ¼ë¡œ í•´ì„
interpret_operational_performance(
    accuracy=performance['test_accuracy'],
    precision=performance['test_precision'], 
    recall=performance['test_recall']
)
```

---

## ğŸ”§ ê³ ê¸‰ í™œìš©ë²•

### **1. ì»¤ìŠ¤í…€ íŠ¹ì§• ì¶”ì¶œê¸° ì¶”ê°€**

```python
# ìƒˆë¡œìš´ íŠ¹ì§• ì¶”ì¶œê¸° í´ë˜ìŠ¤ ì •ì˜
class WaveletFeatureExtractor:
    def __init__(self):
        self.wavelet_type = 'db4'
        self.levels = 3
    
    def extract_features(self, image):
        import pywt
        
        # Wavelet ë³€í™˜
        coeffs = pywt.wavedec2(image, self.wavelet_type, level=self.levels)
        
        # í†µê³„ íŠ¹ì§• ì¶”ì¶œ
        features = []
        for coeff in coeffs:
            if isinstance(coeff, tuple):
                for c in coeff:
                    features.extend([
                        np.mean(c), np.std(c), 
                        np.max(c), np.min(c)
                    ])
            else:
                features.extend([
                    np.mean(coeff), np.std(coeff),
                    np.max(coeff), np.min(coeff)
                ])
        
        return np.array(features)

# ê¸°ì¡´ ì•™ìƒë¸”ì— ì¶”ê°€
extractors['wavelet'] = WaveletFeatureExtractor()
```

### **2. ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ë¶„ì„**

```python
def multi_scale_analysis(image, scales=[0.5, 1.0, 1.5, 2.0]):
    """ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ì—ì„œ íŠ¹ì§• ì¶”ì¶œ"""
    
    multi_scale_features = []
    
    for scale in scales:
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        new_size = (int(image.shape[0] * scale), int(image.shape[1] * scale))
        scaled_image = cv2.resize(image, new_size)
        
        # ê° ìŠ¤ì¼€ì¼ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
        scale_features = {}
        for name, extractor in extractors.items():
            features = extractor.extract_features(scaled_image)
            scale_features[f"{name}_scale_{scale}"] = features
        
        multi_scale_features.append(scale_features)
    
    return multi_scale_features
```

### **3. ì ì‘í˜• ì„ê³„ê°’ ì„¤ì •**

```python
class AdaptiveThresholdClassifier:
    def __init__(self, base_model):
        self.base_model = base_model
        self.adaptive_threshold = 0.5
        
    def predict_adaptive(self, X, confidence_threshold=0.8):
        # ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°
        probabilities = self.base_model.predict_proba(X)
        max_probs = np.max(probabilities, axis=1)
        
        # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì ì‘í˜• ë¶„ë¥˜
        predictions = []
        for i, (prob, max_prob) in enumerate(zip(probabilities, max_probs)):
            if max_prob >= confidence_threshold:
                # ë†’ì€ ì‹ ë¢°ë„: ì¼ë°˜ ì„ê³„ê°’ ì‚¬ìš©
                pred = 1 if prob[1] > self.adaptive_threshold else 0
            else:
                # ë‚®ì€ ì‹ ë¢°ë„: ë³´ìˆ˜ì  ì„ê³„ê°’ ì‚¬ìš©
                conservative_threshold = self.adaptive_threshold + 0.1
                pred = 1 if prob[1] > conservative_threshold else 0
            
            predictions.append(pred)
        
        return np.array(predictions), max_probs
```

### **4. ì‹¤ì‹œê°„ ì²˜ë¦¬ ìµœì í™”**

```python
class RealTimeProcessor:
    def __init__(self, model, feature_extractors):
        self.model = model
        self.extractors = feature_extractors
        self.feature_cache = {}
        self.batch_size = 10
        
    def process_stream(self, image_stream):
        """ì´ë¯¸ì§€ ìŠ¤íŠ¸ë¦¼ ì‹¤ì‹œê°„ ì²˜ë¦¬"""
        batch = []
        
        for image in image_stream:
            batch.append(image)
            
            if len(batch) >= self.batch_size:
                # ë°°ì¹˜ ì²˜ë¦¬
                predictions = self.process_batch(batch)
                yield predictions
                batch = []
        
        # ë‚¨ì€ ì´ë¯¸ì§€ ì²˜ë¦¬
        if batch:
            predictions = self.process_batch(batch)
            yield predictions
    
    def process_batch(self, image_batch):
        # ë³‘ë ¬ íŠ¹ì§• ì¶”ì¶œ
        features_batch = []
        for image in image_batch:
            features = self.extract_features_parallel(image)
            features_batch.append(features)
        
        # ë°°ì¹˜ ì˜ˆì¸¡
        X = np.array(features_batch)
        predictions = self.model.predict(X)
        probabilities = self.model.predict_proba(X)
        
        return list(zip(predictions, probabilities))
    
    def extract_features_parallel(self, image):
        from concurrent.futures import ThreadPoolExecutor
        
        # ë³‘ë ¬ íŠ¹ì§• ì¶”ì¶œ
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = {
                name: executor.submit(extractor.extract_features, image)
                for name, extractor in self.extractors.items()
            }
            
            features = {}
            for name, future in futures.items():
                features[name] = future.result()
        
        return np.hstack(list(features.values()))
```

---

## ğŸ› ï¸ ë¬¸ì œí•´ê²° ë° ìµœì í™”

### **ì¼ë°˜ì ì¸ ë¬¸ì œë“¤**

#### **1. ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜**

```python
# í•´ê²°ì±… 1: ë°°ì¹˜ ì²˜ë¦¬
def process_large_dataset_batched(images, labels, batch_size=50):
    """ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ë°°ì¹˜ ì²˜ë¦¬"""
    results = []
    
    for i in range(0, len(images), batch_size):
        print(f"ì²˜ë¦¬ ì¤‘: {i+1}-{min(i+batch_size, len(images))} / {len(images)}")
        
        batch_images = images[i:i+batch_size]
        batch_labels = labels[i:i+batch_size]
        
        # ë°°ì¹˜ë³„ íŠ¹ì§• ì¶”ì¶œ
        batch_features = extract_features_batch(batch_images)
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        import gc
        gc.collect()
        
        results.append({
            'features': batch_features,
            'labels': batch_labels,
            'indices': list(range(i, min(i+batch_size, len(images))))
        })
    
    return results

# í•´ê²°ì±… 2: ë©”ëª¨ë¦¬ ë§¤í•‘ ì‚¬ìš©
def save_features_memmap(features, filepath):
    """ë©”ëª¨ë¦¬ ë§¤í•‘ìœ¼ë¡œ ëŒ€ìš©ëŸ‰ íŠ¹ì§• ì €ì¥"""
    shape = features.shape
    dtype = features.dtype
    
    # ë©”ëª¨ë¦¬ ë§µ íŒŒì¼ ìƒì„±
    memmap_features = np.memmap(filepath, dtype=dtype, mode='w+', shape=shape)
    memmap_features[:] = features[:]
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    np.save(f"{filepath}_shape.npy", shape)
    np.save(f"{filepath}_dtype.npy", str(dtype))
    
    del memmap_features
    return filepath

def load_features_memmap(filepath):
    """ë©”ëª¨ë¦¬ ë§µì—ì„œ íŠ¹ì§• ë¡œë“œ"""
    shape = tuple(np.load(f"{filepath}_shape.npy"))
    dtype = str(np.load(f"{filepath}_dtype.npy"))
    
    return np.memmap(filepath, dtype=dtype, mode='r', shape=shape)
```

#### **2. íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨**

```python
# ê²¬ê³ í•œ íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜
def robust_feature_extraction(image, extractors, fallback_dim=100):
    """ì˜¤ë¥˜ì— ê°•í•œ íŠ¹ì§• ì¶”ì¶œ"""
    features = {}
    
    for name, extractor in extractors.items():
        try:
            # 1ì°¨ ì‹œë„: ì›ë³¸ ì¶”ì¶œê¸°
            feat = extractor.extract_features(image)
            
            # íŠ¹ì§• ìœ íš¨ì„± ê²€ì‚¬
            if len(feat) == 0 or np.any(np.isnan(feat)) or np.any(np.isinf(feat)):
                raise ValueError(f"Invalid features: {len(feat)} dims, NaN: {np.any(np.isnan(feat))}")
                
            features[name] = feat
            
        except Exception as e:
            logger.warning(f"{name} íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
            try:
                # 2ì°¨ ì‹œë„: ë‹¨ìˆœ í†µê³„ íŠ¹ì§•
                fallback_features = extract_statistical_features(image)
                
                # ì°¨ì› ë§ì¶”ê¸°
                if len(fallback_features) < fallback_dim:
                    padded = np.zeros(fallback_dim)
                    padded[:len(fallback_features)] = fallback_features
                    fallback_features = padded
                elif len(fallback_features) > fallback_dim:
                    fallback_features = fallback_features[:fallback_dim]
                
                features[name] = fallback_features
                logger.info(f"{name} í´ë°± íŠ¹ì§• ì‚¬ìš© ({fallback_dim}ì°¨ì›)")
                
            except Exception as e2:
                logger.error(f"{name} í´ë°±ë„ ì‹¤íŒ¨: {e2}")
                # ìµœí›„ ìˆ˜ë‹¨: ì˜ ë²¡í„°
                features[name] = np.zeros(fallback_dim)
    
    return features

def extract_statistical_features(image):
    """ì´ë¯¸ì§€ í†µê³„ íŠ¹ì§• ì¶”ì¶œ (í´ë°±ìš©)"""
    features = []
    
    # ê¸°ë³¸ í†µê³„ëŸ‰
    features.extend([
        np.mean(image), np.std(image), np.var(image),
        np.min(image), np.max(image), np.median(image),
        np.percentile(image, 25), np.percentile(image, 75)
    ])
    
    # ê¸°ìš¸ê¸° í†µê³„
    gy, gx = np.gradient(image)
    features.extend([
        np.mean(np.abs(gx)), np.mean(np.abs(gy)),
        np.std(gx), np.std(gy)
    ])
    
    # íˆìŠ¤í† ê·¸ë¨ íŠ¹ì§•
    hist, _ = np.histogram(image.flatten(), bins=10, range=(0, 1))
    hist = hist / np.sum(hist)  # ì •ê·œí™”
    features.extend(hist)
    
    return np.array(features)
```

#### **3. ì„±ëŠ¥ ì €í•˜ ë¬¸ì œ**

```python
# ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
import cProfile
import pstats
from functools import wraps

def profile_function(func):
    """í•¨ìˆ˜ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        profiler = cProfile.Profile()
        profiler.enable()
        
        result = func(*args, **kwargs)
        
        profiler.disable()
        
        # í”„ë¡œíŒŒì¼ ê²°ê³¼ ì¶œë ¥
        stats = pstats.Stats(profiler)
        stats.sort_stats('cumulative')
        stats.print_stats(20)  # ìƒìœ„ 20ê°œ í•¨ìˆ˜
        
        return result
    return wrapper

# ë³‘ëª© ì§€ì  ì‹ë³„ ë° ìµœì í™”
@profile_function
def optimized_feature_extraction(images):
    """ìµœì í™”ëœ íŠ¹ì§• ì¶”ì¶œ"""
    
    # 1. ë²¡í„°í™” ì—°ì‚° ì‚¬ìš©
    batch_features = {}
    
    for name, extractor in extractors.items():
        if hasattr(extractor, 'extract_batch'):
            # ë°°ì¹˜ ì²˜ë¦¬ ì§€ì› ì¶”ì¶œê¸°
            batch_features[name] = extractor.extract_batch(images)
        else:
            # ê°œë³„ ì²˜ë¦¬
            features_list = []
            for img in images:
                feat = extractor.extract_features(img)
                features_list.append(feat)
            batch_features[name] = np.array(features_list)
    
    return batch_features

# ìºì‹± ì‹œìŠ¤í…œ
from functools import lru_cache
import hashlib

class FeatureCache:
    def __init__(self, max_size=1000):
        self.cache = {}
        self.max_size = max_size
        
    def get_cache_key(self, image):
        """ì´ë¯¸ì§€ í•´ì‹œí‚¤ ìƒì„±"""
        image_bytes = image.tobytes()
        return hashlib.md5(image_bytes).hexdigest()
    
    def get(self, image, extractor_name):
        key = f"{self.get_cache_key(image)}_{extractor_name}"
        return self.cache.get(key)
    
    def set(self, image, extractor_name, features):
        if len(self.cache) >= self.max_size:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
        
        key = f"{self.get_cache_key(image)}_{extractor_name}"
        self.cache[key] = features

# ìºì‹œ ì ìš©
cache = FeatureCache(max_size=500)

def cached_feature_extraction(image, extractor_name, extractor):
    """ìºì‹œ ì ìš© íŠ¹ì§• ì¶”ì¶œ"""
    
    # ìºì‹œ í™•ì¸
    cached_features = cache.get(image, extractor_name)
    if cached_features is not None:
        return cached_features
    
    # íŠ¹ì§• ì¶”ì¶œ ë° ìºì‹±
    features = extractor.extract_features(image)
    cache.set(image, extractor_name, features)
    
    return features
```

### **ì„±ëŠ¥ ìµœì í™” íŒ**

#### **1. GPU ê°€ì†í™”**

```python
# GPU í™œìš© ìµœì í™”
def enable_gpu_optimization():
    """GPU ìµœì í™” ì„¤ì •"""
    
    import torch
    
    if torch.cuda.is_available():
        # CUDA ìµœì í™” ì„¤ì •
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        
        # ë©”ëª¨ë¦¬ ìµœì í™”
        torch.cuda.empty_cache()
        
        print(f"GPU ìµœì í™” í™œì„±í™”: {torch.cuda.get_device_name(0)}")
        return True
    else:
        print("GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

# GPU ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œ (ì˜ˆ: Gabor í•„í„°)
def gpu_accelerated_gabor(image):
    """GPU ê°€ì† Gabor í•„í„°ë§"""
    
    import torch
    import torch.nn.functional as F
    
    if not torch.cuda.is_available():
        return cpu_gabor_extraction(image)
    
    device = torch.device('cuda')
    
    # ì´ë¯¸ì§€ë¥¼ GPU í…ì„œë¡œ ë³€í™˜
    image_tensor = torch.from_numpy(image).float().unsqueeze(0).unsqueeze(0).to(device)
    
    # Gabor í•„í„° ì»¤ë„ ìƒì„± (GPUì—ì„œ)
    gabor_kernels = create_gabor_kernels_gpu(device)
    
    # GPUì—ì„œ ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°
    features = []
    for kernel in gabor_kernels:
        response = F.conv2d(image_tensor, kernel, padding='same')
        
        # í†µê³„ëŸ‰ ê³„ì‚°
        stats = torch.stack([
            response.mean(),
            response.std(),
            response.max(),
            response.min()
        ])
        
        features.append(stats)
    
    # CPUë¡œ ê²°ê³¼ ì´ë™
    result = torch.cat(features).cpu().numpy()
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    torch.cuda.empty_cache()
    
    return result
```

#### **2. ë³‘ë ¬ ì²˜ë¦¬**

```python
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
import multiprocessing as mp

def parallel_feature_extraction(images, extractors, n_jobs=None):
    """ë³‘ë ¬ íŠ¹ì§• ì¶”ì¶œ"""
    
    if n_jobs is None:
        n_jobs = mp.cpu_count()
    
    def extract_single_image(args):
        image, extractor_dict = args
        features = {}
        for name, extractor in extractor_dict.items():
            features[name] = extractor.extract_features(image)
        return features
    
    # í”„ë¡œì„¸ìŠ¤ í’€ë¡œ ë³‘ë ¬ ì²˜ë¦¬
    with ProcessPoolExecutor(max_workers=n_jobs) as executor:
        args_list = [(img, extractors) for img in images]
        results = list(executor.map(extract_single_image, args_list))
    
    # ê²°ê³¼ ì •ë¦¬
    combined_features = {}
    for name in extractors.keys():
        combined_features[name] = np.array([r[name] for r in results])
    
    return combined_features

# I/O ì§‘ì•½ì  ì‘ì—…ì€ ThreadPoolExecutor ì‚¬ìš©
def parallel_file_processing(file_paths):
    """ë³‘ë ¬ íŒŒì¼ ì²˜ë¦¬"""
    
    def process_single_file(filepath):
        # íŒŒì¼ ì½ê¸° ë° ì²˜ë¦¬
        image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)
        features = extract_features_from_image(image)
        return filepath, features
    
    with ThreadPoolExecutor(max_workers=8) as executor:
        results = list(executor.map(process_single_file, file_paths))
    
    return dict(results)
```

---

## ğŸ“ ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„

### **ğŸ¯ ì´ ê°€ì´ë“œë¡œ í•  ìˆ˜ ìˆëŠ” ê²ƒ**

1. **âœ… XTF íŒŒì¼ì—ì„œ ê°•ë„ ë°ì´í„° ì¶”ì¶œ**
2. **âœ… ë‹¤ì¤‘ íŠ¹ì§• ì¶”ì¶œ (LBP, Gabor, HOG, SfS)**
3. **âœ… ğŸ†• ê³ ë„í™”ëœ íŠ¹ì§• ì•™ìƒë¸” (ì—°ê²°, ê°€ì¤‘ìœµí•©, ìŠ¤íƒœí‚¹)**
4. **âœ… ê¸°ê³„í•™ìŠµ/ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨**
5. **âœ… ì¢…í•© ì„±ëŠ¥ í‰ê°€ ë° ë¶„ì„**
6. **âœ… ì‹¤ë°ì´í„°-ëª¨ì˜ë°ì´í„° ë¹„êµ**
7. **âœ… GPU/í´ë¼ìš°ë“œ í™˜ê²½ ìë™ ìµœì í™”**

### **ğŸš€ ê¶Œì¥ ì‹¤í–‰ ìˆœì„œ**

```bash
# 1ï¸âƒ£ í™˜ê²½ ì„¤ì • ë° í…ŒìŠ¤íŠ¸
python scripts/test_multi_environment.py

# 2ï¸âƒ£ ë‹¨ì¼ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸  
python -m src.data_processing.xtf_intensity_extractor --test
python -m src.feature_extraction.feature_ensemble --test

# 3ï¸âƒ£ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
python src/main_pipeline.py

# 4ï¸âƒ£ ì•™ìƒë¸” íŠ¹í™” ë¶„ì„ (ì„ íƒì )
python src/feature_extraction/feature_ensemble.py

# 5ï¸âƒ£ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
python scripts/benchmark_performance.py --save
```

### **ğŸ“ˆ ê¸°ëŒ€ ì„±ëŠ¥**

| êµ¬ì„± | ì •í™•ë„ | íŠ¹ì§• |
|------|--------|------|
| **ê°œë³„ íŠ¹ì§•** | 80-85% | ë¹ ë¦„, í•´ì„ ìš©ì´ |
| **ë‹¨ìˆœ ì—°ê²°** | 85-87% | êµ¬í˜„ ê°„ë‹¨ |
| **ğŸ†• ê°€ì¤‘ ìœµí•©** | 87-89% | ê· í˜•ì¡íŒ ì„±ëŠ¥ |
| **ğŸ†• ìŠ¤íƒœí‚¹** | **89-92%** | ìµœê³  ì„±ëŠ¥ |

### **ğŸ”„ ì§€ì†ì ì¸ ê°œì„  ë°©ì•ˆ**

1. **ìƒˆë¡œìš´ íŠ¹ì§• ì¶”ê°€**: Wavelet, SIFT, ë”¥ëŸ¬ë‹ íŠ¹ì§•
2. **ì•™ìƒë¸” ê³ ë„í™”**: ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜, ë™ì  ê°€ì¤‘ì¹˜
3. **ì‹¤ì‹œê°„ ìµœì í™”**: ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬, GPU íŒŒì´í”„ë¼ì¸
4. **ë„ë©”ì¸ ì ì‘**: ìƒˆë¡œìš´ í•´ì—­ ë°ì´í„° ì ì‘

---

**ğŸ‰ ì´ì œ ì™„ì „í•œ ì‚¬ì´ë“œìŠ¤ìº” ì†Œë‚˜ ê¸°ë¢°íƒì§€ ì‹œìŠ¤í…œì„ ììœ ìì¬ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!**

ê° ëª¨ë“ˆì€ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë©°, ì „ì²´ íŒŒì´í”„ë¼ì¸ì€ ìë™í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ìƒˆë¡œ ì¶”ê°€ëœ íŠ¹ì§• ì•™ìƒë¸” ì‹œìŠ¤í…œì„ í†µí•´ ì´ì „ë³´ë‹¤ í›¨ì”¬ í–¥ìƒëœ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ íŠ¹ì • ë¶€ë¶„ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë¬¸ì˜í•˜ì„¸ìš”! ğŸ“

---

**Contact**: ê¸°ë¢°íƒì§€ì‹œìŠ¤í…œ ê°œë°œíŒ€  
**Version**: 3.0 (2025-09-09)  
**License**: Research & Development Only