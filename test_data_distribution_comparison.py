#!/usr/bin/env python3
"""
ì‹¤ë°ì´í„°ì™€ ëª¨ì˜ë°ì´í„° ë¶„í¬ ë¹„êµ í…ŒìŠ¤íŠ¸

ê¸°ì¡´ ëª¨ì˜ë°ì´í„°ì™€ ìƒˆë¡œìš´ ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ëª¨ì˜ë°ì´í„°ì˜ ë¶„í¬ íŠ¹ì„±ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import numpy as np
import logging
from pathlib import Path
import json
import sys
from typing import Dict, List, Any, Tuple

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
sys.path.append('src')

from data_simulation.scenario_generator import ScenarioDataGenerator
# ì§ì ‘ importë¥¼ í”¼í•˜ê³  íŒŒì¼ ê²½ë¡œë¡œ ë¡œë“œ
import importlib.util

# ì§ì ‘ ëª¨ë“ˆ ë¡œë“œ
spec = importlib.util.spec_from_file_location(
    "data_distribution_analyzer", 
    "src/evaluation/data_distribution_analyzer.py"
)
analyzer_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(analyzer_module)

DataDistributionAnalyzer = analyzer_module.DataDistributionAnalyzer
json_safe_convert = analyzer_module.json_safe_convert

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def create_legacy_synthetic_data(n_samples: int = 20, size: Tuple[int, int] = (64, 64)) -> np.ndarray:
    """ê¸°ì¡´ ë°©ì‹ì˜ ëª¨ì˜ë°ì´í„° ìƒì„± (Phase 1 ìŠ¤íƒ€ì¼)"""
    np.random.seed(42)
    images = []
    
    for i in range(n_samples):
        # ê¸°ë³¸ ë°°ê²½ ìƒì„±
        image = np.random.normal(0.5, 0.1, size)
        
        if i < n_samples // 2:  # ì ˆë°˜ì€ ì–‘ì„± ìƒ˜í”Œ
            # ê°„ë‹¨í•œ íƒ€ì›í˜• ê¸°ë¢° ì¶”ê°€
            center_y, center_x = size[0] // 2, size[1] // 2
            
            y, x = np.ogrid[:size[0], :size[1]]
            mask = ((x - center_x) / 12)**2 + ((y - center_y) / 8)**2 < 1
            image[mask] += 0.3
            
            # ê°„ë‹¨í•œ ê·¸ë¦¼ì
            shadow_start = center_x + 15
            shadow_end = min(shadow_start + 20, size[1])
            shadow_y_start = max(0, center_y - 10)
            shadow_y_end = min(center_y + 10, size[0])
            
            image[shadow_y_start:shadow_y_end, shadow_start:shadow_end] -= 0.2
        
        image = np.clip(image, 0, 1)
        images.append(image)
    
    return np.array(images, dtype=np.float32)


def generate_scenario_comparison_datasets() -> Dict[str, np.ndarray]:
    """ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµìš© ë°ì´í„°ì…‹ ìƒì„±"""
    logger.info("ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµìš© ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘")
    
    datasets = {}
    generator = ScenarioDataGenerator()
    
    # 1. ê¸°ì¡´ ë°©ì‹ ëª¨ì˜ë°ì´í„°
    legacy_data = create_legacy_synthetic_data(n_samples=20, size=(64, 64))
    datasets['Legacy_Synthetic'] = legacy_data
    
    # 2. ì‹œë‚˜ë¦¬ì˜¤ë³„ ëª¨ì˜ë°ì´í„°
    scenarios_to_test = [
        'A_deep_ocean',      # ê¹Šì€ ë°”ë‹¤
        'B_shallow_coastal', # ì–•ì€ ì—°ì•ˆ  
        'C_medium_depth',    # ì¤‘ê°„ ê¹Šì´
        'D_high_current',    # ê°•í•œ í•´ë¥˜
        'E_sandy_rocky'      # ëª¨ë˜/ì•”ì´ˆ
    ]
    
    for scenario_name in scenarios_to_test:
        logger.info(f"{scenario_name} ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        
        dataset = generator.generate_scenario_dataset(
            scenario_name,
            n_positive=10,
            n_negative=10,
            image_size=(64, 64)
        )
        
        images = np.array(dataset['images'])
        datasets[scenario_name] = images
    
    logger.info(f"ì´ {len(datasets)}ê°œ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
    return datasets


def analyze_data_quality_metrics(datasets: Dict[str, np.ndarray]) -> Dict[str, Any]:
    """ë°ì´í„° í’ˆì§ˆ ì§€í‘œ ë¶„ì„"""
    logger.info("ë°ì´í„° í’ˆì§ˆ ì§€í‘œ ë¶„ì„ ì‹œì‘")
    
    quality_metrics = {}
    
    for name, data in datasets.items():
        logger.info(f"{name} í’ˆì§ˆ ë¶„ì„ ì¤‘...")
        
        flat_data = data.flatten()
        
        # ê¸°ë³¸ í’ˆì§ˆ ì§€í‘œ
        metrics = {
            'dynamic_range': float(np.max(flat_data) - np.min(flat_data)),
            'signal_noise_ratio': float(np.mean(flat_data) / (np.std(flat_data) + 1e-10)),
            'contrast_ratio': float(np.percentile(flat_data, 95) - np.percentile(flat_data, 5)),
            'data_sparsity': float(np.sum(flat_data < 0.1) / len(flat_data)),  # ë§¤ìš° ì–´ë‘ìš´ í”½ì…€ ë¹„ìœ¨
            'saturation_ratio': float(np.sum(flat_data > 0.9) / len(flat_data)),  # í¬í™” í”½ì…€ ë¹„ìœ¨
            'entropy': calculate_entropy(flat_data),
            'uniformity_score': 1.0 / (np.std(flat_data) + 1e-10)  # ë†’ì„ìˆ˜ë¡ ê· ì¼í•¨
        }
        
        # í…ìŠ¤ì²˜ ë³µì¡ë„
        if len(data.shape) >= 3:
            sample_image = data[0]
        else:
            sample_image = data
        
        # ê·¸ë˜ë””ì–¸íŠ¸ ê¸°ë°˜ ë³µì¡ë„
        grad_x = np.diff(sample_image, axis=1)
        grad_y = np.diff(sample_image, axis=0)
        gradient_magnitude = np.sqrt(grad_x[:-1, :]**2 + grad_y[:, :-1]**2)
        
        metrics.update({
            'texture_complexity': float(np.mean(gradient_magnitude)),
            'edge_sharpness': float(np.percentile(gradient_magnitude, 95)),
            'texture_uniformity': float(1.0 / (np.std(gradient_magnitude) + 1e-10))
        })
        
        quality_metrics[name] = metrics
    
    return quality_metrics


def calculate_entropy(data: np.ndarray, bins: int = 256) -> float:
    """íˆìŠ¤í† ê·¸ë¨ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°"""
    try:
        hist, _ = np.histogram(data, bins=bins, density=True)
        hist = hist + 1e-10  # log(0) ë°©ì§€
        entropy = -np.sum(hist * np.log2(hist)) / np.log2(bins)  # ì •ê·œí™”
        return float(entropy)
    except:
        return 0.0


def create_distribution_report(analysis_results: Dict[str, Any], 
                             quality_metrics: Dict[str, Any]) -> str:
    """ë¶„í¬ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
    
    report_lines = [
        "# ğŸ” ì‹¤ë°ì´í„°ì™€ ëª¨ì˜ë°ì´í„° ë¶„í¬ ë¹„êµ ë¶„ì„ ë¦¬í¬íŠ¸",
        f"**ë¶„ì„ ì¼ì‹œ**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}" if 'pd' in globals() else "**ë¶„ì„ ì¼ì‹œ**: 2025-09-09",
        "",
        "---",
        "",
        "## ğŸ“Š ë°ì´í„°ì…‹ ê°œìš”",
        ""
    ]
    
    # ë°ì´í„°ì…‹ ê¸°ë³¸ ì •ë³´
    if 'summary' in analysis_results and 'dataset_stats' in analysis_results['summary']:
        report_lines.append("| ë°ì´í„°ì…‹ | í‰ê·  | í‘œì¤€í¸ì°¨ | ìµœì†Œê°’ | ìµœëŒ€ê°’ | ìƒ˜í”Œ ìˆ˜ |")
        report_lines.append("|---------|------|----------|--------|--------|---------|")
        
        for name, stats in analysis_results['summary']['dataset_stats'].items():
            report_lines.append(
                f"| **{name}** | {stats['mean']:.3f} | {stats['std']:.3f} | "
                f"{stats['min']:.3f} | {stats['max']:.3f} | {stats['size']//4096:,} |"
            )
        report_lines.append("")
    
    # í’ˆì§ˆ ì§€í‘œ
    report_lines.extend([
        "## ğŸ¯ ë°ì´í„° í’ˆì§ˆ ì§€í‘œ",
        "",
        "| ë°ì´í„°ì…‹ | ë™ì ë²”ìœ„ | S/N ë¹„ | ëŒ€ë¹„ë„ | í…ìŠ¤ì²˜ë³µì¡ë„ | ì—”íŠ¸ë¡œí”¼ |",
        "|---------|----------|--------|--------|--------------|----------|"
    ])
    
    for name, metrics in quality_metrics.items():
        report_lines.append(
            f"| **{name}** | {metrics['dynamic_range']:.3f} | "
            f"{metrics['signal_noise_ratio']:.1f} | {metrics['contrast_ratio']:.3f} | "
            f"{metrics['texture_complexity']:.4f} | {metrics['entropy']:.3f} |"
        )
    
    report_lines.extend(["", "## ğŸ”„ ë¶„í¬ ìœ ì‚¬ë„ ë¹„êµ", ""])
    
    # ìœ ì‚¬ë„ ë¶„ì„
    if 'pairwise_comparisons' in analysis_results:
        report_lines.append("| ë¹„êµ ìŒ | í‰ê·  ì°¨ì´ | KS í†µê³„ëŸ‰ | íˆìŠ¤í† ê·¸ë¨ ìƒê´€ | ìœ ì‚¬ë„ ì ìˆ˜ |")
        report_lines.append("|---------|-----------|-----------|-----------------|-------------|")
        
        for pair_name, comparison in analysis_results['pairwise_comparisons'].items():
            report_lines.append(
                f"| **{pair_name.replace('_vs_', ' vs ')}** | "
                f"{comparison.get('mean_difference', 0):.4f} | "
                f"{comparison.get('ks_statistic', 0):.3f} | "
                f"{comparison.get('histogram_correlation', 0):.3f} | "
                f"{comparison.get('similarity_score', 0):.3f} |"
            )
        report_lines.append("")
    
    # ìš”ì•½ ë° ê¶Œì¥ì‚¬í•­
    summary = analysis_results.get('summary', {})
    
    report_lines.extend([
        "## ğŸ’¡ ë¶„ì„ ê²°ê³¼ ìš”ì•½",
        "",
        f"- **ì „ì²´ í‰ê·  ìœ ì‚¬ë„**: {summary.get('average_similarity', 0):.3f}",
        f"- **ìœ ì‚¬ë„ ë²”ìœ„**: {summary.get('similarity_range', [0, 0])[0]:.3f} ~ {summary.get('similarity_range', [0, 0])[1]:.3f}",
    ])
    
    if summary.get('most_similar_pair'):
        report_lines.append(f"- **ê°€ì¥ ìœ ì‚¬í•œ ìŒ**: {summary['most_similar_pair'].replace('_vs_', ' vs ')}")
    if summary.get('least_similar_pair'):
        report_lines.append(f"- **ê°€ì¥ ë‹¤ë¥¸ ìŒ**: {summary['least_similar_pair'].replace('_vs_', ' vs ')}")
    
    report_lines.extend([
        "",
        "## ğŸš€ ê¶Œì¥ì‚¬í•­",
        "",
        "### ì‹œë‚˜ë¦¬ì˜¤ë³„ íŠ¹ì„±"
    ])
    
    # ì‹œë‚˜ë¦¬ì˜¤ë³„ ë¶„ì„
    scenario_analysis = {
        'A_deep_ocean': "ê¹Šì€ ë°”ë‹¤ í™˜ê²½ - ë‚®ì€ ë…¸ì´ì¦ˆ, ë†’ì€ ê¸°ë¢° ê°€ì‹œì„±",
        'B_shallow_coastal': "ì–•ì€ ì—°ì•ˆ í™˜ê²½ - ë†’ì€ ë…¸ì´ì¦ˆ, ë³µì¡í•œ í…ìŠ¤ì²˜", 
        'C_medium_depth': "ì¤‘ê°„ ê¹Šì´ í™˜ê²½ - ê· í˜•ì¡íŒ íŠ¹ì„±",
        'D_high_current': "ê°•í•œ í•´ë¥˜ í™˜ê²½ - ë™ì  ì™œê³¡, ë‚®ì€ ê¸°ë¢° ê°€ì‹œì„±",
        'E_sandy_rocky': "ëª¨ë˜/ì•”ì´ˆ í™˜ê²½ - ë†’ì€ í…ìŠ¤ì²˜ ë³µì¡ë„"
    }
    
    for scenario, description in scenario_analysis.items():
        if scenario in quality_metrics:
            metrics = quality_metrics[scenario]
            report_lines.append(f"- **{scenario}**: {description}")
            report_lines.append(f"  - í…ìŠ¤ì²˜ ë³µì¡ë„: {metrics['texture_complexity']:.4f}")
            report_lines.append(f"  - ëŒ€ë¹„ë„: {metrics['contrast_ratio']:.3f}")
            report_lines.append(f"  - ì—”íŠ¸ë¡œí”¼: {metrics['entropy']:.3f}")
    
    report_lines.extend([
        "",
        "### ëª¨ë¸ í›ˆë ¨ ê¶Œì¥ì‚¬í•­",
        "",
        "1. **ë‹¤ì–‘ì„± í™•ë³´**: ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì¡°í•©í•˜ì—¬ ê°•ê±´í•œ ëª¨ë¸ êµ¬ì¶•",
        "2. **ê· í˜• ì¡°ì •**: ê° í™˜ê²½ë³„ ìƒ˜í”Œ ë¹„ìœ¨ì„ ì‹¤ì œ ìš´ìš© í™˜ê²½ì— ë§ê²Œ ì¡°ì •",
        "3. **ì ì§„ì  í›ˆë ¨**: ë‹¨ìˆœí•œ í™˜ê²½(ê¹Šì€ ë°”ë‹¤)ë¶€í„° ë³µì¡í•œ í™˜ê²½(ì—°ì•ˆ)ìœ¼ë¡œ ì ì§„ì  í•™ìŠµ",
        "4. **ì „ì´ í•™ìŠµ**: ì‹œë‚˜ë¦¬ì˜¤ê°„ ì§€ì‹ ì „ì´ë¥¼ í†µí•œ íš¨ìœ¨ì  í•™ìŠµ"
    ])
    
    return "\n".join(report_lines)


def main():
    """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
    logger.info("ì‹¤ë°ì´í„°ì™€ ëª¨ì˜ë°ì´í„° ë¶„í¬ ë¹„êµ ë¶„ì„ ì‹œì‘")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path("data/results/data_comparison")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. ë°ì´í„°ì…‹ ìƒì„±
    logger.info("\n" + "="*50)
    logger.info("1. ë°ì´í„°ì…‹ ìƒì„±")
    logger.info("="*50)
    
    datasets = generate_scenario_comparison_datasets()
    
    # 2. ë¶„í¬ ë¶„ì„
    logger.info("\n" + "="*50)
    logger.info("2. ë¶„í¬ íŠ¹ì„± ë¶„ì„")
    logger.info("="*50)
    
    analyzer = DataDistributionAnalyzer()
    analysis_results = analyzer.analyze_dataset_collection(datasets)
    
    # 3. í’ˆì§ˆ ì§€í‘œ ë¶„ì„
    logger.info("\n" + "="*50)
    logger.info("3. ë°ì´í„° í’ˆì§ˆ ì§€í‘œ ë¶„ì„")
    logger.info("="*50)
    
    quality_metrics = analyze_data_quality_metrics(datasets)
    
    # 4. ê²°ê³¼ ì €ì¥
    logger.info("\n" + "="*50)
    logger.info("4. ê²°ê³¼ ì €ì¥")
    logger.info("="*50)
    
    # JSON ê²°ê³¼ ì €ì¥
    complete_results = {
        'distribution_analysis': analysis_results,
        'quality_metrics': quality_metrics,
        'metadata': {
            'analysis_type': 'real_vs_synthetic_comparison',
            'datasets_analyzed': list(datasets.keys()),
            'total_samples': {name: data.shape[0] for name, data in datasets.items()}
        }
    }
    
    # json_safe_convertëŠ” ì´ë¯¸ ìœ„ì—ì„œ importë¨
    
    with open(output_dir / 'data_comparison_results.json', 'w', encoding='utf-8') as f:
        json.dump(json_safe_convert(complete_results), f, ensure_ascii=False, indent=2)
    
    # í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
    report_text = create_distribution_report(analysis_results, quality_metrics)
    
    with open(output_dir / 'data_comparison_report.md', 'w', encoding='utf-8') as f:
        f.write(report_text)
    
    # 5. ìš”ì•½ ì¶œë ¥
    logger.info("\n" + "="*50)
    logger.info("5. ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    logger.info("="*50)
    
    summary = analysis_results.get('summary', {})
    
    logger.info(f"ë¶„ì„ ë°ì´í„°ì…‹: {len(datasets)}ê°œ")
    for name in datasets.keys():
        logger.info(f"  - {name}: {datasets[name].shape[0]}ê°œ ìƒ˜í”Œ")
    
    logger.info(f"\ní‰ê·  ìœ ì‚¬ë„ ì ìˆ˜: {summary.get('average_similarity', 0):.3f}")
    logger.info(f"ìœ ì‚¬ë„ ë²”ìœ„: {summary.get('similarity_range', [0, 0])[0]:.3f} ~ {summary.get('similarity_range', [0, 0])[1]:.3f}")
    
    if summary.get('most_similar_pair'):
        logger.info(f"ê°€ì¥ ìœ ì‚¬í•œ ìŒ: {summary['most_similar_pair']}")
    if summary.get('least_similar_pair'):
        logger.info(f"ê°€ì¥ ë‹¤ë¥¸ ìŒ: {summary['least_similar_pair']}")
    
    # í’ˆì§ˆ ì§€í‘œ ìš”ì•½
    logger.info(f"\në°ì´í„° í’ˆì§ˆ ì§€í‘œ:")
    for name, metrics in quality_metrics.items():
        logger.info(f"  {name}:")
        logger.info(f"    ë™ì ë²”ìœ„: {metrics['dynamic_range']:.3f}")
        logger.info(f"    í…ìŠ¤ì²˜ë³µì¡ë„: {metrics['texture_complexity']:.4f}")
        logger.info(f"    ì—”íŠ¸ë¡œí”¼: {metrics['entropy']:.3f}")
    
    logger.info(f"\nê²°ê³¼ê°€ {output_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
    logger.info(f"  - JSON: data_comparison_results.json")
    logger.info(f"  - ë¦¬í¬íŠ¸: data_comparison_report.md")
    
    return complete_results


if __name__ == "__main__":
    main()