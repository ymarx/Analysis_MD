#!/usr/bin/env python3
"""
íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸

ë§¤í•‘ëœ ê°ì²´ ìœ„ì¹˜ì—ì„œ ë‹¤ì–‘í•œ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì—¬
ê¸°ë¬¼ íƒì§€ë¥¼ ìœ„í•œ ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
"""

import sys
import numpy as np
import pandas as pd
import cv2
import json
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import logging
import matplotlib.pyplot as plt
from skimage.feature import hog, local_binary_pattern
from skimage.filters import gabor
from skimage import measure
import warnings

warnings.filterwarnings('ignore')

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

# ê¸°ì¡´ ëª¨ë“ˆ ì„í¬íŠ¸
from config.paths import path_manager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class FeatureExtractionPipeline:
    """íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        self.datasets_path = path_manager.datasets
        self.output_path = path_manager.processed_data
        self.figures_path = path_manager.figures
        
        # ë°ì´í„° êµ¬ì¡°
        self.annotation_image = None
        self.coordinate_mappings = []
        self.extracted_features = []
        
        logger.info("íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_annotation_image(self) -> bool:
        """ì–´ë…¸í…Œì´ì…˜ ì´ë¯¸ì§€ ë¡œë“œ"""
        annotation_file = self.datasets_path / 'PH_annotation.png'
        
        try:
            image = cv2.imread(str(annotation_file))
            if image is not None:
                # RGBë¡œ ë³€í™˜í•˜ê³  ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë„ ì¤€ë¹„
                self.annotation_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                self.annotation_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                logger.info(f"ì–´ë…¸í…Œì´ì…˜ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {self.annotation_image.shape}")
                return True
            else:
                logger.error("ì–´ë…¸í…Œì´ì…˜ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"ì–´ë…¸í…Œì´ì…˜ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def load_coordinate_mappings(self) -> bool:
        """ì¢Œí‘œ ë§¤í•‘ ì •ë³´ ë¡œë“œ"""
        mapping_file = self.output_path / 'coordinate_mappings' / 'pixel_gps_mappings.json'
        
        try:
            with open(mapping_file, 'r') as f:
                self.coordinate_mappings = json.load(f)
            
            logger.info(f"ì¢Œí‘œ ë§¤í•‘ ë¡œë“œ ì™„ë£Œ: {len(self.coordinate_mappings)}ê°œ")
            return True
            
        except Exception as e:
            logger.error(f"ì¢Œí‘œ ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def extract_roi_patches(self, patch_size: Tuple[int, int] = (64, 64)) -> List[Dict]:
        """ê´€ì‹¬ ì˜ì—­(ROI) íŒ¨ì¹˜ ì¶”ì¶œ"""
        patches = []
        
        try:
            for mapping in self.coordinate_mappings:
                bbox = mapping['bbox']
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¤‘ì‹¬ì—ì„œ íŒ¨ì¹˜ ì¶”ì¶œ
                center_x = mapping['pixel_x']
                center_y = mapping['pixel_y']
                
                # íŒ¨ì¹˜ í¬ê¸°ì˜ ì ˆë°˜
                half_w, half_h = patch_size[0] // 2, patch_size[1] // 2
                
                # íŒ¨ì¹˜ ì¢Œí‘œ ê³„ì‚°
                x1 = max(0, center_x - half_w)
                y1 = max(0, center_y - half_h)
                x2 = min(self.annotation_image.shape[1], center_x + half_w)
                y2 = min(self.annotation_image.shape[0], center_y + half_h)
                
                # íŒ¨ì¹˜ ì¶”ì¶œ (RGBì™€ ê·¸ë ˆì´ìŠ¤ì¼€ì¼)
                rgb_patch = self.annotation_image[y1:y2, x1:x2]
                gray_patch = self.annotation_gray[y1:y2, x1:x2]
                
                # íŒ¨ì¹˜ë¥¼ ì§€ì •ëœ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                if rgb_patch.shape[:2] != patch_size:
                    rgb_patch = cv2.resize(rgb_patch, patch_size)
                    gray_patch = cv2.resize(gray_patch, patch_size)
                
                patch_data = {
                    'object_id': mapping['object_id'],
                    'gps_point_id': mapping['gps_point_id'],
                    'center_coords': (center_x, center_y),
                    'patch_coords': (x1, y1, x2, y2),
                    'rgb_patch': rgb_patch,
                    'gray_patch': gray_patch,
                    'patch_size': patch_size,
                    'latitude': mapping['latitude'],
                    'longitude': mapping['longitude']
                }
                
                patches.append(patch_data)
            
            logger.info(f"ROI íŒ¨ì¹˜ ì¶”ì¶œ ì™„ë£Œ: {len(patches)}ê°œ ({patch_size[0]}x{patch_size[1]})")
            return patches
            
        except Exception as e:
            logger.error(f"ROI íŒ¨ì¹˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def extract_hog_features(self, gray_patch: np.ndarray) -> np.ndarray:
        """HOG íŠ¹ì§• ì¶”ì¶œ"""
        try:
            # HOG íŒŒë¼ë¯¸í„°
            orientations = 9
            pixels_per_cell = (8, 8)
            cells_per_block = (2, 2)
            
            features = hog(
                gray_patch,
                orientations=orientations,
                pixels_per_cell=pixels_per_cell,
                cells_per_block=cells_per_block,
                block_norm='L2-Hys',
                feature_vector=True
            )
            
            return features
            
        except Exception as e:
            logger.error(f"HOG íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return np.array([])
    
    def extract_lbp_features(self, gray_patch: np.ndarray) -> np.ndarray:
        """LBP íŠ¹ì§• ì¶”ì¶œ"""
        try:
            # LBP íŒŒë¼ë¯¸í„°
            radius = 3
            n_points = 8 * radius
            method = 'uniform'
            
            lbp = local_binary_pattern(gray_patch, n_points, radius, method)
            
            # LBP íˆìŠ¤í† ê·¸ë¨ ê³„ì‚°
            n_bins = n_points + 2  # uniform patterns + non-uniform
            hist, _ = np.histogram(lbp, bins=n_bins, range=(0, n_bins), density=True)
            
            return hist
            
        except Exception as e:
            logger.error(f"LBP íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return np.array([])
    
    def extract_gabor_features(self, gray_patch: np.ndarray) -> np.ndarray:
        """Gabor í•„í„° íŠ¹ì§• ì¶”ì¶œ"""
        try:
            features = []
            
            # ë‹¤ì–‘í•œ ì£¼íŒŒìˆ˜ì™€ ê°ë„ë¡œ Gabor í•„í„° ì ìš©
            frequencies = [0.1, 0.3, 0.5]
            angles = [0, 45, 90, 135]
            
            for freq in frequencies:
                for angle in angles:
                    # ê°ë„ë¥¼ ë¼ë””ì•ˆìœ¼ë¡œ ë³€í™˜
                    theta = np.deg2rad(angle)
                    
                    # Gabor í•„í„° ì ìš©
                    filt_real, filt_imag = gabor(gray_patch, frequency=freq, theta=theta)
                    
                    # ì‘ë‹µì˜ í†µê³„ì  íŠ¹ì§• ì¶”ì¶œ
                    features.extend([
                        np.mean(filt_real),
                        np.std(filt_real),
                        np.mean(filt_imag),
                        np.std(filt_imag)
                    ])
            
            return np.array(features)
            
        except Exception as e:
            logger.error(f"Gabor íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return np.array([])
    
    def extract_texture_features(self, gray_patch: np.ndarray) -> np.ndarray:
        """í…ìŠ¤ì²˜ í†µê³„ íŠ¹ì§• ì¶”ì¶œ"""
        try:
            features = []
            
            # ê¸°ë³¸ í†µê³„ íŠ¹ì§•
            features.extend([
                np.mean(gray_patch),
                np.std(gray_patch),
                np.var(gray_patch),
                np.min(gray_patch),
                np.max(gray_patch)
            ])
            
            # GLCM ê¸°ë°˜ íŠ¹ì§• (ê°„ë‹¨í™”ëœ ë²„ì „)
            # íˆìŠ¤í† ê·¸ë¨ íŠ¹ì§•
            hist, _ = np.histogram(gray_patch, bins=16, range=(0, 256), density=True)
            features.extend([
                np.sum(hist * np.arange(16)),  # í‰ê·  ê·¸ë ˆì´ ë ˆë²¨
                np.sum(hist * (np.arange(16) ** 2)),  # ë¶„ì‚°
                -np.sum(hist * np.log(hist + 1e-10))  # ì—”íŠ¸ë¡œí”¼
            ])
            
            return np.array(features)
            
        except Exception as e:
            logger.error(f"í…ìŠ¤ì²˜ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return np.array([])
    
    def extract_geometric_features(self, patch_data: Dict) -> np.ndarray:
        """ê¸°í•˜í•™ì  íŠ¹ì§• ì¶”ì¶œ"""
        try:
            bbox = patch_data['patch_coords']
            gray_patch = patch_data['gray_patch']
            
            # ë°”ìš´ë”© ë°•ìŠ¤ íŠ¹ì§•
            width = bbox[2] - bbox[0]
            height = bbox[3] - bbox[1]
            area = width * height
            aspect_ratio = width / height if height > 0 else 0
            
            # ì´ì§„í™”ëœ ì´ë¯¸ì§€ì—ì„œ ëª¨ë©˜íŠ¸ ê³„ì‚°
            _, binary = cv2.threshold(gray_patch, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # ì—°ê²°ëœ ì»´í¬ë„ŒíŠ¸ ë¶„ì„
            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if contours:
                # ê°€ì¥ í° ì»¨íˆ¬ì–´
                largest_contour = max(contours, key=cv2.contourArea)
                
                # ì»¨íˆ¬ì–´ íŠ¹ì§•
                contour_area = cv2.contourArea(largest_contour)
                perimeter = cv2.arcLength(largest_contour, True)
                compactness = (perimeter ** 2) / (4 * np.pi * contour_area) if contour_area > 0 else 0
                
                # ë°”ìš´ë”© ë°•ìŠ¤
                x, y, w, h = cv2.boundingRect(largest_contour)
                extent = contour_area / (w * h) if w * h > 0 else 0
                
                features = [
                    width, height, area, aspect_ratio,
                    contour_area, perimeter, compactness, extent
                ]
            else:
                features = [width, height, area, aspect_ratio, 0, 0, 0, 0]
            
            return np.array(features)
            
        except Exception as e:
            logger.error(f"ê¸°í•˜í•™ì  íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return np.array([0] * 8)
    
    def extract_all_features(self, patches: List[Dict]) -> List[Dict]:
        """ëª¨ë“  íŠ¹ì§•ì„ ì¢…í•©ì ìœ¼ë¡œ ì¶”ì¶œ"""
        feature_data = []
        
        for i, patch_data in enumerate(patches):
            try:
                gray_patch = patch_data['gray_patch']
                
                # ê° ì¢…ë¥˜ë³„ íŠ¹ì§• ì¶”ì¶œ
                hog_features = self.extract_hog_features(gray_patch)
                lbp_features = self.extract_lbp_features(gray_patch)
                gabor_features = self.extract_gabor_features(gray_patch)
                texture_features = self.extract_texture_features(gray_patch)
                geometric_features = self.extract_geometric_features(patch_data)
                
                # íŠ¹ì§• ë²¡í„° ê²°í•©
                combined_features = np.concatenate([
                    hog_features,
                    lbp_features,
                    gabor_features,
                    texture_features,
                    geometric_features
                ])
                
                feature_record = {
                    'object_id': patch_data['object_id'],
                    'gps_point_id': patch_data['gps_point_id'],
                    'latitude': patch_data['latitude'],
                    'longitude': patch_data['longitude'],
                    'center_coords': patch_data['center_coords'],
                    'features': combined_features.tolist(),
                    'feature_dimensions': {
                        'hog': len(hog_features),
                        'lbp': len(lbp_features),
                        'gabor': len(gabor_features),
                        'texture': len(texture_features),
                        'geometric': len(geometric_features),
                        'total': len(combined_features)
                    }
                }
                
                feature_data.append(feature_record)
                
                if (i + 1) % 10 == 0:
                    logger.info(f"íŠ¹ì§• ì¶”ì¶œ ì§„í–‰: {i + 1}/{len(patches)}")
                
            except Exception as e:
                logger.error(f"ê°ì²´ {patch_data['object_id']} íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        logger.info(f"ì „ì²´ íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ: {len(feature_data)}ê°œ ê°ì²´")
        
        if feature_data:
            total_dims = feature_data[0]['feature_dimensions']['total']
            logger.info(f"íŠ¹ì§• ë²¡í„° ì°¨ì›: {total_dims}ì°¨ì›")
        
        return feature_data
    
    def save_features(self, feature_data: List[Dict]) -> bool:
        """ì¶”ì¶œëœ íŠ¹ì§•ì„ ì €ì¥"""
        try:
            features_dir = self.output_path / 'features'
            features_dir.mkdir(exist_ok=True)
            
            # JSON í˜•íƒœë¡œ ì €ì¥
            features_file = features_dir / 'extracted_features.json'
            with open(features_file, 'w') as f:
                json.dump(feature_data, f, indent=2, ensure_ascii=False)
            
            # CSV í˜•íƒœë¡œë„ ì €ì¥ (ë©”íƒ€ë°ì´í„° + íŠ¹ì§• ì¼ë¶€)
            csv_data = []
            for record in feature_data:
                row = {
                    'object_id': record['object_id'],
                    'gps_point_id': record['gps_point_id'],
                    'latitude': record['latitude'],
                    'longitude': record['longitude'],
                    'center_x': record['center_coords'][0],
                    'center_y': record['center_coords'][1],
                    'feature_dim_total': record['feature_dimensions']['total'],
                    'feature_dim_hog': record['feature_dimensions']['hog'],
                    'feature_dim_lbp': record['feature_dimensions']['lbp'],
                    'feature_dim_gabor': record['feature_dimensions']['gabor'],
                    'feature_dim_texture': record['feature_dimensions']['texture'],
                    'feature_dim_geometric': record['feature_dimensions']['geometric']
                }
                csv_data.append(row)
            
            df = pd.DataFrame(csv_data)
            csv_file = features_dir / 'feature_metadata.csv'
            df.to_csv(csv_file, index=False, encoding='utf-8-sig')
            
            # NumPy ë°°ì—´ë¡œ íŠ¹ì§• ë²¡í„°ë§Œ ì €ì¥ (ML í•™ìŠµìš©)
            feature_matrix = np.array([record['features'] for record in feature_data])
            labels = np.array([record['object_id'] for record in feature_data])
            
            np.savez_compressed(
                features_dir / 'feature_matrix.npz',
                features=feature_matrix,
                labels=labels,
                metadata=csv_data
            )
            
            logger.info(f"íŠ¹ì§• ë°ì´í„° ì €ì¥ ì™„ë£Œ: {features_dir}")
            logger.info(f"íŠ¹ì§• ë§¤íŠ¸ë¦­ìŠ¤ í¬ê¸°: {feature_matrix.shape}")
            
            return True
            
        except Exception as e:
            logger.error(f"íŠ¹ì§• ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def create_feature_visualization(self, feature_data: List[Dict], patches: List[Dict]) -> bool:
        """íŠ¹ì§• ì¶”ì¶œ ê²°ê³¼ ì‹œê°í™”"""
        try:
            viz_dir = self.figures_path / 'feature_extraction'
            viz_dir.mkdir(exist_ok=True)
            
            # 1. íŒ¨ì¹˜ ìƒ˜í”Œ ì‹œê°í™”
            self._visualize_patch_samples(patches, viz_dir)
            
            # 2. íŠ¹ì§• ì°¨ì› ë¶„ì„
            self._visualize_feature_dimensions(feature_data, viz_dir)
            
            # 3. íŠ¹ì§• ë¶„í¬ ë¶„ì„
            self._visualize_feature_distributions(feature_data, viz_dir)
            
            logger.info(f"íŠ¹ì§• ì¶”ì¶œ ì‹œê°í™” ìƒì„± ì™„ë£Œ: {viz_dir}")
            return True
            
        except Exception as e:
            logger.error(f"íŠ¹ì§• ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _visualize_patch_samples(self, patches: List[Dict], output_dir: Path):
        """íŒ¨ì¹˜ ìƒ˜í”Œ ì‹œê°í™”"""
        fig, axes = plt.subplots(4, 6, figsize=(18, 12))
        fig.suptitle('ROI Patch Samples', fontsize=16)
        
        sample_indices = np.linspace(0, len(patches)-1, 24, dtype=int)
        
        for i, idx in enumerate(sample_indices):
            row, col = i // 6, i % 6
            
            patch = patches[idx]
            axes[row, col].imshow(patch['rgb_patch'])
            axes[row, col].set_title(f"ID:{patch['object_id']} GPS:{patch['gps_point_id']}", fontsize=8)
            axes[row, col].axis('off')
        
        plt.tight_layout()
        plt.savefig(output_dir / 'roi_patch_samples.png', dpi=150, bbox_inches='tight')
        plt.close()
    
    def _visualize_feature_dimensions(self, feature_data: List[Dict], output_dir: Path):
        """íŠ¹ì§• ì°¨ì› ë¶„ì„ ì‹œê°í™”"""
        if not feature_data:
            return
        
        dims = feature_data[0]['feature_dimensions']
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # íŠ¹ì§• íƒ€ì…ë³„ ì°¨ì› ìˆ˜
        feature_types = list(dims.keys())[:-1]  # 'total' ì œì™¸
        dim_counts = [dims[ft] for ft in feature_types]
        
        colors = ['skyblue', 'lightgreen', 'salmon', 'gold', 'lightcoral']
        bars = ax1.bar(feature_types, dim_counts, color=colors)
        ax1.set_title('Feature Dimensions by Type', fontsize=14)
        ax1.set_ylabel('Number of Dimensions')
        ax1.tick_params(axis='x', rotation=45)
        
        # ê° ë§‰ëŒ€ì— ê°’ í‘œì‹œ
        for bar, count in zip(bars, dim_counts):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                    f'{count}', ha='center', va='bottom')
        
        # íŒŒì´ ì°¨íŠ¸
        ax2.pie(dim_counts, labels=feature_types, colors=colors, autopct='%1.1f%%')
        ax2.set_title('Feature Dimension Distribution', fontsize=14)
        
        plt.tight_layout()
        plt.savefig(output_dir / 'feature_dimensions.png', dpi=150, bbox_inches='tight')
        plt.close()
    
    def _visualize_feature_distributions(self, feature_data: List[Dict], output_dir: Path):
        """íŠ¹ì§• ë¶„í¬ ì‹œê°í™”"""
        if not feature_data:
            return
        
        # íŠ¹ì§• ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì„±
        feature_matrix = np.array([record['features'] for record in feature_data])
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. íŠ¹ì§• í‰ê· ê°’ ë¶„í¬
        feature_means = np.mean(feature_matrix, axis=0)
        axes[0, 0].hist(feature_means, bins=30, alpha=0.7, color='blue')
        axes[0, 0].set_title('Distribution of Feature Means')
        axes[0, 0].set_xlabel('Feature Mean Value')
        axes[0, 0].set_ylabel('Frequency')
        
        # 2. íŠ¹ì§• í‘œì¤€í¸ì°¨ ë¶„í¬
        feature_stds = np.std(feature_matrix, axis=0)
        axes[0, 1].hist(feature_stds, bins=30, alpha=0.7, color='green')
        axes[0, 1].set_title('Distribution of Feature Standard Deviations')
        axes[0, 1].set_xlabel('Feature Std Value')
        axes[0, 1].set_ylabel('Frequency')
        
        # 3. ìƒ˜í”Œë³„ íŠ¹ì§• ë²¡í„° í¬ê¸°
        feature_norms = np.linalg.norm(feature_matrix, axis=1)
        axes[1, 0].hist(feature_norms, bins=20, alpha=0.7, color='red')
        axes[1, 0].set_title('Distribution of Feature Vector Norms')
        axes[1, 0].set_xlabel('L2 Norm')
        axes[1, 0].set_ylabel('Frequency')
        
        # 4. íŠ¹ì§• ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ (ìƒ˜í”Œë§)
        if feature_matrix.shape[1] > 50:
            # ë„ˆë¬´ ë§ì€ íŠ¹ì§•ì´ ìˆìœ¼ë©´ ìƒ˜í”Œë§
            sample_indices = np.random.choice(feature_matrix.shape[1], 50, replace=False)
            sample_features = feature_matrix[:, sample_indices]
        else:
            sample_features = feature_matrix
        
        correlation_matrix = np.corrcoef(sample_features.T)
        im = axes[1, 1].imshow(correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1)
        axes[1, 1].set_title('Feature Correlation Matrix (Sample)')
        plt.colorbar(im, ax=axes[1, 1])
        
        plt.tight_layout()
        plt.savefig(output_dir / 'feature_distributions.png', dpi=150, bbox_inches='tight')
        plt.close()
    
    def run_complete_pipeline(self, patch_size: Tuple[int, int] = (64, 64)) -> bool:
        """ì „ì²´ íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("=== íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘ ===")
        
        try:
            # 1. ë°ì´í„° ë¡œë“œ
            logger.info("1. í•„ìš” ë°ì´í„° ë¡œë“œ")
            if not self.load_annotation_image():
                return False
                
            if not self.load_coordinate_mappings():
                return False
            
            # 2. ROI íŒ¨ì¹˜ ì¶”ì¶œ
            logger.info("2. ROI íŒ¨ì¹˜ ì¶”ì¶œ")
            patches = self.extract_roi_patches(patch_size)
            if not patches:
                logger.error("íŒ¨ì¹˜ ì¶”ì¶œ ì‹¤íŒ¨")
                return False
            
            # 3. íŠ¹ì§• ì¶”ì¶œ
            logger.info("3. íŠ¹ì§• ì¶”ì¶œ")
            feature_data = self.extract_all_features(patches)
            if not feature_data:
                logger.error("íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨")
                return False
            
            # 4. íŠ¹ì§• ì €ì¥
            logger.info("4. íŠ¹ì§• ë°ì´í„° ì €ì¥")
            if not self.save_features(feature_data):
                return False
            
            # 5. ì‹œê°í™” ìƒì„±
            logger.info("5. íŠ¹ì§• ì¶”ì¶œ ì‹œê°í™”")
            if not self.create_feature_visualization(feature_data, patches):
                return False
            
            logger.info("=== íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ ===")
            self._print_summary(feature_data)
            
            return True
            
        except Exception as e:
            logger.error(f"íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return False
    
    def _print_summary(self, feature_data: List[Dict]):
        """íŠ¹ì§• ì¶”ì¶œ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        
        if feature_data:
            dims = feature_data[0]['feature_dimensions']
            feature_matrix = np.array([record['features'] for record in feature_data])
            
            print(f"ğŸ¯ ì²˜ë¦¬ëœ ê°ì²´ ìˆ˜: {len(feature_data)}ê°œ")
            print(f"ğŸ“ ì´ íŠ¹ì§• ì°¨ì›: {dims['total']}ì°¨ì›")
            print(f"   - HOG: {dims['hog']}ì°¨ì›")
            print(f"   - LBP: {dims['lbp']}ì°¨ì›")
            print(f"   - Gabor: {dims['gabor']}ì°¨ì›")
            print(f"   - Texture: {dims['texture']}ì°¨ì›")
            print(f"   - Geometric: {dims['geometric']}ì°¨ì›")
            
            print(f"ğŸ“Š íŠ¹ì§• ë§¤íŠ¸ë¦­ìŠ¤ í¬ê¸°: {feature_matrix.shape}")
            print(f"ğŸ“ˆ íŠ¹ì§• ê°’ ë²”ìœ„: [{feature_matrix.min():.3f}, {feature_matrix.max():.3f}]")
            print(f"ğŸ“‰ íŠ¹ì§• í‰ê· : {feature_matrix.mean():.3f} Â± {feature_matrix.std():.3f}")
        
        print(f"\nğŸ’¾ ì¶œë ¥ ìœ„ì¹˜:")
        print(f"- íŠ¹ì§• ë°ì´í„°: {self.output_path / 'features'}")
        print(f"- ì‹œê°í™”: {self.figures_path / 'feature_extraction'}")
        
        print("="*60)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    pipeline = FeatureExtractionPipeline()
    
    success = pipeline.run_complete_pipeline(patch_size=(64, 64))
    
    if success:
        print("âœ… íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        return 0
    else:
        print("âŒ íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        return 1


if __name__ == "__main__":
    exit(main())