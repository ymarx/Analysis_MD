#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸

í˜„ì¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê¸°ë³¸ì ì¸ íŠ¹ì§• ì¶”ì¶œ ì„±ëŠ¥ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import sys
import numpy as np
import time
import logging
from pathlib import Path
import json
from datetime import datetime

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def create_simple_sonar_images(num_samples=20):
    """ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜ ì†Œë‚˜ ì´ë¯¸ì§€ ìƒì„±"""
    logger.info(f"ì‹œë®¬ë ˆì´ì…˜ ì†Œë‚˜ ë°ì´í„° ìƒì„±: {num_samples}ê°œ ìƒ˜í”Œ")
    
    np.random.seed(42)
    images = []
    labels = []
    
    # ì–‘ì„± ìƒ˜í”Œ (ê¸°ë¬¼ í¬í•¨)
    for i in range(num_samples // 2):
        # ë² ì´ìŠ¤ ì´ë¯¸ì§€
        image = np.random.normal(0.3, 0.1, (64, 64))
        
        # ê¸°ë¬¼ ì¶”ê°€ (ë°ì€ ì›í˜• ì˜ì—­)
        center_x, center_y = np.random.randint(15, 50), np.random.randint(15, 50)
        radius = np.random.randint(5, 12)
        
        y, x = np.ogrid[:64, :64]
        mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2
        image[mask] = 0.8 + 0.2 * np.random.random()
        
        # ë…¸ì´ì¦ˆ ì¶”ê°€
        image += np.random.normal(0, 0.05, image.shape)
        image = np.clip(image, 0, 1)
        
        images.append(image)
        labels.append(1)
    
    # ìŒì„± ìƒ˜í”Œ (ë°°ê²½ë§Œ)
    for i in range(num_samples - num_samples // 2):
        image = np.random.normal(0.2, 0.08, (64, 64))
        image += np.random.normal(0, 0.03, image.shape)
        image = np.clip(image, 0, 1)
        
        images.append(image)
        labels.append(0)
    
    return images, labels


def test_basic_features():
    """ê¸°ë³¸ì ì¸ íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    logger.info("=== ê¸°ë³¸ íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    images, labels = create_simple_sonar_images(20)
    
    results = {}
    output_dir = Path("data/results/simple_feature_test")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. ê¸°ë³¸ í†µê³„ íŠ¹ì§•
    logger.info("ê¸°ë³¸ í†µê³„ íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸...")
    start_time = time.time()
    
    statistical_features = []
    for image in images:
        features = [
            np.mean(image),          # í‰ê· 
            np.std(image),           # í‘œì¤€í¸ì°¨  
            np.max(image),           # ìµœëŒ€ê°’
            np.min(image),           # ìµœì†Œê°’
            np.median(image),        # ì¤‘ê°„ê°’
            len(np.unique(image)),   # ê³ ìœ ê°’ ê°œìˆ˜
        ]
        
        # íˆìŠ¤í† ê·¸ë¨ íŠ¹ì§•
        hist, _ = np.histogram(image, bins=10, range=(0, 1))
        hist = hist / hist.sum()  # ì •ê·œí™”
        features.extend(hist)
        
        statistical_features.append(features)
    
    stat_time = (time.time() - start_time) * 1000
    
    results['statistical'] = {
        'feature_count': len(statistical_features[0]),
        'extraction_time_ms': stat_time,
        'success_rate': 1.0,
        'description': 'ê¸°ë³¸ í†µê³„ + íˆìŠ¤í† ê·¸ë¨ íŠ¹ì§•'
    }
    
    # 2. ê°„ë‹¨í•œ HOG íŠ¹ì§• (scikit-image ì‚¬ìš©)
    logger.info("ê°„ë‹¨í•œ HOG íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸...")
    
    try:
        from skimage.feature import hog
        from skimage import exposure
        
        start_time = time.time()
        hog_features = []
        
        for image in images:
            # ì´ë¯¸ì§€ ì •ê·œí™”
            normalized = exposure.equalize_adapthist(image)
            
            # HOG íŠ¹ì§• ì¶”ì¶œ
            features = hog(
                normalized,
                orientations=8,
                pixels_per_cell=(8, 8),
                cells_per_block=(2, 2),
                feature_vector=True
            )
            
            hog_features.append(features)
        
        hog_time = (time.time() - start_time) * 1000
        
        results['hog_simple'] = {
            'feature_count': len(hog_features[0]),
            'extraction_time_ms': hog_time,
            'success_rate': 1.0,
            'description': 'ê¸°ë³¸ HOG íŠ¹ì§• (8ë°©í–¥, 8x8ì…€)'
        }
        
    except Exception as e:
        logger.error(f"HOG íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        results['hog_simple'] = {'error': str(e)}
    
    # 3. ê°„ë‹¨í•œ í…ìŠ¤ì²˜ íŠ¹ì§•
    logger.info("ê°„ë‹¨í•œ í…ìŠ¤ì²˜ íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸...")
    
    start_time = time.time()
    texture_features = []
    
    for image in images:
        # ê¸°ìš¸ê¸° ê¸°ë°˜ í…ìŠ¤ì²˜ íŠ¹ì§•
        grad_y, grad_x = np.gradient(image)
        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
        
        features = [
            np.mean(gradient_magnitude),     # í‰ê·  ê¸°ìš¸ê¸° í¬ê¸°
            np.std(gradient_magnitude),      # ê¸°ìš¸ê¸° í¬ê¸° ë¶„ì‚°
            np.max(gradient_magnitude),      # ìµœëŒ€ ê¸°ìš¸ê¸°
            np.sum(gradient_magnitude > np.percentile(gradient_magnitude, 90)) / gradient_magnitude.size,  # ê°•í•œ ì—£ì§€ ë¹„ìœ¨
        ]
        
        # ì§€ì—­ ë¶„ì‚°
        from scipy.ndimage import uniform_filter
        local_mean = uniform_filter(image, size=3)
        local_variance = uniform_filter(image**2, size=3) - local_mean**2
        
        features.extend([
            np.mean(local_variance),         # í‰ê·  ì§€ì—­ ë¶„ì‚°
            np.std(local_variance),          # ì§€ì—­ ë¶„ì‚°ì˜ ë¶„ì‚°
        ])
        
        texture_features.append(features)
    
    texture_time = (time.time() - start_time) * 1000
    
    results['texture_simple'] = {
        'feature_count': len(texture_features[0]),
        'extraction_time_ms': texture_time,
        'success_rate': 1.0,
        'description': 'ê¸°ìš¸ê¸° + ì§€ì—­ ë¶„ì‚° ê¸°ë°˜ í…ìŠ¤ì²˜'
    }
    
    # 4. íŠ¹ì§• í’ˆì§ˆ í‰ê°€
    logger.info("íŠ¹ì§• í’ˆì§ˆ í‰ê°€...")
    
    all_features = {
        'statistical': np.array(statistical_features),
        'texture_simple': np.array(texture_features)
    }
    
    if 'hog_simple' in results and 'error' not in results['hog_simple']:
        all_features['hog_simple'] = np.array(hog_features)
    
    # ê° íŠ¹ì§•ë³„ ë¶„ë¥˜ ì„±ëŠ¥ ê°„ë‹¨ í‰ê°€
    for feature_name, feature_matrix in all_features.items():
        try:
            # ê°„ë‹¨í•œ ë¶„ë¥˜ ì„±ëŠ¥ ì¸¡ì •
            from sklearn.ensemble import RandomForestClassifier
            from sklearn.model_selection import cross_val_score
            
            if len(feature_matrix) >= 10:  # ìµœì†Œ ìƒ˜í”Œ ìˆ˜ í™•ì¸
                rf = RandomForestClassifier(n_estimators=10, random_state=42)
                scores = cross_val_score(rf, feature_matrix, labels, cv=3)
                
                results[feature_name]['classification_accuracy'] = np.mean(scores)
                results[feature_name]['accuracy_std'] = np.std(scores)
            
        except Exception as e:
            logger.warning(f"{feature_name} ë¶„ë¥˜ í‰ê°€ ì‹¤íŒ¨: {e}")
    
    # 5. ê²°ê³¼ ì €ì¥
    results['metadata'] = {
        'test_date': datetime.now().isoformat(),
        'num_samples': len(images),
        'positive_samples': sum(labels),
        'negative_samples': len(labels) - sum(labels),
        'image_size': f"{images[0].shape[0]}x{images[0].shape[1]}"
    }
    
    # JSON ì €ì¥
    with open(output_dir / 'simple_feature_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=str)
    
    # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±
    with open(output_dir / 'simple_feature_report.md', 'w', encoding='utf-8') as f:
        f.write("# ê°„ë‹¨í•œ íŠ¹ì§• ì¶”ì¶œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼\n\n")
        f.write(f"**í…ŒìŠ¤íŠ¸ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"**ìƒ˜í”Œ ìˆ˜**: {len(images)}ê°œ (ì–‘ì„±: {sum(labels)}, ìŒì„±: {len(labels) - sum(labels)})\n\n")
        
        f.write("## ğŸ“Š íŠ¹ì§•ë³„ ì„±ëŠ¥ ìš”ì•½\n\n")
        f.write("| íŠ¹ì§• íƒ€ì… | íŠ¹ì§• ìˆ˜ | ì¶”ì¶œ ì‹œê°„(ms) | ë¶„ë¥˜ ì •í™•ë„ | ì„¤ëª… |\n")
        f.write("|-----------|---------|---------------|-------------|------|\n")
        
        for name, result in results.items():
            if name == 'metadata' or 'error' in result:
                continue
                
            feature_count = result.get('feature_count', 0)
            extraction_time = result.get('extraction_time_ms', 0)
            accuracy = result.get('classification_accuracy', 0)
            description = result.get('description', '')
            
            f.write(f"| {name} | {feature_count} | {extraction_time:.2f} | {accuracy:.3f} | {description} |\n")
        
        f.write("\n## ğŸ” ìƒì„¸ ê²°ê³¼\n\n")
        
        for name, result in results.items():
            if name == 'metadata':
                continue
                
            f.write(f"### {name}\n\n")
            
            if 'error' in result:
                f.write(f"âŒ **ì˜¤ë¥˜ ë°œìƒ**: {result['error']}\n\n")
                continue
            
            f.write(f"- **íŠ¹ì§• ê°œìˆ˜**: {result.get('feature_count', 0)}ê°œ\n")
            f.write(f"- **ì¶”ì¶œ ì‹œê°„**: {result.get('extraction_time_ms', 0):.2f}ms\n")
            f.write(f"- **ì„±ê³µë¥ **: {result.get('success_rate', 0)*100:.1f}%\n")
            
            if 'classification_accuracy' in result:
                f.write(f"- **ë¶„ë¥˜ ì •í™•ë„**: {result['classification_accuracy']:.3f} Â± {result.get('accuracy_std', 0):.3f}\n")
            
            f.write(f"- **ì„¤ëª…**: {result.get('description', '')}\n\n")
        
        f.write("## ğŸ’¡ ê²°ë¡ \n\n")
        
        # ìµœê³  ì„±ëŠ¥ íŠ¹ì§• ì°¾ê¸°
        best_feature = None
        best_accuracy = 0
        
        for name, result in results.items():
            if 'classification_accuracy' in result:
                accuracy = result['classification_accuracy']
                if accuracy > best_accuracy:
                    best_accuracy = accuracy
                    best_feature = name
        
        if best_feature:
            f.write(f"ğŸ† **ìµœê³  ì„±ëŠ¥**: {best_feature} (ì •í™•ë„: {best_accuracy:.3f})\n")
        
        # ìµœê³  ì†ë„
        fastest_feature = None
        fastest_time = float('inf')
        
        for name, result in results.items():
            if 'extraction_time_ms' in result:
                time_val = result['extraction_time_ms']
                if time_val < fastest_time:
                    fastest_time = time_val
                    fastest_feature = name
        
        if fastest_feature:
            f.write(f"âš¡ **ìµœê³  ì†ë„**: {fastest_feature} ({fastest_time:.2f}ms)\n")
    
    logger.info("=== ê¸°ë³¸ íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ‰ ê°„ë‹¨í•œ íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"ğŸ“Š ê²°ê³¼ ë””ë ‰í† ë¦¬: {output_dir}")
    print(f"ğŸ“ˆ ë¦¬í¬íŠ¸: {output_dir / 'simple_feature_report.md'}")
    print(f"ğŸ” ìƒì„¸ ê²°ê³¼: {output_dir / 'simple_feature_results.json'}")
    
    print("\nğŸ“‹ ìš”ì•½:")
    for name, result in results.items():
        if name == 'metadata' or 'error' in result:
            continue
        
        feature_count = result.get('feature_count', 0)
        extraction_time = result.get('extraction_time_ms', 0)
        accuracy = result.get('classification_accuracy', 0)
        
        print(f"  {name}: {feature_count}ê°œ íŠ¹ì§•, {extraction_time:.1f}ms, ì •í™•ë„ {accuracy:.3f}")


if __name__ == "__main__":
    test_basic_features()