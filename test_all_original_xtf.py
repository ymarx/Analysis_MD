#!/usr/bin/env python3
"""
ì„¸ ê°œì˜ original XTF íŒŒì¼ ì „ì²´ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

datasets í´ë”ì— ìˆëŠ” ëª¨ë“  original XTF íŒŒì¼ì—ì„œ í•‘ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³ 
ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ê²°ê³¼ë¥¼ ì €ì¥/í™•ì¸í•©ë‹ˆë‹¤.
"""

import sys
import numpy as np
import pandas as pd
from pathlib import Path
import logging
import json
import time

# src ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent / 'src'))

from data_processing.xtf_reader import XTFReader
from data_processing.xtf_intensity_extractor import XTFIntensityExtractor

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def find_original_xtf_files():
    """datasets í´ë”ì—ì„œ original .xtf íŒŒì¼ë§Œ ì°¾ê¸°"""
    datasets_path = Path('datasets')
    
    xtf_files = []
    if datasets_path.exists():
        for dataset_dir in datasets_path.iterdir():
            if dataset_dir.is_dir():
                # original í´ë”ì—ì„œ .xtf íŒŒì¼ ì°¾ê¸°
                original_path = dataset_dir / 'original'
                if original_path.exists():
                    for xtf_file in original_path.glob('*.xtf'):
                        xtf_files.append(xtf_file)
    
    return sorted(xtf_files)


def test_xtf_reader(xtf_file_path):
    """XTF Readerë¡œ ë°ì´í„° ì¶”ì¶œ ë° í…ŒìŠ¤íŠ¸"""
    print(f"\n{'='*80}")
    print(f"XTF Reader í…ŒìŠ¤íŠ¸: {xtf_file_path.name}")
    print(f"{'='*80}")
    
    start_time = time.time()
    
    try:
        # XTF Reader ì´ˆê¸°í™” (ì²˜ë¦¬ ì‹œê°„ì„ ìœ„í•´ ì²« 100 pingë§Œ)
        reader = XTFReader(xtf_file_path, max_pings=100)
        
        # íŒŒì¼ ë¡œë“œ
        if not reader.load_file():
            print("âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨")
            return None
        
        print(f"âœ… íŒŒì¼ ë¡œë“œ ì„±ê³µ ({time.time() - start_time:.2f}ì´ˆ)")
        
        # íŒŒì¼ ìš”ì•½ ì •ë³´
        summary = reader.get_summary()
        print(f"\nğŸ“‹ íŒŒì¼ ìš”ì•½:")
        print(f"  - íŒŒì¼ëª…: {summary['filename']}")
        print(f"  - ì´ í•‘ ìˆ˜: {summary['total_pings']}")
        print(f"  - ì†Œë‚˜ ì±„ë„ ìˆ˜: {summary['num_sonar_channels']}")
        print(f"  - ì£¼íŒŒìˆ˜ ì •ë³´: {summary['frequency_info']}")
        print(f"  - ì¢Œí‘œ ë²”ìœ„: {summary['coordinate_bounds']}")
        
        # ping ë°ì´í„° íŒŒì‹±
        ping_start = time.time()
        ping_data = reader.parse_pings()
        print(f"âœ… Ping íŒŒì‹± ì™„ë£Œ: {len(ping_data)}ê°œ ({time.time() - ping_start:.2f}ì´ˆ)")
        
        if len(ping_data) > 0:
            # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ping ì •ë³´
            first_ping = ping_data[0]
            last_ping = ping_data[-1]
            
            print(f"\nğŸ“Š ë°ì´í„° ìƒ˜í”Œ:")
            print(f"  ì²« ë²ˆì§¸ ping:")
            print(f"    - ping_number: {first_ping.ping_number}")
            print(f"    - ì¢Œí‘œ: ({first_ping.latitude:.6f}, {first_ping.longitude:.6f})")
            print(f"    - ë°ì´í„° í¬ê¸°: {len(first_ping.data)}")
            print(f"    - ë°ì´í„° ë²”ìœ„: [{first_ping.data.min():.2f}, {first_ping.data.max():.2f}]")
            
            print(f"  ë§ˆì§€ë§‰ ping:")
            print(f"    - ping_number: {last_ping.ping_number}")
            print(f"    - ì¢Œí‘œ: ({last_ping.latitude:.6f}, {last_ping.longitude:.6f})")
            print(f"    - ë°ì´í„° í¬ê¸°: {len(last_ping.data)}")
            
            # ê°•ë„ ë§¤íŠ¸ë¦­ìŠ¤ ì¶”ì¶œ
            matrix_start = time.time()
            intensity_matrix = reader.extract_intensity_matrix()
            print(f"âœ… ê°•ë„ ë§¤íŠ¸ë¦­ìŠ¤: {intensity_matrix.shape} ({time.time() - matrix_start:.2f}ì´ˆ)")
            
            # ìœ„ì¹˜ ì •ë³´ ë°ì´í„°í”„ë ˆì„
            geo_df = reader.get_georeferenced_data()
            print(f"âœ… ìœ„ì¹˜ ì •ë³´: {len(geo_df)}ê°œ ë ˆì½”ë“œ")
            
            # í†µê³„ ì •ë³´
            print(f"\nğŸ“ˆ í†µê³„:")
            print(f"  - í‰ê·  ê°•ë„: {intensity_matrix.mean():.2f}")
            print(f"  - ê°•ë„ ë²”ìœ„: [{intensity_matrix.min():.2f}, {intensity_matrix.max():.2f}]")
            print(f"  - ìœ„ë„ ë²”ìœ„: [{geo_df['latitude'].min():.6f}, {geo_df['latitude'].max():.6f}]")
            print(f"  - ê²½ë„ ë²”ìœ„: [{geo_df['longitude'].min():.6f}, {geo_df['longitude'].max():.6f}]")
            
            return {
                'reader': reader,
                'ping_data': ping_data,
                'intensity_matrix': intensity_matrix,
                'geo_df': geo_df,
                'processing_time': time.time() - start_time
            }
        else:
            print("âŒ ping ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨")
            return None
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_intensity_extractor(xtf_file_path):
    """Intensity Extractorë¡œ ë°ì´í„° ì¶”ì¶œ ë° í…ŒìŠ¤íŠ¸"""
    print(f"\n{'='*80}")
    print(f"Intensity Extractor í…ŒìŠ¤íŠ¸: {xtf_file_path.name}")
    print(f"{'='*80}")
    
    start_time = time.time()
    
    try:
        extractor = XTFIntensityExtractor()
        
        # ê°•ë„ ë°ì´í„° ì¶”ì¶œ (ì²« 50 pingë§Œ)
        result = extractor.extract_intensity_data(str(xtf_file_path), ping_range=(0, 50))
        
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ ({time.time() - start_time:.2f}ì´ˆ)")
        
        metadata = result['metadata']
        print(f"\nğŸ“‹ ë©”íƒ€ë°ì´í„°:")
        print(f"  - ping ìˆ˜: {metadata.ping_count}")
        print(f"  - ì±„ë„ ìˆ˜: {metadata.channel_count}")
        print(f"  - ì£¼íŒŒìˆ˜: {metadata.frequency}")
        print(f"  - ì‹œê°„ ë²”ìœ„: {metadata.timestamp_range}")
        print(f"  - ì¢Œí‘œ ê²½ê³„: {metadata.coordinate_bounds}")
        
        ping_data = result['ping_data']
        print(f"  - ì‹¤ì œ ì¶”ì¶œëœ ping ìˆ˜: {len(ping_data)}")
        
        if len(ping_data) > 0:
            first_ping = ping_data[0]
            print(f"\nğŸ“Š ì²« ë²ˆì§¸ ping:")
            print(f"  - Port ë°ì´í„°: {len(first_ping.port_intensity)} ìƒ˜í”Œ")
            print(f"  - Starboard ë°ì´í„°: {len(first_ping.starboard_intensity)} ìƒ˜í”Œ")
            print(f"  - ì¢Œí‘œ: ({first_ping.latitude:.6f}, {first_ping.longitude:.6f})")
            
            # ê°•ë„ ì´ë¯¸ì§€ í™•ì¸
            images = result['intensity_images']
            print(f"\nğŸ–¼ï¸ ê°•ë„ ì´ë¯¸ì§€:")
            for img_type, img_array in images.items():
                if img_array.size > 0:
                    print(f"  - {img_type}: {img_array.shape}, ë²”ìœ„: [{img_array.min():.3f}, {img_array.max():.3f}]")
            
            # ë„¤ë¹„ê²Œì´ì…˜ ë°ì´í„° í™•ì¸
            nav_data = result['navigation_data']
            if nav_data:
                print(f"\nğŸ§­ ë„¤ë¹„ê²Œì´ì…˜ ë°ì´í„°:")
                for key, arr in nav_data.items():
                    if len(arr) > 0:
                        print(f"  - {key}: {len(arr)}ê°œ, ë²”ìœ„: [{np.min(arr):.6f}, {np.max(arr):.6f}]")
            
            return result
        else:
            print("âŒ ping ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨")
            return None
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None


def save_test_results(results, output_path):
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    summary = {
        'test_time': time.strftime('%Y-%m-%d %H:%M:%S'),
        'total_files': len(results),
        'successful_files': len([r for r in results if r['success']]),
        'files': []
    }
    
    for result in results:
        file_info = {
            'filename': result['filename'],
            'success': result['success'],
            'processing_time': result.get('processing_time', 0)
        }
        
        if result['success'] and 'reader_result' in result:
            reader_result = result['reader_result']
            file_info.update({
                'ping_count': len(reader_result['ping_data']),
                'matrix_shape': list(reader_result['intensity_matrix'].shape),
                'coordinate_range': {
                    'lat_min': float(reader_result['geo_df']['latitude'].min()),
                    'lat_max': float(reader_result['geo_df']['latitude'].max()),
                    'lon_min': float(reader_result['geo_df']['longitude'].min()),
                    'lon_max': float(reader_result['geo_df']['longitude'].max())
                }
            })
        
        summary['files'].append(file_info)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {output_path}")


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("="*100)
    print("ì„¸ ê°œ original XTF íŒŒì¼ ì „ì²´ í…ŒìŠ¤íŠ¸")
    print("="*100)
    
    # original .xtf íŒŒì¼ ì°¾ê¸°
    xtf_files = find_original_xtf_files()
    
    if not xtf_files:
        print("âŒ datasets í´ë”ì—ì„œ original .xtf íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return
    
    print(f"ë°œê²¬ëœ original .xtf íŒŒì¼: {len(xtf_files)}ê°œ")
    for i, xtf_file in enumerate(xtf_files, 1):
        print(f"  {i}. {xtf_file}")
    
    results = []
    
    for i, xtf_file in enumerate(xtf_files, 1):
        print(f"\n\n{'='*100}")
        print(f"íŒŒì¼ {i}/{len(xtf_files)} ì²˜ë¦¬ ì¤‘")
        print(f"{'='*100}")
        
        start_time = time.time()
        result = {
            'filename': xtf_file.name,
            'filepath': str(xtf_file),
            'success': False
        }
        
        # XTF Reader í…ŒìŠ¤íŠ¸
        reader_result = test_xtf_reader(xtf_file)
        if reader_result:
            result['reader_result'] = reader_result
            result['success'] = True
            
            # Intensity Extractor í…ŒìŠ¤íŠ¸
            extractor_result = test_intensity_extractor(xtf_file)
            if extractor_result:
                result['extractor_result'] = extractor_result
        
        result['processing_time'] = time.time() - start_time
        results.append(result)
        
        print(f"íŒŒì¼ {i} ì²˜ë¦¬ ì™„ë£Œ: {'âœ… ì„±ê³µ' if result['success'] else 'âŒ ì‹¤íŒ¨'} ({result['processing_time']:.2f}ì´ˆ)")
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print(f"\n\n{'='*100}")
    print("ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print(f"{'='*100}")
    
    successful = len([r for r in results if r['success']])
    total_time = sum(r['processing_time'] for r in results)
    
    print(f"ì´ íŒŒì¼ ìˆ˜: {len(results)}")
    print(f"ì„±ê³µí•œ íŒŒì¼: {successful}")
    print(f"ì‹¤íŒ¨í•œ íŒŒì¼: {len(results) - successful}")
    print(f"ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
    
    for result in results:
        status = "âœ…" if result['success'] else "âŒ"
        print(f"  {status} {result['filename']} ({result['processing_time']:.2f}ì´ˆ)")
    
    # ê²°ê³¼ ì €ì¥
    output_path = Path("data/processed/xtf_extracted/test_results.json")
    output_path.parent.mkdir(parents=True, exist_ok=True)
    save_test_results(results, output_path)
    
    print(f"\nğŸ“‚ ì¶”ì¶œëœ ë°ì´í„° í™•ì¸ ìœ„ì¹˜:")
    print(f"  - ë©”ì¸ ë””ë ‰í† ë¦¬: data/processed/xtf_extracted/")
    print(f"  - í…ŒìŠ¤íŠ¸ ê²°ê³¼: {output_path}")
    
    if successful == len(results):
        print("\nğŸ‰ ëª¨ë“  XTF íŒŒì¼ ì²˜ë¦¬ ì„±ê³µ!")
    else:
        print(f"\nâš ï¸  {len(results) - successful}ê°œ íŒŒì¼ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()