#!/usr/bin/env python3
"""
ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

Phase 2ì—ì„œ ê°œë°œí•œ ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œê¸°ë“¤ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
"""

import sys
import numpy as np
import time
import logging
from pathlib import Path
import json
from datetime import datetime
import warnings

warnings.filterwarnings('ignore')

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def create_realistic_sonar_data(num_samples=30):
    """ë” í˜„ì‹¤ì ì¸ ì‹œë®¬ë ˆì´ì…˜ ì†Œë‚˜ ë°ì´í„° ìƒì„±"""
    logger.info(f"í˜„ì‹¤ì ì¸ ì†Œë‚˜ ë°ì´í„° ìƒì„±: {num_samples}ê°œ ìƒ˜í”Œ")
    
    np.random.seed(42)
    images = []
    labels = []
    
    # ì–‘ì„± ìƒ˜í”Œ (ê¸°ë¬¼ í¬í•¨)
    for i in range(num_samples // 2):
        # ë‹¤ì–‘í•œ í•´ì €ë©´ ë°°ê²½
        terrain_type = np.random.choice(['sand', 'mud', 'rock'])
        
        if terrain_type == 'sand':
            base_intensity = 0.4 + 0.2 * np.random.random()
            texture_scale = 0.08
        elif terrain_type == 'mud':
            base_intensity = 0.2 + 0.1 * np.random.random()
            texture_scale = 0.04
        else:  # rock
            base_intensity = 0.3 + 0.3 * np.random.random()
            texture_scale = 0.12
        
        # ë² ì´ìŠ¤ ì´ë¯¸ì§€ ìƒì„±
        image = np.random.normal(base_intensity, texture_scale, (96, 96))
        
        # í…ìŠ¤ì²˜ íŒ¨í„´ ì¶”ê°€
        for _ in range(np.random.randint(3, 8)):
            blob_x = np.random.randint(10, 86)
            blob_y = np.random.randint(10, 86) 
            blob_size = np.random.randint(3, 12)
            
            y, x = np.ogrid[:96, :96]
            blob_mask = (x - blob_x)**2 + (y - blob_y)**2 <= blob_size**2
            
            intensity_change = np.random.uniform(-0.15, 0.15)
            image[blob_mask] += intensity_change
        
        # ê¸°ë¬¼ ì¶”ê°€ - ë‹¤ì–‘í•œ í˜•íƒœ
        object_type = np.random.choice(['circular', 'elongated', 'irregular'])
        
        center_x = np.random.randint(20, 76)
        center_y = np.random.randint(20, 76)
        
        # ë³€ìˆ˜ ì´ˆê¸°í™”
        radius = 10
        radius_x = 6
        radius_y = 10
        
        if object_type == 'circular':
            radius = np.random.randint(6, 15)
            y, x = np.ogrid[:96, :96]
            mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2
            
        elif object_type == 'elongated':
            radius_x = np.random.randint(4, 8)
            radius_y = np.random.randint(10, 20)
            y, x = np.ogrid[:96, :96]
            mask = ((x - center_x) / radius_x)**2 + ((y - center_y) / radius_y)**2 <= 1
            
        else:  # irregular
            base_radius = np.random.randint(6, 12)
            radius = base_radius  # ê·¸ë¦¼ì ê³„ì‚°ìš©
            y, x = np.ogrid[:96, :96]
            base_mask = (x - center_x)**2 + (y - center_y)**2 <= base_radius**2
            
            # ë¶ˆê·œì¹™í•œ í˜•íƒœë¥¼ ìœ„í•œ ë³€í˜•
            noise_mask = np.random.random((96, 96)) > 0.3
            mask = base_mask & noise_mask
        
        # ê¸°ë¬¼ ë°˜ì‚¬ê°•ë„ ì ìš©
        object_intensity = 0.7 + 0.2 * np.random.random()
        image[mask] = object_intensity + np.random.normal(0, 0.05, np.sum(mask))
        
        # ìŒí–¥ ê·¸ë¦¼ì ì¶”ê°€
        shadow_length = np.random.randint(12, 25)
        shadow_start_y = center_y + (radius if object_type == 'circular' else max(radius_x, radius_y)) + 2
        shadow_end_y = min(96, shadow_start_y + shadow_length)
        
        if shadow_end_y < 96:
            shadow_x_start = max(0, center_x - 6)
            shadow_x_end = min(96, center_x + 6)
            
            shadow_intensity = 0.05 + 0.05 * np.random.random()
            image[shadow_start_y:shadow_end_y, shadow_x_start:shadow_x_end] = shadow_intensity
        
        # ì „ì²´ ë…¸ì´ì¦ˆ ë° í´ë¦¬í•‘
        noise = np.random.normal(0, 0.02, image.shape)
        image += noise
        image = np.clip(image, 0, 1)
        
        images.append(image)
        labels.append(1)
    
    # ìŒì„± ìƒ˜í”Œ (ë°°ê²½ë§Œ - ë” ë³µì¡í•œ ë°°ê²½)
    for i in range(num_samples - num_samples // 2):
        terrain_type = np.random.choice(['sand', 'mud', 'rock', 'mixed'])
        
        if terrain_type == 'mixed':
            # í˜¼í•© ì§€í˜•
            image = np.zeros((96, 96))
            
            # ì—¬ëŸ¬ ì§€í˜• íŒ¨ì¹˜ë¥¼ í•©ì„±
            for region in range(3):
                region_type = np.random.choice(['sand', 'mud', 'rock'])
                
                if region_type == 'sand':
                    base = 0.4 + 0.1 * np.random.random()
                    noise_scale = 0.06
                elif region_type == 'mud':
                    base = 0.2 + 0.08 * np.random.random()
                    noise_scale = 0.03
                else:  # rock
                    base = 0.35 + 0.2 * np.random.random()
                    noise_scale = 0.1
                
                # ì˜ì—­ ë§ˆìŠ¤í¬
                region_center_x = np.random.randint(20, 76)
                region_center_y = np.random.randint(20, 76)
                region_radius = np.random.randint(15, 30)
                
                y, x = np.ogrid[:96, :96]
                region_mask = (x - region_center_x)**2 + (y - region_center_y)**2 <= region_radius**2
                
                region_image = np.random.normal(base, noise_scale, (96, 96))
                image[region_mask] = region_image[region_mask]
        
        else:
            # ë‹¨ì¼ ì§€í˜•
            if terrain_type == 'sand':
                base_intensity = 0.4 + 0.15 * np.random.random()
                texture_noise = np.random.normal(0, 0.07, (96, 96))
            elif terrain_type == 'mud':
                base_intensity = 0.25 + 0.1 * np.random.random()
                texture_noise = np.random.normal(0, 0.04, (96, 96))
            else:  # rock
                base_intensity = 0.35 + 0.25 * np.random.random()
                texture_noise = np.random.normal(0, 0.11, (96, 96))
            
            image = np.full((96, 96), base_intensity) + texture_noise
        
        # ìì—°ìŠ¤ëŸ¬ìš´ ì§€í˜• ë³€í™” ë° êµ¬ì¡°ë¬¼ (ê¸°ë¬¼ì´ ì•„ë‹Œ)
        for _ in range(np.random.randint(4, 10)):
            structure_x = np.random.randint(5, 91)
            structure_y = np.random.randint(5, 91)
            structure_size = np.random.randint(3, 8)
            
            y, x = np.ogrid[:96, :96]
            structure_mask = (x - structure_x)**2 + (y - structure_y)**2 <= structure_size**2
            
            intensity_variation = np.random.uniform(-0.08, 0.08)
            image[structure_mask] += intensity_variation
        
        # ì „ì²´ ë…¸ì´ì¦ˆ
        noise = np.random.normal(0, 0.015, image.shape)
        image += noise
        image = np.clip(image, 0, 1)
        
        images.append(image)
        labels.append(0)
    
    # ë°ì´í„° ì„ê¸°
    combined = list(zip(images, labels))
    np.random.shuffle(combined)
    images, labels = zip(*combined)
    
    return list(images), list(labels)


def test_advanced_hog_features(images, labels):
    """ê³ ê¸‰ HOG íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    logger.info("ê³ ê¸‰ HOG íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸...")
    
    try:
        from src.feature_extraction.hog_extractor import MultiScaleHOGExtractor
        
        extractor = MultiScaleHOGExtractor()
        
        start_time = time.time()
        features_list = []
        successful_extractions = 0
        
        for image in images:
            try:
                features = extractor.extract_combined_features(image)
                if len(features) > 0:
                    features_list.append(features)
                    successful_extractions += 1
                else:
                    logger.warning("ë¹ˆ HOG íŠ¹ì§• ë²¡í„°")
            except Exception as e:
                logger.warning(f"HOG ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        extraction_time = (time.time() - start_time) * 1000
        
        if features_list:
            feature_matrix = np.array(features_list)
            
            # ë¶„ë¥˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            try:
                from sklearn.ensemble import RandomForestClassifier
                from sklearn.model_selection import cross_val_score
                
                successful_labels = labels[:len(features_list)]
                rf = RandomForestClassifier(n_estimators=20, random_state=42)
                scores = cross_val_score(rf, feature_matrix, successful_labels, cv=3)
                
                return {
                    'name': 'MultiScale_HOG',
                    'success_rate': successful_extractions / len(images),
                    'feature_count': feature_matrix.shape[1],
                    'extraction_time_ms': extraction_time,
                    'classification_accuracy': np.mean(scores),
                    'accuracy_std': np.std(scores),
                    'description': 'ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ HOG (3ê°€ì§€ ìŠ¤ì¼€ì¼)'
                }
            except Exception as e:
                logger.warning(f"HOG ë¶„ë¥˜ í‰ê°€ ì‹¤íŒ¨: {e}")
                return {
                    'name': 'MultiScale_HOG',
                    'success_rate': successful_extractions / len(images),
                    'feature_count': feature_matrix.shape[1],
                    'extraction_time_ms': extraction_time,
                    'description': 'ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ HOG (3ê°€ì§€ ìŠ¤ì¼€ì¼)',
                    'classification_error': str(e)
                }
        else:
            return {'name': 'MultiScale_HOG', 'error': 'ëª¨ë“  HOG ì¶”ì¶œ ì‹¤íŒ¨'}
            
    except ImportError as e:
        return {'name': 'MultiScale_HOG', 'error': f'ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}'}
    except Exception as e:
        return {'name': 'MultiScale_HOG', 'error': f'HOG í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}'}


def test_advanced_lbp_features(images, labels):
    """ê³ ê¸‰ LBP íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    logger.info("ê³ ê¸‰ LBP íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸...")
    
    try:
        from src.feature_extraction.lbp_extractor import ComprehensiveLBPExtractor
        
        extractor = ComprehensiveLBPExtractor()
        
        start_time = time.time()
        features_list = []
        successful_extractions = 0
        
        for image in images:
            try:
                features = extractor.extract_comprehensive_features(image)
                if len(features) > 0:
                    features_list.append(features)
                    successful_extractions += 1
            except Exception as e:
                logger.warning(f"LBP ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        extraction_time = (time.time() - start_time) * 1000
        
        if features_list:
            feature_matrix = np.array(features_list)
            
            # ë¶„ë¥˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            try:
                from sklearn.ensemble import RandomForestClassifier
                from sklearn.model_selection import cross_val_score
                
                successful_labels = labels[:len(features_list)]
                rf = RandomForestClassifier(n_estimators=20, random_state=42)
                scores = cross_val_score(rf, feature_matrix, successful_labels, cv=3)
                
                return {
                    'name': 'Comprehensive_LBP',
                    'success_rate': successful_extractions / len(images),
                    'feature_count': feature_matrix.shape[1],
                    'extraction_time_ms': extraction_time,
                    'classification_accuracy': np.mean(scores),
                    'accuracy_std': np.std(scores),
                    'description': 'ì¢…í•© LBP (ì§€í˜• ì ì‘í˜• + íšŒì „ ë¶ˆë³€)'
                }
            except Exception as e:
                return {
                    'name': 'Comprehensive_LBP',
                    'success_rate': successful_extractions / len(images),
                    'feature_count': feature_matrix.shape[1],
                    'extraction_time_ms': extraction_time,
                    'description': 'ì¢…í•© LBP (ì§€í˜• ì ì‘í˜• + íšŒì „ ë¶ˆë³€)',
                    'classification_error': str(e)
                }
        else:
            return {'name': 'Comprehensive_LBP', 'error': 'ëª¨ë“  LBP ì¶”ì¶œ ì‹¤íŒ¨'}
            
    except ImportError as e:
        return {'name': 'Comprehensive_LBP', 'error': f'ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}'}
    except Exception as e:
        return {'name': 'Comprehensive_LBP', 'error': f'LBP í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}'}


def test_advanced_gabor_features(images, labels):
    """ê³ ê¸‰ Gabor íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    logger.info("ê³ ê¸‰ Gabor íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸...")
    
    try:
        from src.feature_extraction.gabor_extractor import GaborFeatureExtractor
        
        extractor = GaborFeatureExtractor(n_frequencies=4, n_orientations=6)
        
        start_time = time.time()
        features_list = []
        successful_extractions = 0
        
        for image in images:
            try:
                features = extractor.extract_comprehensive_features(image)
                if len(features) > 0:
                    features_list.append(features)
                    successful_extractions += 1
            except Exception as e:
                logger.warning(f"Gabor ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        extraction_time = (time.time() - start_time) * 1000
        
        if features_list:
            feature_matrix = np.array(features_list)
            
            # ë¶„ë¥˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            try:
                from sklearn.ensemble import RandomForestClassifier
                from sklearn.model_selection import cross_val_score
                
                successful_labels = labels[:len(features_list)]
                rf = RandomForestClassifier(n_estimators=20, random_state=42)
                scores = cross_val_score(rf, feature_matrix, successful_labels, cv=3)
                
                return {
                    'name': 'Advanced_Gabor',
                    'success_rate': successful_extractions / len(images),
                    'feature_count': feature_matrix.shape[1],
                    'extraction_time_ms': extraction_time,
                    'classification_accuracy': np.mean(scores),
                    'accuracy_std': np.std(scores),
                    'description': 'ê³ ê¸‰ Gabor í•„í„° ë±…í¬ (4ì£¼íŒŒìˆ˜ Ã— 6ë°©í–¥)'
                }
            except Exception as e:
                return {
                    'name': 'Advanced_Gabor',
                    'success_rate': successful_extractions / len(images),
                    'feature_count': feature_matrix.shape[1],
                    'extraction_time_ms': extraction_time,
                    'description': 'ê³ ê¸‰ Gabor í•„í„° ë±…í¬ (4ì£¼íŒŒìˆ˜ Ã— 6ë°©í–¥)',
                    'classification_error': str(e)
                }
        else:
            return {'name': 'Advanced_Gabor', 'error': 'ëª¨ë“  Gabor ì¶”ì¶œ ì‹¤íŒ¨'}
            
    except ImportError as e:
        return {'name': 'Advanced_Gabor', 'error': f'ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}'}
    except Exception as e:
        return {'name': 'Advanced_Gabor', 'error': f'Gabor í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}'}


def run_advanced_feature_evaluation():
    """ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰"""
    logger.info("=== ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ ì„±ëŠ¥ í‰ê°€ ì‹œì‘ ===")
    
    output_dir = Path("data/results/advanced_feature_test")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ë” í˜„ì‹¤ì ì¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    images, labels = create_realistic_sonar_data(30)
    
    results = {}
    
    # ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œê¸°ë“¤ í…ŒìŠ¤íŠ¸
    test_functions = [
        test_advanced_hog_features,
        test_advanced_lbp_features,
        test_advanced_gabor_features
    ]
    
    for test_func in test_functions:
        try:
            result = test_func(images, labels)
            results[result['name']] = result
            
            if 'error' not in result:
                logger.info(f"{result['name']} ì™„ë£Œ - "
                          f"ì„±ê³µë¥ : {result.get('success_rate', 0)*100:.1f}%, "
                          f"íŠ¹ì§•ìˆ˜: {result.get('feature_count', 0)}, "
                          f"ì‹œê°„: {result.get('extraction_time_ms', 0):.1f}ms")
            else:
                logger.error(f"{result['name']} ì‹¤íŒ¨: {result['error']}")
                
        except Exception as e:
            logger.error(f"í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
    
    # ë©”íƒ€ë°ì´í„° ì¶”ê°€
    results['metadata'] = {
        'test_date': datetime.now().isoformat(),
        'num_samples': len(images),
        'positive_samples': sum(labels),
        'negative_samples': len(labels) - sum(labels),
        'image_size': f"{images[0].shape[0]}x{images[0].shape[1]}",
        'test_type': 'advanced_features'
    }
    
    # ê²°ê³¼ ì €ì¥
    with open(output_dir / 'advanced_feature_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=str)
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    generate_advanced_report(results, output_dir)
    
    logger.info("=== ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ ì„±ëŠ¥ í‰ê°€ ì™„ë£Œ ===")
    
    return results


def generate_advanced_report(results, output_dir):
    """ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ ë¦¬í¬íŠ¸ ìƒì„±"""
    with open(output_dir / 'advanced_feature_report.md', 'w', encoding='utf-8') as f:
        f.write("# ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ ì„±ëŠ¥ í‰ê°€ ë¦¬í¬íŠ¸\n\n")
        f.write(f"**í‰ê°€ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        metadata = results.get('metadata', {})
        f.write(f"**ìƒ˜í”Œ ìˆ˜**: {metadata.get('num_samples', 0)}ê°œ\n")
        f.write(f"**ì–‘ì„± ìƒ˜í”Œ**: {metadata.get('positive_samples', 0)}ê°œ\n")
        f.write(f"**ìŒì„± ìƒ˜í”Œ**: {metadata.get('negative_samples', 0)}ê°œ\n")
        f.write(f"**ì´ë¯¸ì§€ í¬ê¸°**: {metadata.get('image_size', 'N/A')}\n\n")
        
        f.write("## ğŸ“Š ì„±ëŠ¥ ìš”ì•½\n\n")
        f.write("| íŠ¹ì§• ì¶”ì¶œê¸° | ì„±ê³µë¥  | íŠ¹ì§• ìˆ˜ | ì¶”ì¶œ ì‹œê°„(ms) | ë¶„ë¥˜ ì •í™•ë„ | ì„¤ëª… |\n")
        f.write("|-------------|--------|---------|---------------|-------------|------|\n")
        
        for name, result in results.items():
            if name == 'metadata' or 'error' in result:
                continue
                
            success_rate = result.get('success_rate', 0) * 100
            feature_count = result.get('feature_count', 0)
            extraction_time = result.get('extraction_time_ms', 0)
            accuracy = result.get('classification_accuracy', 0)
            description = result.get('description', '')
            
            f.write(f"| {name} | {success_rate:.1f}% | {feature_count} | {extraction_time:.1f} | {accuracy:.3f} | {description} |\n")
        
        f.write("\n## ğŸ” ìƒì„¸ ë¶„ì„\n\n")
        
        for name, result in results.items():
            if name == 'metadata':
                continue
                
            f.write(f"### {name}\n\n")
            
            if 'error' in result:
                f.write(f"âŒ **ì‹¤í–‰ ì‹¤íŒ¨**: {result['error']}\n\n")
                continue
            
            f.write(f"- **ì„±ê³µë¥ **: {result.get('success_rate', 0)*100:.1f}%\n")
            f.write(f"- **íŠ¹ì§• ì°¨ì›**: {result.get('feature_count', 0):,}ê°œ\n")
            f.write(f"- **ì¶”ì¶œ ì‹œê°„**: {result.get('extraction_time_ms', 0):.2f}ms\n")
            
            if 'classification_accuracy' in result:
                f.write(f"- **ë¶„ë¥˜ ì •í™•ë„**: {result['classification_accuracy']:.3f} Â± {result.get('accuracy_std', 0):.3f}\n")
            elif 'classification_error' in result:
                f.write(f"- **ë¶„ë¥˜ ì˜¤ë¥˜**: {result['classification_error']}\n")
            
            f.write(f"- **ì„¤ëª…**: {result.get('description', '')}\n\n")
        
        # ê²°ë¡ 
        f.write("## ğŸ’¡ ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­\n\n")
        
        # ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ëœ ì¶”ì¶œê¸°ë“¤ ì¤‘ì—ì„œ ìµœê³  ì„±ëŠ¥ ì°¾ê¸°
        successful_results = {k: v for k, v in results.items() 
                            if k != 'metadata' and 'error' not in v and 'classification_accuracy' in v}
        
        if successful_results:
            best_accuracy = max(successful_results.items(), 
                              key=lambda x: x[1].get('classification_accuracy', 0))
            fastest = min(successful_results.items(), 
                         key=lambda x: x[1].get('extraction_time_ms', float('inf')))
            most_features = max(successful_results.items(), 
                              key=lambda x: x[1].get('feature_count', 0))
            
            f.write(f"ğŸ† **ìµœê³  ë¶„ë¥˜ ì„±ëŠ¥**: {best_accuracy[0]} (ì •í™•ë„: {best_accuracy[1]['classification_accuracy']:.3f})\n")
            f.write(f"âš¡ **ìµœê³  ì†ë„**: {fastest[0]} ({fastest[1]['extraction_time_ms']:.1f}ms)\n")
            f.write(f"ğŸ“Š **ìµœë‹¤ íŠ¹ì§•**: {most_features[0]} ({most_features[1]['feature_count']:,}ì°¨ì›)\n\n")
        
        f.write("### ì¶”ì²œ ì‚¬í•­\n\n")
        f.write("1. **ì‹¤ìš©ì„±**: ë¹ ë¥¸ ì¶”ì¶œê³¼ ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ìœ„í•´ ì„±ê³µë¥  90% ì´ìƒì¸ ì¶”ì¶œê¸° ì„ íƒ\n")
        f.write("2. **ì •í™•ë„**: ë¶„ë¥˜ ì„±ëŠ¥ì´ 0.8 ì´ìƒì¸ ì¶”ì¶œê¸°ë¥¼ ìš°ì„  ê³ ë ¤\n")
        f.write("3. **íŠ¹ì§• ì°¨ì›**: ê³¼ë„í•œ ì°¨ì›ì€ ê³¼ì í•© ìœ„í—˜ì´ ìˆìœ¼ë¯€ë¡œ ì ì ˆí•œ ì°¨ì›ìˆ˜ ìœ ì§€\n")
        f.write("4. **ì²˜ë¦¬ ì‹œê°„**: ì‹¤ì‹œê°„ ì ìš©ì„ ìœ„í•´ì„œëŠ” 100ms ì´í•˜ì˜ ì¶”ì¶œ ì‹œê°„ ê¶Œì¥\n\n")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    results = run_advanced_feature_evaluation()
    
    output_dir = Path("data/results/advanced_feature_test")
    
    print(f"\nğŸ‰ ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ ì„±ëŠ¥ í‰ê°€ ì™„ë£Œ!")
    print(f"ğŸ“Š ê²°ê³¼ ë””ë ‰í† ë¦¬: {output_dir}")
    print(f"ğŸ“ˆ ë¦¬í¬íŠ¸: {output_dir / 'advanced_feature_report.md'}")
    print(f"ğŸ” ìƒì„¸ ê²°ê³¼: {output_dir / 'advanced_feature_results.json'}")
    
    print("\nğŸ“‹ ìš”ì•½:")
    for name, result in results.items():
        if name == 'metadata':
            continue
        
        if 'error' in result:
            print(f"  âŒ {name}: ì‹¤í–‰ ì‹¤íŒ¨ - {result['error']}")
        else:
            success_rate = result.get('success_rate', 0) * 100
            feature_count = result.get('feature_count', 0)
            extraction_time = result.get('extraction_time_ms', 0)
            accuracy = result.get('classification_accuracy', 0)
            
            print(f"  âœ… {name}: {feature_count}ê°œ íŠ¹ì§•, {extraction_time:.1f}ms, "
                  f"ì„±ê³µë¥  {success_rate:.1f}%, ì •í™•ë„ {accuracy:.3f}")


if __name__ == "__main__":
    main()