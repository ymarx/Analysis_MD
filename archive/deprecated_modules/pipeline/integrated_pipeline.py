"""
í†µí•© í•™ìŠµ íŒŒì´í”„ë¼ì¸

íŠ¹ì§• ì¶”ì¶œ, ë°ì´í„° ì¦ê°•, CNN ëª¨ë¸ì„ í†µí•©í•œ ì—”ë“œíˆ¬ì—”ë“œ í•™ìŠµ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
"""

import os
import json
import pickle
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass
import warnings
from datetime import datetime

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
import sys
sys.path.append(str(Path(__file__).parent.parent))

from feature_extraction.hog_extractor import MultiScaleHOGExtractor
from feature_extraction.lbp_extractor import ComprehensiveLBPExtractor
from feature_extraction.gabor_extractor import GaborFeatureExtractor
from feature_extraction.sfs_extractor import EnhancedSfSExtractor
from data_augmentation.augmentation_engine import AdvancedAugmentationEngine, AugmentationConfig
from models.cnn_detector import SidescanTargetDetector, ModelConfig, ModelTrainer, SidescanDataset

warnings.filterwarnings('ignore')
logger = logging.getLogger(__name__)


@dataclass
class PipelineConfig:
    """í†µí•© íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
    # ë°ì´í„° ì„¤ì •
    test_split_ratio: float = 0.2
    validation_split_ratio: float = 0.2
    random_seed: int = 42
    
    # íŠ¹ì§• ì¶”ì¶œ ì„¤ì •
    use_hog: bool = True
    use_lbp: bool = True
    use_gabor: bool = True
    use_sfs: bool = True
    
    # ë°ì´í„° ì¦ê°• ì„¤ì •
    augmentation_strength: float = 0.6
    augmentations_per_positive: int = 5
    target_balance_ratio: float = 1.0
    
    # ëª¨ë¸ ì„¤ì •
    use_traditional_ml: bool = True
    use_deep_learning: bool = True
    ensemble_models: bool = True
    
    # í›ˆë ¨ ì„¤ì •
    batch_size: int = 32
    num_epochs: int = 100
    learning_rate: float = 0.001
    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # ì¶œë ¥ ì„¤ì •
    save_models: bool = True
    save_features: bool = True
    verbose: bool = True


class FeatureExtractorPipeline:
    """íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config: PipelineConfig):
        self.config = config
        
        # íŠ¹ì§• ì¶”ì¶œê¸° ì´ˆê¸°í™”
        self.extractors = {}
        
        if config.use_hog:
            self.extractors['hog'] = MultiScaleHOGExtractor()
        
        if config.use_lbp:
            self.extractors['lbp'] = ComprehensiveLBPExtractor()
        
        if config.use_gabor:
            self.extractors['gabor'] = GaborFeatureExtractor()
        
        if config.use_sfs:
            self.extractors['sfs'] = EnhancedSfSExtractor()
        
        logger.info(f"íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” - {len(self.extractors)}ê°œ ì¶”ì¶œê¸°")
    
    def extract_features(self, images: List[np.ndarray]) -> Tuple[np.ndarray, Dict[str, int]]:
        """
        ì´ë¯¸ì§€ì—ì„œ ëª¨ë“  íŠ¹ì§• ì¶”ì¶œ
        
        Args:
            images: ì…ë ¥ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            Tuple[np.ndarray, Dict[str, int]]: (íŠ¹ì§• í–‰ë ¬, íŠ¹ì§• ì°¨ì› ì •ë³´)
        """
        if not images:
            return np.array([]), {}
        
        all_features = []
        feature_dims = {}
        
        for name, extractor in self.extractors.items():
            logger.info(f"{name.upper()} íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
            
            batch_features = []
            for i, image in enumerate(images):
                try:
                    if name == 'hog':
                        features = extractor.extract_combined_features(image)
                    elif name == 'lbp':
                        features = extractor.extract_comprehensive_features(image)
                    elif name == 'gabor':
                        features = extractor.extract_comprehensive_features(image)
                    elif name == 'sfs':
                        features = extractor.extract_comprehensive_sfs_features(image)
                    
                    if len(features) == 0:
                        logger.warning(f"{name} íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨ - ì´ë¯¸ì§€ {i}")
                        features = np.zeros(100, dtype=np.float32)  # ê¸°ë³¸ í¬ê¸°
                    
                    batch_features.append(features)
                    
                except Exception as e:
                    logger.error(f"{name} íŠ¹ì§• ì¶”ì¶œ ì˜¤ë¥˜ - ì´ë¯¸ì§€ {i}: {e}")
                    batch_features.append(np.zeros(100, dtype=np.float32))
            
            if batch_features:
                # ëª¨ë“  íŠ¹ì§• ë²¡í„°ë¥¼ ê°™ì€ ê¸¸ì´ë¡œ ë§ì¶”ê¸°
                max_len = max(len(f) for f in batch_features)
                if max_len == 0:
                    max_len = 100  # ê¸°ë³¸ê°’
                
                padded_features = []
                for features in batch_features:
                    if len(features) < max_len:
                        padded = np.zeros(max_len, dtype=np.float32)
                        padded[:len(features)] = features
                        padded_features.append(padded)
                    else:
                        padded_features.append(features[:max_len])
                
                feature_matrix = np.array(padded_features)
                all_features.append(feature_matrix)
                feature_dims[name] = max_len
                
                logger.info(f"{name.upper()} íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ: {feature_matrix.shape}")
        
        if all_features:
            combined_features = np.hstack(all_features)
            logger.info(f"ì „ì²´ íŠ¹ì§• ê²°í•© ì™„ë£Œ: {combined_features.shape}")
        else:
            logger.warning("ëª¨ë“  íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨")
            combined_features = np.zeros((len(images), 400), dtype=np.float32)
            feature_dims = {'default': 400}
        
        return combined_features, feature_dims


class DataAugmentationPipeline:
    """ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config: PipelineConfig):
        self.config = config
        
        aug_config = AugmentationConfig(
            augmentation_strength=config.augmentation_strength
        )
        
        self.augmentation_engine = AdvancedAugmentationEngine(aug_config)
        
        logger.info("ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def augment_dataset(self, images: List[np.ndarray], 
                       labels: List[int],
                       masks: Optional[List[np.ndarray]] = None) -> Tuple[List[np.ndarray], List[int], Optional[List[np.ndarray]]]:
        """
        ë°ì´í„°ì…‹ ì¦ê°• ë° ê· í˜•í™”
        
        Args:
            images: ì…ë ¥ ì´ë¯¸ì§€
            labels: ë¼ë²¨
            masks: ë§ˆìŠ¤í¬ (ì˜µì…˜)
            
        Returns:
            Tuple: (ì¦ê°•ëœ ì´ë¯¸ì§€, ì¦ê°•ëœ ë¼ë²¨, ì¦ê°•ëœ ë§ˆìŠ¤í¬)
        """
        # ì–‘ì„±/ìŒì„± ìƒ˜í”Œ ë¶„ë¦¬
        positive_images = [img for img, label in zip(images, labels) if label == 1]
        negative_images = [img for img, label in zip(images, labels) if label == 0]
        
        positive_masks = None
        if masks:
            positive_masks = [mask for mask, label in zip(masks, labels) if label == 1 and mask is not None]
        
        logger.info(f"ì›ë³¸ ë°ì´í„°: {len(positive_images)} ì–‘ì„±, {len(negative_images)} ìŒì„±")
        
        # ë°ì´í„°ì…‹ ê· í˜•í™”
        balanced_images, _, balanced_masks, balanced_labels = self.augmentation_engine.balance_dataset(
            positive_images=positive_images,
            negative_images=negative_images,
            positive_masks=positive_masks,
            target_ratio=self.config.target_balance_ratio
        )
        
        logger.info(f"ê· í˜•í™”ëœ ë°ì´í„°: {len(balanced_images)} ì´ ìƒ˜í”Œ")
        
        return balanced_images, balanced_labels, balanced_masks


class TraditionalMLPipeline:
    """ì „í†µì  ê¸°ê³„í•™ìŠµ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config: PipelineConfig):
        self.config = config
        self.scaler = StandardScaler()
        self.models = {}
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.models['random_forest'] = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=config.random_seed,
            n_jobs=-1
        )
        
        self.models['svm'] = SVC(
            kernel='rbf',
            C=1.0,
            gamma='scale',
            probability=True,
            random_state=config.random_seed
        )
        
        logger.info("ì „í†µì  ML íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def train(self, X_train: np.ndarray, y_train: np.ndarray,
             X_val: np.ndarray, y_val: np.ndarray) -> Dict[str, Dict[str, float]]:
        """
        ì „í†µì  ML ëª¨ë¸ í›ˆë ¨
        
        Args:
            X_train: í›ˆë ¨ íŠ¹ì§•
            y_train: í›ˆë ¨ ë¼ë²¨
            X_val: ê²€ì¦ íŠ¹ì§•
            y_val: ê²€ì¦ ë¼ë²¨
            
        Returns:
            Dict: ëª¨ë¸ë³„ ì„±ëŠ¥ ì§€í‘œ
        """
        # íŠ¹ì§• ì •ê·œí™”
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_val_scaled = self.scaler.transform(X_val)
        
        results = {}
        
        for name, model in self.models.items():
            logger.info(f"{name} ëª¨ë¸ í›ˆë ¨ ì¤‘...")
            
            try:
                # ëª¨ë¸ í›ˆë ¨
                model.fit(X_train_scaled, y_train)
                
                # ì˜ˆì¸¡
                y_pred = model.predict(X_val_scaled)
                y_proba = model.predict_proba(X_val_scaled)[:, 1] if hasattr(model, 'predict_proba') else None
                
                # ì„±ëŠ¥ í‰ê°€
                from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
                
                accuracy = accuracy_score(y_val, y_pred)
                precision = precision_score(y_val, y_pred, average='weighted', zero_division=0)
                recall = recall_score(y_val, y_pred, average='weighted', zero_division=0)
                f1 = f1_score(y_val, y_pred, average='weighted', zero_division=0)
                
                auc = roc_auc_score(y_val, y_proba) if y_proba is not None else 0.0
                
                results[name] = {
                    'accuracy': accuracy,
                    'precision': precision,
                    'recall': recall,
                    'f1_score': f1,
                    'auc': auc
                }
                
                logger.info(f"{name} ì„±ëŠ¥ - ì •í™•ë„: {accuracy:.4f}, F1: {f1:.4f}")
                
            except Exception as e:
                logger.error(f"{name} ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
                results[name] = {
                    'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0, 'auc': 0.0
                }
        
        return results
    
    def save_models(self, save_dir: Path):
        """ëª¨ë¸ ì €ì¥"""
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
        with open(save_dir / 'scaler.pkl', 'wb') as f:
            pickle.dump(self.scaler, f)
        
        # ëª¨ë¸ ì €ì¥
        for name, model in self.models.items():
            with open(save_dir / f'{name}_model.pkl', 'wb') as f:
                pickle.dump(model, f)
        
        logger.info(f"ì „í†µì  ML ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_dir}")


class DeepLearningPipeline:
    """ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config: PipelineConfig):
        self.config = config
        
        # ëª¨ë¸ ì„¤ì •
        self.model_config = ModelConfig(
            backbone='resnet18',
            input_channels=1,
            num_classes=2,
            dropout_rate=0.3,
            use_attention=True
        )
        
        # ëª¨ë¸ ë° í›ˆë ¨ê¸° ì´ˆê¸°í™”
        self.model = SidescanTargetDetector(self.model_config)
        self.trainer = ModelTrainer(self.model, config.device)
        self.trainer.setup_optimizer(config.learning_rate)
        
        logger.info("ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def prepare_data(self, images: List[np.ndarray], labels: List[int],
                    masks: Optional[List[np.ndarray]] = None) -> Tuple[DataLoader, DataLoader]:
        """
        ë°ì´í„° ì¤€ë¹„
        
        Args:
            images: ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            labels: ë¼ë²¨ ë¦¬ìŠ¤íŠ¸
            masks: ë§ˆìŠ¤í¬ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            Tuple[DataLoader, DataLoader]: (í›ˆë ¨ ë¡œë”, ê²€ì¦ ë¡œë”)
        """
        # ë°ì´í„°ì…‹ ìƒì„±
        dataset = SidescanDataset(images, labels, masks)
        
        # í›ˆë ¨/ê²€ì¦ ë¶„í• 
        val_size = int(self.config.validation_split_ratio * len(dataset))
        train_size = len(dataset) - val_size
        
        train_dataset, val_dataset = random_split(
            dataset, [train_size, val_size],
            generator=torch.Generator().manual_seed(self.config.random_seed)
        )
        
        # ë°ì´í„° ë¡œë” ìƒì„±
        train_loader = DataLoader(
            train_dataset,
            batch_size=self.config.batch_size,
            shuffle=True,
            num_workers=2,
            pin_memory=True if self.config.device == 'cuda' else False
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=2,
            pin_memory=True if self.config.device == 'cuda' else False
        )
        
        logger.info(f"ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ - í›ˆë ¨: {len(train_dataset)}, ê²€ì¦: {len(val_dataset)}")
        
        return train_loader, val_loader
    
    def train(self, train_loader: DataLoader, val_loader: DataLoader,
             save_path: Optional[Path] = None) -> Dict[str, List[float]]:
        """
        ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨
        
        Args:
            train_loader: í›ˆë ¨ ë°ì´í„° ë¡œë”
            val_loader: ê²€ì¦ ë°ì´í„° ë¡œë”
            save_path: ëª¨ë¸ ì €ì¥ ê²½ë¡œ
            
        Returns:
            Dict: í›ˆë ¨ íˆìŠ¤í† ë¦¬
        """
        logger.info("ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        
        save_path_str = str(save_path) if save_path else None
        history = self.trainer.train(
            train_loader=train_loader,
            val_loader=val_loader,
            num_epochs=self.config.num_epochs,
            save_path=save_path_str
        )
        
        return history


class IntegratedPipeline:
    """í†µí•© í•™ìŠµ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config: Optional[PipelineConfig] = None):
        self.config = config or PipelineConfig()
        
        # í•˜ìœ„ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        self.feature_extractor = FeatureExtractorPipeline(self.config)
        self.data_augmentor = DataAugmentationPipeline(self.config)
        
        if self.config.use_traditional_ml:
            self.traditional_ml = TraditionalMLPipeline(self.config)
        
        if self.config.use_deep_learning:
            self.deep_learning = DeepLearningPipeline(self.config)
        
        # ê²°ê³¼ ì €ì¥
        self.results = {}
        
        logger.info("í†µí•© íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def run_complete_pipeline(self, 
                            images: List[np.ndarray],
                            labels: List[int],
                            masks: Optional[List[np.ndarray]] = None,
                            output_dir: Optional[Path] = None) -> Dict[str, Any]:
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            images: ì…ë ¥ ì´ë¯¸ì§€
            labels: ë¼ë²¨
            masks: ë§ˆìŠ¤í¬ (ì˜µì…˜)
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
            
        Returns:
            Dict: ì „ì²´ ê²°ê³¼
        """
        start_time = datetime.now()
        logger.info("=== í†µí•© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘ ===")
        
        if output_dir:
            output_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. ë°ì´í„° ì¦ê°• ë° ê· í˜•í™”
        logger.info("1. ë°ì´í„° ì¦ê°• ë° ê· í˜•í™”")
        augmented_images, augmented_labels, augmented_masks = self.data_augmentor.augment_dataset(
            images, labels, masks
        )
        
        # 2. íŠ¹ì§• ì¶”ì¶œ
        logger.info("2. íŠ¹ì§• ì¶”ì¶œ")
        features, feature_dims = self.feature_extractor.extract_features(augmented_images)
        
        # íŠ¹ì§• ì €ì¥
        if output_dir and self.config.save_features:
            np.save(output_dir / 'features.npy', features)
            np.save(output_dir / 'labels.npy', np.array(augmented_labels))
            
            with open(output_dir / 'feature_dims.json', 'w') as f:
                json.dump(feature_dims, f, indent=2)
        
        # 3. ë°ì´í„° ë¶„í• 
        logger.info("3. ë°ì´í„° ë¶„í• ")
        X_train, X_test, y_train, y_test = train_test_split(
            features, augmented_labels,
            test_size=self.config.test_split_ratio,
            random_state=self.config.random_seed,
            stratify=augmented_labels
        )
        
        X_train, X_val, y_train, y_val = train_test_split(
            X_train, y_train,
            test_size=self.config.validation_split_ratio,
            random_state=self.config.random_seed,
            stratify=y_train
        )
        
        logger.info(f"ë°ì´í„° ë¶„í•  ì™„ë£Œ - í›ˆë ¨: {len(X_train)}, ê²€ì¦: {len(X_val)}, í…ŒìŠ¤íŠ¸: {len(X_test)}")
        
        # 4. ì „í†µì  ê¸°ê³„í•™ìŠµ
        if self.config.use_traditional_ml:
            logger.info("4. ì „í†µì  ê¸°ê³„í•™ìŠµ ëª¨ë¸ í›ˆë ¨")
            ml_results = self.traditional_ml.train(X_train, y_train, X_val, y_val)
            self.results['traditional_ml'] = ml_results
            
            if output_dir and self.config.save_models:
                self.traditional_ml.save_models(output_dir / 'traditional_models')
        
        # 5. ë”¥ëŸ¬ë‹
        if self.config.use_deep_learning:
            logger.info("5. ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨")
            
            # ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ë³µêµ¬ (íŠ¹ì§•ì—ì„œ ì´ë¯¸ì§€ë¡œ)
            train_indices = range(len(X_train))
            val_indices = range(len(X_train), len(X_train) + len(X_val))
            
            train_images = [augmented_images[i] for i in train_indices if i < len(augmented_images)]
            val_images = [augmented_images[i] for i in val_indices if i < len(augmented_images)]
            
            # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ë”¥ëŸ¬ë‹ ì‹¤í–‰
            if len(train_images) >= self.config.batch_size and len(val_images) >= self.config.batch_size:
                train_masks = [augmented_masks[i] if augmented_masks else None for i in train_indices]
                val_masks = [augmented_masks[i] if augmented_masks else None for i in val_indices]
                
                train_loader, val_loader = self.deep_learning.prepare_data(
                    train_images[:len(X_train)], y_train.tolist(), 
                    train_masks[:len(X_train)] if any(train_masks) else None
                )
                
                val_loader = self.deep_learning.prepare_data(
                    val_images[:len(X_val)], y_val.tolist(),
                    val_masks[:len(X_val)] if any(val_masks) else None
                )[1]
                
                save_path = output_dir / 'deep_learning_model.pth' if output_dir else None
                dl_history = self.deep_learning.train(train_loader, val_loader, save_path)
                self.results['deep_learning'] = dl_history
            else:
                logger.warning("ë”¥ëŸ¬ë‹ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                self.results['deep_learning'] = {'message': 'Insufficient data for deep learning'}
        
        # 6. ê²°ê³¼ ìš”ì•½
        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()
        
        self.results['summary'] = {
            'execution_time_seconds': execution_time,
            'total_samples': len(augmented_images),
            'feature_dimensions': sum(feature_dims.values()),
            'config': self.config.__dict__
        }
        
        # ê²°ê³¼ ì €ì¥
        if output_dir:
            with open(output_dir / 'pipeline_results.json', 'w') as f:
                # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
                json_results = self._convert_to_json_serializable(self.results)
                json.dump(json_results, f, indent=2)
        
        logger.info(f"=== í†µí•© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ ({execution_time:.1f}ì´ˆ) ===")
        
        return self.results
    
    def _convert_to_json_serializable(self, obj):
        """JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
        if isinstance(obj, dict):
            return {k: self._convert_to_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_to_json_serializable(v) for v in obj]
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        else:
            return obj
    
    def generate_report(self, output_dir: Path):
        """ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.results:
            logger.warning("ìƒì„±í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±
        report_path = output_dir / 'training_report.md'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# ì‚¬ì´ë“œìŠ¤ìº” ì†Œë‚˜ ê¸°ë¬¼ íƒì§€ ëª¨ë¸ í›ˆë ¨ ë¦¬í¬íŠ¸\n\n")
            f.write(f"ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # ìš”ì•½ ì •ë³´
            if 'summary' in self.results:
                summary = self.results['summary']
                f.write("## ğŸ“Š í›ˆë ¨ ìš”ì•½\n\n")
                f.write(f"- **ì‹¤í–‰ ì‹œê°„**: {summary.get('execution_time_seconds', 0):.1f}ì´ˆ\n")
                f.write(f"- **ì´ ìƒ˜í”Œ ìˆ˜**: {summary.get('total_samples', 0):,}ê°œ\n")
                f.write(f"- **íŠ¹ì§• ì°¨ì›**: {summary.get('feature_dimensions', 0):,}ì°¨ì›\n\n")
            
            # ì „í†µì  ML ê²°ê³¼
            if 'traditional_ml' in self.results:
                f.write("## ğŸ¤– ì „í†µì  ê¸°ê³„í•™ìŠµ ê²°ê³¼\n\n")
                for model_name, metrics in self.results['traditional_ml'].items():
                    f.write(f"### {model_name.replace('_', ' ').title()}\n")
                    f.write(f"- **ì •í™•ë„**: {metrics.get('accuracy', 0):.4f}\n")
                    f.write(f"- **ì •ë°€ë„**: {metrics.get('precision', 0):.4f}\n")
                    f.write(f"- **ì¬í˜„ìœ¨**: {metrics.get('recall', 0):.4f}\n")
                    f.write(f"- **F1 ì ìˆ˜**: {metrics.get('f1_score', 0):.4f}\n")
                    f.write(f"- **AUC**: {metrics.get('auc', 0):.4f}\n\n")
            
            # ë”¥ëŸ¬ë‹ ê²°ê³¼
            if 'deep_learning' in self.results:
                f.write("## ğŸ§  ë”¥ëŸ¬ë‹ ê²°ê³¼\n\n")
                dl_results = self.results['deep_learning']
                if 'val_accuracy' in dl_results and dl_results['val_accuracy']:
                    best_accuracy = max(dl_results['val_accuracy'])
                    f.write(f"- **ìµœê³  ê²€ì¦ ì •í™•ë„**: {best_accuracy:.4f}\n")
                    f.write(f"- **ì´ ì—í­**: {len(dl_results['val_accuracy'])}íšŒ\n\n")
        
        logger.info(f"í›ˆë ¨ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {report_path}")


class PipelineRunner:
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ê¸°"""
    
    @staticmethod
    def run_with_sample_data(sample_data_dir: Path, output_dir: Path):
        """ìƒ˜í”Œ ë°ì´í„°ë¡œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("ìƒ˜í”Œ ë°ì´í„°ë¡œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
        
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” ë°ì´í„° ë¡œë”ì—ì„œ ê°€ì ¸ì˜´)
        np.random.seed(42)
        
        # ê°€ìƒì˜ ì†Œë‚˜ ì´ë¯¸ì§€ ë°ì´í„° ìƒì„±
        images = []
        labels = []
        
        # ì–‘ì„± ìƒ˜í”Œ (ê¸°ë¬¼)
        for i in range(50):
            # ê°€ìƒì˜ ê¸°ë¬¼ ì´ë¯¸ì§€ (ì¤‘ì•™ì— ë°ì€ ì˜ì—­)
            img = np.random.normal(0.3, 0.1, (128, 128))
            img[40:80, 40:80] += np.random.normal(0.4, 0.1, (40, 40))
            img = np.clip(img, 0, 1)
            images.append(img)
            labels.append(1)
        
        # ìŒì„± ìƒ˜í”Œ (ë°°ê²½)
        for i in range(30):
            # ê°€ìƒì˜ ë°°ê²½ ì´ë¯¸ì§€
            img = np.random.normal(0.2, 0.05, (128, 128))
            img = np.clip(img, 0, 1)
            images.append(img)
            labels.append(0)
        
        # íŒŒì´í”„ë¼ì¸ ì„¤ì •
        config = PipelineConfig(
            use_traditional_ml=True,
            use_deep_learning=False,  # ìƒ˜í”Œ ë°ì´í„°ë¡œëŠ” ë”¥ëŸ¬ë‹ ë¹„í™œì„±í™”
            batch_size=16,
            num_epochs=10,
            augmentation_strength=0.3
        )
        
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline = IntegratedPipeline(config)
        results = pipeline.run_complete_pipeline(images, labels, output_dir=output_dir)
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        pipeline.generate_report(output_dir)
        
        return results


if __name__ == "__main__":
    # ì˜ˆì œ ì‹¤í–‰
    from pathlib import Path
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    output_dir = Path("data/results/pipeline_test")
    
    # ìƒ˜í”Œ ë°ì´í„°ë¡œ ì‹¤í–‰
    runner = PipelineRunner()
    results = runner.run_with_sample_data(None, output_dir)
    
    print("íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
    print(f"ê²°ê³¼ëŠ” {output_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")