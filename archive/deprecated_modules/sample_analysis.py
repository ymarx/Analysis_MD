#!/usr/bin/env python3
"""
ìƒ˜í”Œ ë°ì´í„° íƒìƒ‰ì  ë¶„ì„ ë° ì „ì²˜ë¦¬ ì„±ëŠ¥ ê²€ì¦

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì´ìš©í•´ ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. XTF ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ë¶„ì„
2. ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ê²€ì¦
3. ê²°ê³¼ ì‹œê°í™” ë° í’ˆì§ˆ í‰ê°€
4. 2ë‹¨ê³„ ì§„í–‰ì„ ìœ„í•œ ê¶Œì¥ì‚¬í•­ ë„ì¶œ
"""

import sys
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import json
import warnings
warnings.filterwarnings('ignore')

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
sys.path.append(str(Path(__file__).parent))

from src.data_processing.xtf_reader import XTFReader
from src.data_processing.coordinate_mapper import CoordinateTransformer, TargetLocationLoader, CoordinateMapper
from src.data_processing.preprocessor import Preprocessor, PreprocessingConfig
from config.settings import *
from config.paths import path_manager

# ë¡œê¹… ì„¤ì •
import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SampleDataAnalyzer:
    """ìƒ˜í”Œ ë°ì´í„° íƒìƒ‰ì  ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.results = {}
        self.figures_dir = path_manager.figures
        self.processed_dir = path_manager.processed_data
        
        logger.info("ìƒ˜í”Œ ë°ì´í„° ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def run_complete_analysis(self):
        """ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("="*60)
        print("ì‚¬ì´ë“œìŠ¤ìº” ì†Œë‚˜ ìƒ˜í”Œ ë°ì´í„° íƒìƒ‰ì  ë¶„ì„")
        print("="*60)
        
        try:
            # Phase 1: ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ë¶„ì„
            self.phase1_data_loading()
            
            # Phase 2: ì „ì²˜ë¦¬ ì„±ëŠ¥ ë¶„ì„
            self.phase2_preprocessing_analysis()
            
            # Phase 3: ì¢Œí‘œ ë§¤í•‘ ê²€ì¦
            self.phase3_coordinate_mapping()
            
            # Phase 4: ê²°ê³¼ ì¢…í•© ë° í‰ê°€
            self.phase4_comprehensive_evaluation()
            
            # Phase 5: 2ë‹¨ê³„ ì§„í–‰ ê³„íš
            self.phase5_next_phase_planning()
            
            print("\\n" + "="*60)
            print("ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ëŠ” ë‹¤ìŒ ìœ„ì¹˜ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
            print(f"- ê·¸ë¦¼: {self.figures_dir}")
            print(f"- ì²˜ë¦¬ëœ ë°ì´í„°: {self.processed_dir}")
            print("="*60)
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            raise
    
    def phase1_data_loading(self):
        """Phase 1: ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ë¶„ì„"""
        print("\\nğŸ” Phase 1: ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ë¶„ì„")
        print("-" * 40)
        
        # XTF íŒŒì¼ ë¡œë“œ
        xtf_filename = XTF_CONFIG['sample_file']
        xtf_filepath = path_manager.get_sample_file(xtf_filename)
        
        if not xtf_filepath.exists():
            logger.error(f"XTF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {xtf_filepath}")
            print(f"âŒ XTF íŒŒì¼ ì—†ìŒ: {xtf_filename}")
            return False
        
        print(f"ğŸ“„ XTF íŒŒì¼ ë¡œë“œ: {xtf_filename} ({xtf_filepath.stat().st_size / (1024*1024):.1f} MB)")
        
        # XTF Reader ì´ˆê¸°í™”
        self.xtf_reader = XTFReader(xtf_filepath, max_pings=XTF_CONFIG['max_pings_per_load'])
        
        if not self.xtf_reader.load_file():
            logger.error("XTF íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨")
            print("âŒ XTF íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨")
            return False
        
        # Ping ë°ì´í„° íŒŒì‹±
        self.ping_data = self.xtf_reader.parse_pings()
        print(f"âœ… {len(self.ping_data)} pings ë¡œë“œ ì™„ë£Œ")
        
        # ê¸°ë³¸ ì •ë³´ ì¶œë ¥
        summary = self.xtf_reader.get_summary()
        self.results['basic_info'] = summary
        
        print(f"\\nğŸ“Š ê¸°ë³¸ ì •ë³´:")
        print(f"   - ì´ ping ìˆ˜: {summary['total_pings']:,}")
        print(f"   - ì†Œë‚˜ ì±„ë„ ìˆ˜: {summary['num_sonar_channels']}")
        print(f"   - ì£¼íŒŒìˆ˜ ì •ë³´: {summary['frequency_info']}")
        
        if summary['coordinate_bounds']['lat'][0]:
            print(f"   - ìœ„ë„ ë²”ìœ„: {summary['coordinate_bounds']['lat'][0]:.6f} ~ {summary['coordinate_bounds']['lat'][1]:.6f}")
            print(f"   - ê²½ë„ ë²”ìœ„: {summary['coordinate_bounds']['lon'][0]:.6f} ~ {summary['coordinate_bounds']['lon'][1]:.6f}")
        else:
            print("   - âš ï¸  ìœ„ì¹˜ ì •ë³´ ì—†ìŒ")
        
        # Intensity ë°ì´í„° ì¶”ì¶œ ë° ë¶„ì„
        self.port_intensity, self.port_geo = self.xtf_reader.get_channel_data(0)
        self.starboard_intensity, self.starboard_geo = self.xtf_reader.get_channel_data(1)
        
        print(f"\\nğŸ“ˆ Intensity ë°ì´í„°:")
        print(f"   - Port ì±„ë„: {self.port_intensity.shape} ({self.port_intensity.nbytes / (1024*1024):.1f} MB)")
        print(f"   - Starboard ì±„ë„: {self.starboard_intensity.shape} ({self.starboard_intensity.nbytes / (1024*1024):.1f} MB)")
        
        # ë°ì´í„° í’ˆì§ˆ ë¶„ì„
        quality_metrics = self._analyze_data_quality(self.port_intensity)
        self.results['data_quality'] = quality_metrics
        
        print(f"\\nâš¡ ë°ì´í„° í’ˆì§ˆ:")
        print(f"   - ë™ì  ë²”ìœ„: {quality_metrics['dynamic_range']:.2f}")
        print(f"   - í‰ê·  ê°•ë„: {quality_metrics['mean_intensity']:.2f}")
        print(f"   - í‘œì¤€í¸ì°¨: {quality_metrics['std_intensity']:.2f}")
        print(f"   - ê²°ì¸¡ì¹˜ ë¹„ìœ¨: {quality_metrics['missing_ratio']:.1%}")
        print(f"   - SNR ì¶”ì •: {quality_metrics['estimated_snr']:.1f} dB")
        
        # ì´ˆê¸° ì‹œê°í™”
        self._visualize_raw_data()
        
        return True
    
    def phase2_preprocessing_analysis(self):
        """Phase 2: ì „ì²˜ë¦¬ ì„±ëŠ¥ ë¶„ì„"""
        print("\\nğŸ”§ Phase 2: ì „ì²˜ë¦¬ ì„±ëŠ¥ ë¶„ì„")
        print("-" * 40)
        
        # ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ì„¤ì •ìœ¼ë¡œ ì„±ëŠ¥ ë¹„êµ
        preprocessing_configs = {
            'basic': PreprocessingConfig(
                remove_water_column=True,
                normalize_intensity=True,
                apply_denoising=False,
                enhance_contrast=False,
                terrain_adaptive=False
            ),
            'standard': PreprocessingConfig(
                remove_water_column=True,
                normalize_intensity=True,
                normalization_method='minmax',
                apply_denoising=True,
                denoising_method='gaussian',
                enhance_contrast=True,
                contrast_method='clahe',
                terrain_adaptive=False
            ),
            'advanced': PreprocessingConfig(
                remove_water_column=True,
                normalize_intensity=True,
                normalization_method='minmax',
                apply_denoising=True,
                denoising_method='bilateral',
                enhance_contrast=True,
                contrast_method='clahe',
                terrain_adaptive=True
            )
        }
        
        preprocessing_results = {}
        
        for config_name, config in preprocessing_configs.items():
            print(f"\\nğŸ”„ {config_name.upper()} ì „ì²˜ë¦¬ ì‹¤í–‰...")
            
            preprocessor = Preprocessor(config)
            result = preprocessor.process(self.port_intensity)
            
            preprocessing_results[config_name] = {
                'result': result,
                'config': config,
                'processing_time': getattr(result, 'processing_time', 0)
            }
            
            print(f"   âœ… ì²˜ë¦¬ ë‹¨ê³„: {len(result.processing_steps)}")
            print(f"   ğŸ“Š SNR: {result.quality_metrics['snr']:.1f} dB")
            print(f"   ğŸ¯ ëŒ€ë¹„ ê°œì„ : {result.quality_metrics['contrast_improvement']:.2f}x")
            print(f"   ğŸ”€ ì—£ì§€ ë³´ì¡´: {result.quality_metrics['edge_preservation']:.3f}")
        
        self.results['preprocessing'] = preprocessing_results
        
        # ì „ì²˜ë¦¬ ë¹„êµ ì‹œê°í™”
        self._visualize_preprocessing_comparison(preprocessing_results)
        
        # ìµœì  ì „ì²˜ë¦¬ ë°©ë²• ì„ ì •
        best_config = self._select_best_preprocessing(preprocessing_results)
        self.results['best_preprocessing'] = best_config
        
        print(f"\\nğŸ† ìµœì  ì „ì²˜ë¦¬ ë°©ë²•: {best_config}")
        
        return preprocessing_results
    
    def phase3_coordinate_mapping(self):
        """Phase 3: ì¢Œí‘œ ë§¤í•‘ ê²€ì¦"""
        print("\\nğŸ—ºï¸  Phase 3: ì¢Œí‘œ ë§¤í•‘ ê²€ì¦")
        print("-" * 40)
        
        # ê¸°ë¬¼ ìœ„ì¹˜ ì •ë³´ ë¡œë“œ ì‹œë„
        location_file = path_manager.get_sample_file(COORDINATE_CONFIG['location_file'])
        
        if not location_file.exists():
            print(f"âš ï¸  ìœ„ì¹˜ íŒŒì¼ ì—†ìŒ: {location_file.name}")
            self.results['coordinate_mapping'] = {'status': 'no_location_file'}
            return False
        
        # ì¢Œí‘œ ë³€í™˜ê¸° ì´ˆê¸°í™”
        coord_transformer = CoordinateTransformer(utm_zone=COORDINATE_CONFIG['utm_zone'])
        target_loader = TargetLocationLoader(coord_transformer)
        
        try:
            # ì—‘ì…€ íŒŒì¼ êµ¬ì¡° ë¨¼ì € í™•ì¸
            df_preview = pd.read_excel(location_file)
            print(f"ğŸ“‹ ìœ„ì¹˜ íŒŒì¼ êµ¬ì¡° í™•ì¸:")
            print(f"   - í–‰ ìˆ˜: {len(df_preview)}")
            print(f"   - ì»¬ëŸ¼: {list(df_preview.columns)}")
            print(f"   - ì²« 5í–‰:")
            print(df_preview.head().to_string(index=False))
            
            # ì ì ˆí•œ ì»¬ëŸ¼ëª… ì°¾ê¸°
            lat_col, lon_col = self._find_coordinate_columns(df_preview.columns)
            
            if lat_col and lon_col:
                success = target_loader.load_from_excel(
                    location_file,
                    lat_col=lat_col,
                    lon_col=lon_col
                )
                
                if success:
                    targets_df = target_loader.get_targets_dataframe()
                    print(f"\\nâœ… ê¸°ë¬¼ ìœ„ì¹˜ ë¡œë“œ ì„±ê³µ: {len(targets_df)} ê°œ")
                    
                    # ì¢Œí‘œ ë§¤í•‘ê¸° ì„¤ì •
                    coord_mapper = CoordinateMapper(coord_transformer)
                    coord_mapper.set_sonar_data(
                        self.port_geo[['latitude', 'longitude', 'ping_number']],
                        self.port_intensity.shape
                    )
                    
                    # ì¢Œí‘œ ë§¤í•‘ ê²€ì¦
                    mapping_validation = self._validate_coordinate_mapping(coord_mapper, target_loader)
                    self.results['coordinate_mapping'] = mapping_validation
                    
                    print(f"\\nğŸ“ ì¢Œí‘œ ë§¤í•‘ ê²€ì¦:")
                    print(f"   - ë°ì´í„° ì˜ì—­ ë‚´ ê¸°ë¬¼: {mapping_validation['targets_in_area']}")
                    print(f"   - í‰ê·  ë§¤í•‘ ì˜¤ì°¨: {mapping_validation['avg_mapping_error']:.1f}m")
                    print(f"   - ë§¤í•‘ ì„±ê³µë¥ : {mapping_validation['mapping_success_rate']:.1%}")
                    
                else:
                    print("âŒ ê¸°ë¬¼ ìœ„ì¹˜ ë¡œë“œ ì‹¤íŒ¨")
                    self.results['coordinate_mapping'] = {'status': 'load_failed'}
                    
            else:
                print("âŒ ì ì ˆí•œ ì¢Œí‘œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                self.results['coordinate_mapping'] = {'status': 'no_coord_columns'}
                
        except Exception as e:
            logger.error(f"ì¢Œí‘œ ë§¤í•‘ ì‹¤íŒ¨: {e}")
            print(f"âŒ ì¢Œí‘œ ë§¤í•‘ ì˜¤ë¥˜: {e}")
            self.results['coordinate_mapping'] = {'status': 'error', 'error': str(e)}
            
        return True
    
    def phase4_comprehensive_evaluation(self):
        """Phase 4: ê²°ê³¼ ì¢…í•© ë° í‰ê°€"""
        print("\\nğŸ“Š Phase 4: ê²°ê³¼ ì¢…í•© ë° í‰ê°€")
        print("-" * 40)
        
        evaluation = {}
        
        # ë°ì´í„° í’ˆì§ˆ í‰ê°€
        data_quality = self.results['data_quality']
        if data_quality['estimated_snr'] > 15:
            quality_grade = 'A (ìš°ìˆ˜)'
        elif data_quality['estimated_snr'] > 10:
            quality_grade = 'B (ì–‘í˜¸)'
        elif data_quality['estimated_snr'] > 5:
            quality_grade = 'C (ë³´í†µ)'
        else:
            quality_grade = 'D (ê°œì„  í•„ìš”)'
        
        evaluation['data_quality_grade'] = quality_grade
        
        # ì „ì²˜ë¦¬ íš¨ê³¼ í‰ê°€
        if 'preprocessing' in self.results:
            best_preprocessing = self.results['preprocessing'][self.results['best_preprocessing']]
            preprocessing_effectiveness = best_preprocessing['result'].quality_metrics
            
            if preprocessing_effectiveness['snr'] > 20:
                preprocessing_grade = 'A (ë§¤ìš° íš¨ê³¼ì )'
            elif preprocessing_effectiveness['snr'] > 15:
                preprocessing_grade = 'B (íš¨ê³¼ì )'
            elif preprocessing_effectiveness['snr'] > 10:
                preprocessing_grade = 'C (ë³´í†µ)'
            else:
                preprocessing_grade = 'D (ê°œì„  í•„ìš”)'
                
            evaluation['preprocessing_grade'] = preprocessing_grade
        
        # ì¢Œí‘œ ë§¤í•‘ í‰ê°€
        if 'coordinate_mapping' in self.results:
            mapping_result = self.results['coordinate_mapping']
            if mapping_result.get('status') == 'success':
                if mapping_result['mapping_success_rate'] > 0.8:
                    mapping_grade = 'A (ì •í™•)'
                elif mapping_result['mapping_success_rate'] > 0.6:
                    mapping_grade = 'B (ì–‘í˜¸)'
                else:
                    mapping_grade = 'C (ê°œì„  í•„ìš”)'
            else:
                mapping_grade = 'F (ì‹¤íŒ¨)'
            evaluation['mapping_grade'] = mapping_grade
        
        # ì „ì²´ ì‹œìŠ¤í…œ ì¤€ë¹„ë„ í‰ê°€
        grades = [evaluation.get('data_quality_grade', 'D'),
                 evaluation.get('preprocessing_grade', 'D'),
                 evaluation.get('mapping_grade', 'F')]
        
        grade_scores = {'A': 4, 'B': 3, 'C': 2, 'D': 1, 'F': 0}
        avg_score = np.mean([grade_scores[g.split()[0]] for g in grades])
        
        if avg_score >= 3.5:
            overall_readiness = 'Phase 2 ì§„í–‰ ì¤€ë¹„ ì™„ë£Œ'
        elif avg_score >= 2.5:
            overall_readiness = 'Phase 2 ì§„í–‰ ê°€ëŠ¥ (ì¼ë¶€ ê°œì„  ê¶Œì¥)'
        elif avg_score >= 1.5:
            overall_readiness = 'Phase 2 ì§„í–‰ ì „ ê°œì„  í•„ìš”'
        else:
            overall_readiness = 'Phase 1 ì¬ì ê²€ í•„ìš”'
        
        evaluation['overall_readiness'] = overall_readiness
        evaluation['readiness_score'] = avg_score
        
        self.results['comprehensive_evaluation'] = evaluation
        
        print(f"\\nğŸ¯ ì¢…í•© í‰ê°€ ê²°ê³¼:")
        print(f"   - ë°ì´í„° í’ˆì§ˆ: {quality_grade}")
        if 'preprocessing_grade' in evaluation:
            print(f"   - ì „ì²˜ë¦¬ íš¨ê³¼: {preprocessing_grade}")
        if 'mapping_grade' in evaluation:
            print(f"   - ì¢Œí‘œ ë§¤í•‘: {mapping_grade}")
        print(f"   - ì „ì²´ ì¤€ë¹„ë„: {overall_readiness}")
        print(f"   - ì¤€ë¹„ë„ ì ìˆ˜: {avg_score:.1f}/4.0")
        
        return evaluation
    
    def phase5_next_phase_planning(self):
        """Phase 5: 2ë‹¨ê³„ ì§„í–‰ ê³„íš"""
        print("\\nğŸ“‹ Phase 5: 2ë‹¨ê³„ ì§„í–‰ ê³„íš")
        print("-" * 40)
        
        evaluation = self.results['comprehensive_evaluation']
        readiness_score = evaluation['readiness_score']
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = []
        immediate_tasks = []
        medium_term_tasks = []
        
        # ë°ì´í„° í’ˆì§ˆ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        data_quality = self.results['data_quality']
        if data_quality['estimated_snr'] < 10:
            recommendations.append("ë°ì´í„° í’ˆì§ˆ ê°œì„ ì„ ìœ„í•œ ì¶”ê°€ ì „ì²˜ë¦¬ ê¸°ë²• ë„ì…")
            immediate_tasks.append("ë…¸ì´ì¦ˆ ì œê±° ì•Œê³ ë¦¬ì¦˜ ìµœì í™”")
        
        if data_quality['missing_ratio'] > 0.1:
            recommendations.append("ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë°©ë²• ê°œì„ ")
            immediate_tasks.append("ì›Œí„°ì»¬ëŸ¼ ì²˜ë¦¬ ì•Œê³ ë¦¬ì¦˜ íŠœë‹")
        
        # ì¢Œí‘œ ë§¤í•‘ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if 'coordinate_mapping' in self.results:
            mapping_result = self.results['coordinate_mapping']
            if mapping_result.get('status') != 'success':
                recommendations.append("ì¢Œí‘œ ë§¤í•‘ ì‹œìŠ¤í…œ ì¬êµ¬ì„± í•„ìš”")
                immediate_tasks.append("ìœ„ì¹˜ ë°ì´í„° í˜•ì‹ ë° ì¢Œí‘œê³„ ê²€í† ")
            elif mapping_result.get('mapping_success_rate', 0) < 0.7:
                recommendations.append("ì¢Œí‘œ ë§¤í•‘ ì •í™•ë„ ê°œì„ ")
                immediate_tasks.append("UTM ì¡´ ì„¤ì • ë° ë³€í™˜ ì•Œê³ ë¦¬ì¦˜ ìµœì í™”")
        
        # 2ë‹¨ê³„ ì§„í–‰ ê³„íš ìˆ˜ë¦½
        if readiness_score >= 3.0:
            phase2_plan = self._create_advanced_phase2_plan()
        elif readiness_score >= 2.0:
            phase2_plan = self._create_standard_phase2_plan()
        else:
            phase2_plan = self._create_basic_phase2_plan()
        
        self.results['phase2_plan'] = phase2_plan
        self.results['recommendations'] = recommendations
        self.results['immediate_tasks'] = immediate_tasks
        self.results['medium_term_tasks'] = medium_term_tasks
        
        print(f"\\nâœ¨ 2ë‹¨ê³„ ê³„íš: {phase2_plan['plan_type']}")
        print(f"\\nğŸ¯ ì¦‰ì‹œ ìˆ˜í–‰ ê³¼ì œ:")
        for i, task in enumerate(immediate_tasks[:5], 1):
            print(f"   {i}. {task}")
        
        print(f"\\nğŸ“… ì¤‘ê¸° ìˆ˜í–‰ ê³¼ì œ:")
        for i, task in enumerate(medium_term_tasks[:3], 1):
            print(f"   {i}. {task}")
        
        print(f"\\nğŸ’¡ ì£¼ìš” ê¶Œì¥ì‚¬í•­:")
        for i, rec in enumerate(recommendations[:3], 1):
            print(f"   {i}. {rec}")
        
        # ìƒì„¸ ê³„íš ì €ì¥
        self._save_detailed_plan(phase2_plan, recommendations)
        
        return phase2_plan
    
    def _analyze_data_quality(self, intensity_data):
        """ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
        metrics = {
            'dynamic_range': float(np.max(intensity_data) - np.min(intensity_data)),
            'mean_intensity': float(np.mean(intensity_data)),
            'std_intensity': float(np.std(intensity_data)),
            'missing_ratio': float(np.sum(intensity_data == 0) / intensity_data.size),
            'estimated_snr': float(self._estimate_snr(intensity_data))
        }
        return metrics
    
    def _estimate_snr(self, data):
        """SNR ì¶”ì •"""
        # ì‹ í˜¸: ìƒìœ„ 25% ë°ì´í„°ì˜ í‰ê· 
        signal = np.mean(data[data > np.percentile(data, 75)])
        # ë…¸ì´ì¦ˆ: í•˜ìœ„ 25% ë°ì´í„°ì˜ í‘œì¤€í¸ì°¨
        noise = np.std(data[data < np.percentile(data, 25)])
        
        if noise > 0:
            snr_db = 20 * np.log10(signal / noise)
        else:
            snr_db = 40  # ê¸°ë³¸ê°’
        
        return max(0, min(40, snr_db))  # 0-40 dB ë²”ìœ„ë¡œ ì œí•œ
    
    def _visualize_raw_data(self):
        """ì›ë³¸ ë°ì´í„° ì‹œê°í™”"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # Port ì±„ë„ ì´ë¯¸ì§€
        im1 = axes[0, 0].imshow(self.port_intensity, aspect='auto', cmap='gray')
        axes[0, 0].set_title('Port ì±„ë„ (ì›ë³¸)', fontsize=14)
        axes[0, 0].set_xlabel('ìƒ˜í”Œ ë²ˆí˜¸')
        axes[0, 0].set_ylabel('Ping ë²ˆí˜¸')
        plt.colorbar(im1, ax=axes[0, 0])
        
        # Starboard ì±„ë„ ì´ë¯¸ì§€
        im2 = axes[0, 1].imshow(self.starboard_intensity, aspect='auto', cmap='gray')
        axes[0, 1].set_title('Starboard ì±„ë„ (ì›ë³¸)', fontsize=14)
        axes[0, 1].set_xlabel('ìƒ˜í”Œ ë²ˆí˜¸')
        axes[0, 1].set_ylabel('Ping ë²ˆí˜¸')
        plt.colorbar(im2, ax=axes[0, 1])
        
        # Port ì±„ë„ íˆìŠ¤í† ê·¸ë¨
        axes[0, 2].hist(self.port_intensity.flatten(), bins=100, alpha=0.7, color='blue', density=True)
        axes[0, 2].set_title('Port ì±„ë„ ë¶„í¬', fontsize=14)
        axes[0, 2].set_xlabel('Intensity ê°’')
        axes[0, 2].set_ylabel('ë°€ë„')
        axes[0, 2].grid(True, alpha=0.3)
        
        # Starboard ì±„ë„ íˆìŠ¤í† ê·¸ë¨
        axes[1, 0].hist(self.starboard_intensity.flatten(), bins=100, alpha=0.7, color='red', density=True)
        axes[1, 0].set_title('Starboard ì±„ë„ ë¶„í¬', fontsize=14)
        axes[1, 0].set_xlabel('Intensity ê°’')
        axes[1, 0].set_ylabel('ë°€ë„')
        axes[1, 0].grid(True, alpha=0.3)
        
        # ì±„ë„ë³„ í‰ê·  í”„ë¡œíŒŒì¼
        port_mean_profile = np.mean(self.port_intensity, axis=0)
        starboard_mean_profile = np.mean(self.starboard_intensity, axis=0)
        
        axes[1, 1].plot(port_mean_profile, label='Port', alpha=0.8)
        axes[1, 1].plot(starboard_mean_profile, label='Starboard', alpha=0.8)
        axes[1, 1].set_title('ì±„ë„ë³„ í‰ê·  í”„ë¡œíŒŒì¼', fontsize=14)
        axes[1, 1].set_xlabel('ìƒ˜í”Œ ë²ˆí˜¸')
        axes[1, 1].set_ylabel('í‰ê·  Intensity')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        # í†µê³„ ìš”ì•½
        stats_text = f"""ë°ì´í„° í†µê³„ ìš”ì•½
        
Port ì±„ë„:
- í¬ê¸°: {self.port_intensity.shape}
- í‰ê· : {np.mean(self.port_intensity):.2f}
- í‘œì¤€í¸ì°¨: {np.std(self.port_intensity):.2f}
- ìµœì†Ÿê°’: {np.min(self.port_intensity):.2f}
- ìµœëŒ“ê°’: {np.max(self.port_intensity):.2f}

Starboard ì±„ë„:
- í¬ê¸°: {self.starboard_intensity.shape}
- í‰ê· : {np.mean(self.starboard_intensity):.2f}
- í‘œì¤€í¸ì°¨: {np.std(self.starboard_intensity):.2f}
- ìµœì†Ÿê°’: {np.min(self.starboard_intensity):.2f}
- ìµœëŒ“ê°’: {np.max(self.starboard_intensity):.2f}"""
        
        axes[1, 2].text(0.05, 0.95, stats_text, transform=axes[1, 2].transAxes,
                        fontsize=10, verticalalignment='top', fontfamily='monospace')
        axes[1, 2].axis('off')
        
        plt.tight_layout()
        plt.savefig(self.figures_dir / '01_raw_data_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def _visualize_preprocessing_comparison(self, preprocessing_results):
        """ì „ì²˜ë¦¬ ê²°ê³¼ ë¹„êµ ì‹œê°í™”"""
        n_configs = len(preprocessing_results)
        fig, axes = plt.subplots(2, n_configs + 1, figsize=(6 * (n_configs + 1), 12))
        
        # ì›ë³¸ ë°ì´í„°
        im_orig = axes[0, 0].imshow(self.port_intensity, aspect='auto', cmap='gray')
        axes[0, 0].set_title('ì›ë³¸ ë°ì´í„°', fontsize=14)
        plt.colorbar(im_orig, ax=axes[0, 0])
        
        axes[1, 0].hist(self.port_intensity.flatten(), bins=50, alpha=0.7, density=True)
        axes[1, 0].set_title('ì›ë³¸ ë¶„í¬')
        axes[1, 0].grid(True, alpha=0.3)
        
        # ê° ì „ì²˜ë¦¬ ê²°ê³¼
        for i, (config_name, result_data) in enumerate(preprocessing_results.items(), 1):
            processed_data = result_data['result'].processed_data
            
            # ì´ë¯¸ì§€
            im = axes[0, i].imshow(processed_data, aspect='auto', cmap='gray')
            axes[0, i].set_title(f'{config_name.upper()}\\nì „ì²˜ë¦¬ ê²°ê³¼', fontsize=14)
            plt.colorbar(im, ax=axes[0, i])
            
            # íˆìŠ¤í† ê·¸ë¨
            axes[1, i].hist(processed_data.flatten(), bins=50, alpha=0.7, density=True)
            axes[1, i].set_title(f'{config_name.upper()} ë¶„í¬')
            axes[1, i].grid(True, alpha=0.3)
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ
            metrics = result_data['result'].quality_metrics
            metric_text = f"SNR: {metrics['snr']:.1f}dB\\nëŒ€ë¹„: {metrics['contrast_improvement']:.2f}x\\nì—£ì§€: {metrics['edge_preservation']:.3f}"
            axes[1, i].text(0.02, 0.98, metric_text, transform=axes[1, i].transAxes,
                           verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        plt.tight_layout()
        plt.savefig(self.figures_dir / '02_preprocessing_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def _select_best_preprocessing(self, preprocessing_results):
        """ìµœì  ì „ì²˜ë¦¬ ë°©ë²• ì„ ì •"""
        scores = {}
        
        for config_name, result_data in preprocessing_results.items():
            metrics = result_data['result'].quality_metrics
            
            # ë³µí•© ì ìˆ˜ ê³„ì‚° (SNR 50%, ëŒ€ë¹„ê°œì„  30%, ì—£ì§€ë³´ì¡´ 20%)
            score = (metrics['snr'] * 0.5 + 
                    metrics['contrast_improvement'] * 10 * 0.3 +
                    metrics['edge_preservation'] * 20 * 0.2)
            
            scores[config_name] = score
        
        best_config = max(scores.keys(), key=lambda k: scores[k])
        return best_config
    
    def _find_coordinate_columns(self, columns):
        """ì¢Œí‘œ ì»¬ëŸ¼ëª… ìë™ ê°ì§€"""
        lat_keywords = ['lat', 'latitude', 'ìœ„ë„', 'y']
        lon_keywords = ['lon', 'long', 'longitude', 'ê²½ë„', 'x']
        
        lat_col = None
        lon_col = None
        
        for col in columns:
            col_lower = col.lower()
            if any(keyword in col_lower for keyword in lat_keywords):
                lat_col = col
            elif any(keyword in col_lower for keyword in lon_keywords):
                lon_col = col
        
        return lat_col, lon_col
    
    def _validate_coordinate_mapping(self, coord_mapper, target_loader):
        """ì¢Œí‘œ ë§¤í•‘ ê²€ì¦"""
        validation = {}
        
        # ë°ì´í„° ì˜ì—­ ë‚´ ê¸°ë¬¼ ìˆ˜ í™•ì¸
        coord_bounds = self.xtf_reader.get_summary()['coordinate_bounds']
        targets_in_area = target_loader.get_targets_in_bounds(
            min_lat=coord_bounds['lat'][0],
            max_lat=coord_bounds['lat'][1],
            min_lon=coord_bounds['lon'][0],
            max_lon=coord_bounds['lon'][1]
        )
        
        validation['targets_in_area'] = len(targets_in_area)
        
        if targets_in_area:
            # ë§¤í•‘ ì •í™•ë„ í…ŒìŠ¤íŠ¸
            mapping_errors = []
            successful_mappings = 0
            
            for target in targets_in_area[:min(10, len(targets_in_area))]:  # ìµœëŒ€ 10ê°œ í…ŒìŠ¤íŠ¸
                # ìœ„ê²½ë„ -> í”½ì…€ -> ìœ„ê²½ë„ ë³€í™˜ í…ŒìŠ¤íŠ¸
                pixel_coords = coord_mapper.geo_to_pixel(target.longitude, target.latitude)
                
                if pixel_coords[0] >= 0 and pixel_coords[1] >= 0:
                    reverse_coords = coord_mapper.pixel_to_geo(pixel_coords[0], pixel_coords[1])
                    
                    # ê±°ë¦¬ ì˜¤ì°¨ ê³„ì‚° (ëŒ€ëµì )
                    lat_diff = abs(target.latitude - reverse_coords[1])
                    lon_diff = abs(target.longitude - reverse_coords[0])
                    error_meters = np.sqrt((lat_diff * 111000)**2 + (lon_diff * 111000 * np.cos(np.radians(target.latitude)))**2)
                    
                    mapping_errors.append(error_meters)
                    successful_mappings += 1
            
            if mapping_errors:
                validation['avg_mapping_error'] = np.mean(mapping_errors)
                validation['max_mapping_error'] = np.max(mapping_errors)
                validation['mapping_success_rate'] = successful_mappings / len(targets_in_area)
                validation['status'] = 'success'
            else:
                validation['status'] = 'no_valid_mappings'
        else:
            validation['status'] = 'no_targets_in_area'
        
        return validation
    
    def _create_advanced_phase2_plan(self):
        """ê³ ê¸‰ Phase 2 ê³„íš (ì¤€ë¹„ë„ ë†’ìŒ)"""
        return {
            'plan_type': 'ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ ë° ë”¥ëŸ¬ë‹',
            'priority_tasks': [
                'ë‹¤ì¤‘ íŠ¹ì§• ì¶”ì¶œ ì‹œìŠ¤í…œ êµ¬í˜„ (HOG, LBP, Gabor, SfS)',
                'CNN ê¸°ë°˜ ìë™ íŠ¹ì§• í•™ìŠµ',
                'ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„±',
                'ì‹¤ì‹œê°„ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ìµœì í™”'
            ],
            'timeline': '4-6ì£¼',
            'expected_accuracy': '>90%',
            'next_milestones': [
                'íŠ¹ì§• ì¶”ì¶œ ëª¨ë“ˆ ì™„ì„± (2ì£¼)',
                'CNN ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (3ì£¼)', 
                'ì•™ìƒë¸” ì‹œìŠ¤í…œ êµ¬ì¶• (4ì£¼)',
                'ì„±ëŠ¥ ìµœì í™” ì™„ë£Œ (6ì£¼)'
            ]
        }
    
    def _create_standard_phase2_plan(self):
        """í‘œì¤€ Phase 2 ê³„íš (ì¤€ë¹„ë„ ë³´í†µ)"""
        return {
            'plan_type': 'ì „í†µì  íŠ¹ì§• ì¶”ì¶œ + ë¨¸ì‹ ëŸ¬ë‹',
            'priority_tasks': [
                'í•µì‹¬ íŠ¹ì§• ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ (HOG, LBP)',
                'ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ êµ¬ì¶•',
                'SVM/Random Forest ë¶„ë¥˜ ëª¨ë¸',
                'í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”'
            ],
            'timeline': '6-8ì£¼',
            'expected_accuracy': '75-85%',
            'next_milestones': [
                'HOG/LBP íŠ¹ì§• ì¶”ì¶œ (2ì£¼)',
                'ë°ì´í„° ì¦ê°• ì™„ë£Œ (3ì£¼)',
                'ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ (5ì£¼)',
                'ì„±ëŠ¥ í‰ê°€ ì™„ë£Œ (8ì£¼)'
            ]
        }
    
    def _create_basic_phase2_plan(self):
        """ê¸°ë³¸ Phase 2 ê³„íš (ì¤€ë¹„ë„ ë‚®ìŒ)"""
        return {
            'plan_type': 'ê¸°ì´ˆ ì‹œìŠ¤í…œ ì•ˆì •í™” + ë‹¨ìˆœ íƒì§€',
            'priority_tasks': [
                'ë°ì´í„° í’ˆì§ˆ ê°œì„ ',
                'ì¢Œí‘œ ë§¤í•‘ ì‹œìŠ¤í…œ ì¬êµ¬ì¶•',
                'ì„ê³„ê°’ ê¸°ë°˜ ë‹¨ìˆœ íƒì§€',
                'ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ìµœì í™”'
            ],
            'timeline': '8-12ì£¼',
            'expected_accuracy': '60-70%',
            'next_milestones': [
                'ë°ì´í„° ë¬¸ì œ í•´ê²° (3ì£¼)',
                'ì¢Œí‘œ ì‹œìŠ¤í…œ ê°œì„  (5ì£¼)',
                'ê¸°ë³¸ íƒì§€ ì•Œê³ ë¦¬ì¦˜ (8ì£¼)',
                'ì‹œìŠ¤í…œ ì•ˆì •í™” (12ì£¼)'
            ]
        }
    
    def _save_detailed_plan(self, phase2_plan, recommendations):
        """ìƒì„¸ ê³„íš ì €ì¥"""
        report = {
            'analysis_date': datetime.now().isoformat(),
            'sample_data_info': self.results['basic_info'],
            'data_quality_assessment': self.results['data_quality'],
            'preprocessing_evaluation': {
                'best_method': self.results['best_preprocessing'],
                'quality_improvements': self.results['preprocessing'][self.results['best_preprocessing']]['result'].quality_metrics
            },
            'coordinate_mapping_status': self.results.get('coordinate_mapping', {}),
            'overall_evaluation': self.results['comprehensive_evaluation'],
            'phase2_plan': phase2_plan,
            'recommendations': recommendations,
            'immediate_tasks': self.results['immediate_tasks'],
            'medium_term_tasks': self.results['medium_term_tasks']
        }
        
        # JSON ì €ì¥
        with open(self.processed_dir / 'sample_analysis_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        # ìš”ì•½ ë¦¬í¬íŠ¸ ì €ì¥
        self._save_summary_report(report)
    
    def _save_summary_report(self, report):
        """ìš”ì•½ ë¦¬í¬íŠ¸ ì €ì¥"""
        with open(self.processed_dir / 'analysis_summary.txt', 'w', encoding='utf-8') as f:
            f.write("ì‚¬ì´ë“œìŠ¤ìº” ì†Œë‚˜ ìƒ˜í”Œ ë°ì´í„° ë¶„ì„ ìš”ì•½ ë¦¬í¬íŠ¸\\n")
            f.write("=" * 60 + "\\n\\n")
            
            f.write(f"ë¶„ì„ ì¼ì‹œ: {report['analysis_date'][:19]}\\n")
            f.write(f"ë°ì´í„° íŒŒì¼: {report['sample_data_info']['filename']}\\n\\n")
            
            f.write("ğŸ“Š ë°ì´í„° í’ˆì§ˆ í‰ê°€\\n")
            f.write("-" * 30 + "\\n")
            quality = report['data_quality_assessment']
            f.write(f"- ë™ì  ë²”ìœ„: {quality['dynamic_range']:.2f}\\n")
            f.write(f"- ì¶”ì • SNR: {quality['estimated_snr']:.1f} dB\\n")
            f.write(f"- ê²°ì¸¡ì¹˜ ë¹„ìœ¨: {quality['missing_ratio']:.1%}\\n\\n")
            
            f.write("ğŸ”§ ì „ì²˜ë¦¬ ì„±ëŠ¥\\n")
            f.write("-" * 30 + "\\n")
            preprocessing = report['preprocessing_evaluation']
            f.write(f"- ìµœì  ë°©ë²•: {preprocessing['best_method']}\\n")
            f.write(f"- SNR ê°œì„ : {preprocessing['quality_improvements']['snr']:.1f} dB\\n")
            f.write(f"- ëŒ€ë¹„ í–¥ìƒ: {preprocessing['quality_improvements']['contrast_improvement']:.2f}x\\n\\n")
            
            f.write("ğŸ¯ ì¢…í•© í‰ê°€\\n")
            f.write("-" * 30 + "\\n")
            evaluation = report['overall_evaluation']
            f.write(f"- ì¤€ë¹„ë„: {evaluation['overall_readiness']}\\n")
            f.write(f"- ì ìˆ˜: {evaluation['readiness_score']:.1f}/4.0\\n\\n")
            
            f.write("ğŸ“‹ 2ë‹¨ê³„ ê³„íš\\n")
            f.write("-" * 30 + "\\n")
            plan = report['phase2_plan']
            f.write(f"- ê³„íš ìœ í˜•: {plan['plan_type']}\\n")
            f.write(f"- ì˜ˆìƒ ê¸°ê°„: {plan['timeline']}\\n")
            f.write(f"- ëª©í‘œ ì •í™•ë„: {plan['expected_accuracy']}\\n\\n")
            
            f.write("ğŸ’¡ ì¦‰ì‹œ ìˆ˜í–‰ ê³¼ì œ\\n")
            f.write("-" * 30 + "\\n")
            for i, task in enumerate(report['immediate_tasks'], 1):
                f.write(f"{i}. {task}\\n")


if __name__ == "__main__":
    analyzer = SampleDataAnalyzer()
    analyzer.run_complete_analysis()