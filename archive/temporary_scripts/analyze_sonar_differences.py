#!/usr/bin/env python3
"""
ì‚¬ì´ë“œ ìŠ¤ìº” ì†Œë‚˜ ê¸°ì¢…ë³„ ì°¨ì´ì  ë¶„ì„
=====================================
EdgeTech 4205 vs Klein 3900ì˜ íŒ¨í‚· êµ¬ì¡°, ë©”íƒ€ë°ì´í„°, ê°•ë„ ë°ì´í„° ì°¨ì´ì ì„ ë¶„ì„í•©ë‹ˆë‹¤.

Author: YMARX
Date: 2025-09-22
"""

import sys
import logging
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import json

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.data_processing.xtf_reader import XTFReader
from src.data_processing.xtf_intensity_extractor import XTFIntensityExtractor

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def analyze_sonar_system_differences():
    """ì‚¬ì´ë“œ ìŠ¤ìº” ì†Œë‚˜ ê¸°ì¢…ë³„ ì°¨ì´ì  ìƒì„¸ ë¶„ì„"""

    logger.info("="*70)
    logger.info("ì‚¬ì´ë“œ ìŠ¤ìº” ì†Œë‚˜ ê¸°ì¢…ë³„ ì°¨ì´ì  ë¶„ì„")
    logger.info("="*70)

    # ë¶„ì„í•  íŒŒì¼ë“¤
    test_files = {
        'EdgeTech_4205_1': {
            'path': "datasets/Pohang_Eardo_1_Edgetech4205_800_050_20241012110900_001_04/original/Pohang_Eardo_1_Edgetech4205_800_050_20241012110900_001_04.xtf",
            'manufacturer': 'EdgeTech',
            'model': '4205',
            'frequency': '800 kHz',
            'expected_features': ['dual_frequency', 'chirp_capability', 'high_resolution']
        },
        'EdgeTech_4205_2': {
            'path': "datasets/Pohang_Eardo_1_Edgetech4205_800_050_20241012181900_001_04/original/Pohang_Eardo_1_Edgetech4205_800_050_20241012181900_001_04.xtf",
            'manufacturer': 'EdgeTech',
            'model': '4205',
            'frequency': '800 kHz',
            'expected_features': ['dual_frequency', 'chirp_capability', 'high_resolution']
        },
        'Klein_3900': {
            'path': "datasets/Pohang_Eardo_1_Klein3900_900_050_20241011171100_001_04/original/Pohang_Eardo_1_Klein3900_900_050_20241011171100_001_04.xtf",
            'manufacturer': 'Klein',
            'model': '3900',
            'frequency': '900 kHz',
            'expected_features': ['dual_frequency', 'backscatter_analysis', 'bathymetry']
        }
    }

    analysis_results = {}

    for system_id, file_info in test_files.items():
        file_path = Path(file_info['path'])

        if not file_path.exists():
            logger.warning(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            continue

        logger.info(f"\n{'='*50}")
        logger.info(f"ë¶„ì„ ì¤‘: {file_info['manufacturer']} {file_info['model']}")
        logger.info(f"íŒŒì¼: {file_path.name}")

        try:
            # 1. XTF Readerë¡œ ê¸°ë³¸ ë¶„ì„
            reader = XTFReader(file_path, max_pings=1000)
            reader.load_file()
            ping_data = reader.parse_pings()

            # 2. Intensity Extractorë¡œ ìƒì„¸ ë¶„ì„
            extractor = XTFIntensityExtractor(max_memory_mb=256)
            extracted_data = extractor.extract_intensity_data(
                str(file_path),
                ping_range=(0, 500)
            )

            # 3. ê¸°ì¢…ë³„ íŠ¹ì„± ë¶„ì„
            system_analysis = analyze_system_characteristics(
                reader, extracted_data, file_info
            )

            analysis_results[system_id] = system_analysis

        except Exception as e:
            logger.error(f"ë¶„ì„ ì‹¤íŒ¨ ({system_id}): {e}")
            continue

    # 4. ê¸°ì¢…ë³„ ë¹„êµ ë¶„ì„
    comparison_results = compare_sonar_systems(analysis_results)

    # 5. ê²°ê³¼ ì €ì¥
    save_analysis_results(analysis_results, comparison_results)

    return analysis_results, comparison_results


def analyze_system_characteristics(reader, extracted_data, file_info):
    """ê°œë³„ ì†Œë‚˜ ì‹œìŠ¤í…œ íŠ¹ì„± ë¶„ì„"""

    logger.info(f"ì‹œìŠ¤í…œ íŠ¹ì„± ë¶„ì„: {file_info['manufacturer']} {file_info['model']}")

    analysis = {
        'manufacturer': file_info['manufacturer'],
        'model': file_info['model'],
        'frequency': file_info['frequency'],
        'file_characteristics': {},
        'packet_structure': {},
        'data_format': {},
        'performance_metrics': {},
        'unique_features': []
    }

    try:
        # 1. íŒŒì¼ íŠ¹ì„± ë¶„ì„
        metadata = reader.metadata
        if metadata:
            analysis['file_characteristics'] = {
                'total_pings': metadata.total_pings,
                'sonar_channels': metadata.num_sonar_channels,
                'bathymetry_channels': metadata.num_bathymetry_channels,
                'frequency_info': metadata.frequency_info,
                'coordinate_bounds': metadata.coordinate_bounds,
                'time_range': metadata.time_range
            }

        # 2. íŒ¨í‚· êµ¬ì¡° ë¶„ì„
        if reader.ping_data:
            sample_ping = reader.ping_data[0]

            analysis['packet_structure'] = {
                'ping_number_range': {
                    'min': min(p.ping_number for p in reader.ping_data),
                    'max': max(p.ping_number for p in reader.ping_data)
                },
                'samples_per_ping': {
                    'min': min(p.range_samples for p in reader.ping_data),
                    'max': max(p.range_samples for p in reader.ping_data),
                    'typical': sample_ping.range_samples
                },
                'coordinate_precision': {
                    'lat_precision': len(str(sample_ping.latitude).split('.')[-1]) if '.' in str(sample_ping.latitude) else 0,
                    'lon_precision': len(str(sample_ping.longitude).split('.')[-1]) if '.' in str(sample_ping.longitude) else 0
                },
                'timestamp_format': type(sample_ping.timestamp).__name__
            }

        # 3. ë°ì´í„° í¬ë§· ë¶„ì„
        intensity_images = extracted_data.get('intensity_images', {})
        if intensity_images:
            combined_img = intensity_images.get('combined', np.array([]))
            port_img = intensity_images.get('port', np.array([]))
            starboard_img = intensity_images.get('starboard', np.array([]))

            analysis['data_format'] = {
                'combined_shape': combined_img.shape if combined_img.size > 0 else None,
                'port_shape': port_img.shape if port_img.size > 0 else None,
                'starboard_shape': starboard_img.shape if starboard_img.size > 0 else None,
                'data_type': str(combined_img.dtype) if combined_img.size > 0 else None,
                'value_range': {
                    'combined': [float(combined_img.min()), float(combined_img.max())] if combined_img.size > 0 else None,
                    'port': [float(port_img.min()), float(port_img.max())] if port_img.size > 0 else None,
                    'starboard': [float(starboard_img.min()), float(starboard_img.max())] if starboard_img.size > 0 else None
                }
            }

        # 4. ì„±ëŠ¥ ì§€í‘œ ë¶„ì„
        if reader.ping_data and intensity_images:
            # ë°ì´í„° í’ˆì§ˆ ì§€í‘œ
            intensity_matrix = reader.extract_intensity_matrix()

            analysis['performance_metrics'] = {
                'data_completeness': {
                    'pings_with_coordinates': sum(1 for p in reader.ping_data if p.latitude != 0 and p.longitude != 0) / len(reader.ping_data),
                    'pings_with_intensity': sum(1 for p in reader.ping_data if p.data.size > 0) / len(reader.ping_data)
                },
                'intensity_statistics': {
                    'mean': float(intensity_matrix.mean()) if intensity_matrix.size > 0 else 0,
                    'std': float(intensity_matrix.std()) if intensity_matrix.size > 0 else 0,
                    'dynamic_range': float(intensity_matrix.max() - intensity_matrix.min()) if intensity_matrix.size > 0 else 0,
                    'signal_to_noise_estimate': estimate_snr(intensity_matrix) if intensity_matrix.size > 0 else 0
                },
                'spatial_coverage': calculate_spatial_coverage(reader.ping_data),
                'temporal_consistency': assess_temporal_consistency(reader.ping_data)
            }

        # 5. ê¸°ì¢…ë³„ ê³ ìœ  íŠ¹ì„± ì‹ë³„
        analysis['unique_features'] = identify_unique_features(file_info, reader, extracted_data)

        logger.info(f"ì‹œìŠ¤í…œ íŠ¹ì„± ë¶„ì„ ì™„ë£Œ: {len(analysis)} ì¹´í…Œê³ ë¦¬")

    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ íŠ¹ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

    return analysis


def estimate_snr(intensity_matrix):
    """Signal-to-Noise Ratio ì¶”ì •"""
    if intensity_matrix.size == 0:
        return 0

    try:
        # ê°„ë‹¨í•œ SNR ì¶”ì •: ì‹ í˜¸ì˜ í‰ê·  ëŒ€ë¹„ ë…¸ì´ì¦ˆì˜ í‘œì¤€í¸ì°¨
        signal = np.mean(intensity_matrix)
        noise = np.std(intensity_matrix[intensity_matrix < np.percentile(intensity_matrix, 20)])  # í•˜ìœ„ 20%ë¥¼ ë…¸ì´ì¦ˆë¡œ ê°€ì •
        return float(signal / noise) if noise > 0 else 0
    except:
        return 0


def calculate_spatial_coverage(ping_data):
    """ê³µê°„ì  ì»¤ë²„ë¦¬ì§€ ê³„ì‚°"""
    if not ping_data:
        return {}

    try:
        lats = [p.latitude for p in ping_data if p.latitude != 0]
        lons = [p.longitude for p in ping_data if p.longitude != 0]

        if not lats or not lons:
            return {}

        return {
            'lat_range_km': (max(lats) - min(lats)) * 111,  # ëŒ€ëµì  ë³€í™˜
            'lon_range_km': (max(lons) - min(lons)) * 111 * np.cos(np.radians(np.mean(lats))),
            'center_lat': np.mean(lats),
            'center_lon': np.mean(lons),
            'coverage_area_km2': ((max(lats) - min(lats)) * 111) * ((max(lons) - min(lons)) * 111 * np.cos(np.radians(np.mean(lats))))
        }
    except:
        return {}


def assess_temporal_consistency(ping_data):
    """ì‹œê°„ì  ì¼ê´€ì„± í‰ê°€"""
    if not ping_data:
        return {}

    try:
        # Ping ë²ˆí˜¸ì˜ ì¼ê´€ì„± í™•ì¸
        ping_numbers = [p.ping_number for p in ping_data]

        return {
            'ping_sequence_consistent': all(ping_numbers[i] <= ping_numbers[i+1] for i in range(len(ping_numbers)-1)),
            'ping_number_gaps': len(set(range(min(ping_numbers), max(ping_numbers)+1))) - len(set(ping_numbers)),
            'average_ping_interval': (max(ping_numbers) - min(ping_numbers)) / len(ping_numbers) if len(ping_numbers) > 1 else 0
        }
    except:
        return {}


def identify_unique_features(file_info, reader, extracted_data):
    """ê¸°ì¢…ë³„ ê³ ìœ  íŠ¹ì„± ì‹ë³„"""
    features = []

    try:
        manufacturer = file_info['manufacturer']
        model = file_info['model']

        # EdgeTech íŠ¹ì„±
        if manufacturer == 'EdgeTech':
            features.append('edgetech_format')

            # 4205 ëª¨ë¸ íŠ¹ì„±
            if model == '4205':
                features.append('dual_frequency_capable')
                features.append('chirp_sonar')
                features.append('high_resolution_bathymetry')

                # ë°ì´í„° êµ¬ì¡°ì—ì„œ íŠ¹ì„± í™•ì¸
                if reader.ping_data and reader.ping_data[0].data.size > 6000:
                    features.append('high_sample_rate')

        # Klein íŠ¹ì„±
        elif manufacturer == 'Klein':
            features.append('klein_format')

            # 3900 ëª¨ë¸ íŠ¹ì„±
            if model == '3900':
                features.append('dual_frequency_capable')
                features.append('sidescan_bathymetry')
                features.append('backscatter_analysis')

                # Klein íŠ¹ìœ ì˜ íŒ¨í‚· êµ¬ì¡° í™•ì¸
                if 'kleinv4_data_page' in str(extracted_data):
                    features.append('klein_v4_protocol')

        # ë°ì´í„° íŠ¹ì„± ê¸°ë°˜ íŠ¹ì„± ì‹ë³„
        intensity_images = extracted_data.get('intensity_images', {})
        if intensity_images:
            combined_img = intensity_images.get('combined', np.array([]))

            # í•´ìƒë„ íŠ¹ì„±
            if combined_img.size > 0:
                if combined_img.shape[1] > 6500:  # ë†’ì€ range resolution
                    features.append('high_range_resolution')
                elif combined_img.shape[1] < 6500:
                    features.append('standard_range_resolution')

                # ë™ì  ë²”ìœ„ íŠ¹ì„±
                dynamic_range = combined_img.max() - combined_img.min()
                if dynamic_range > 30000:
                    features.append('high_dynamic_range')
                elif dynamic_range < 5000:
                    features.append('standard_dynamic_range')

    except Exception as e:
        logger.warning(f"ê³ ìœ  íŠ¹ì„± ì‹ë³„ ì¤‘ ì˜¤ë¥˜: {e}")

    return features


def compare_sonar_systems(analysis_results):
    """ì†Œë‚˜ ì‹œìŠ¤í…œ ê°„ ë¹„êµ ë¶„ì„"""

    logger.info("ì†Œë‚˜ ì‹œìŠ¤í…œ ê°„ ë¹„êµ ë¶„ì„ ì‹œì‘")

    if len(analysis_results) < 2:
        logger.warning("ë¹„êµí•  ì‹œìŠ¤í…œì´ ë¶€ì¡±í•©ë‹ˆë‹¤")
        return {}

    comparison = {
        'manufacturer_comparison': {},
        'performance_comparison': {},
        'data_format_comparison': {},
        'feature_comparison': {},
        'recommendations': {}
    }

    try:
        # ì œì¡°ì‚¬ë³„ ê·¸ë£¹í™”
        edgetech_systems = {k: v for k, v in analysis_results.items() if v['manufacturer'] == 'EdgeTech'}
        klein_systems = {k: v for k, v in analysis_results.items() if v['manufacturer'] == 'Klein'}

        # 1. ì œì¡°ì‚¬ë³„ ë¹„êµ
        comparison['manufacturer_comparison'] = {
            'EdgeTech': {
                'count': len(edgetech_systems),
                'models': list(set(s['model'] for s in edgetech_systems.values())),
                'frequencies': list(set(s['frequency'] for s in edgetech_systems.values())),
                'avg_pings': np.mean([s['file_characteristics'].get('total_pings', 0) for s in edgetech_systems.values()]) if edgetech_systems else 0,
                'unique_features': list(set().union(*[s['unique_features'] for s in edgetech_systems.values()])) if edgetech_systems else []
            },
            'Klein': {
                'count': len(klein_systems),
                'models': list(set(s['model'] for s in klein_systems.values())),
                'frequencies': list(set(s['frequency'] for s in klein_systems.values())),
                'avg_pings': np.mean([s['file_characteristics'].get('total_pings', 0) for s in klein_systems.values()]) if klein_systems else 0,
                'unique_features': list(set().union(*[s['unique_features'] for s in klein_systems.values()])) if klein_systems else []
            }
        }

        # 2. ì„±ëŠ¥ ë¹„êµ
        all_systems = list(analysis_results.values())
        performance_metrics = [s.get('performance_metrics', {}) for s in all_systems]

        comparison['performance_comparison'] = {
            'data_completeness': {
                'coordinate_completeness': [pm.get('data_completeness', {}).get('pings_with_coordinates', 0) for pm in performance_metrics],
                'intensity_completeness': [pm.get('data_completeness', {}).get('pings_with_intensity', 0) for pm in performance_metrics]
            },
            'intensity_quality': {
                'dynamic_range': [pm.get('intensity_statistics', {}).get('dynamic_range', 0) for pm in performance_metrics],
                'snr_estimate': [pm.get('intensity_statistics', {}).get('signal_to_noise_estimate', 0) for pm in performance_metrics]
            },
            'spatial_coverage': [pm.get('spatial_coverage', {}).get('coverage_area_km2', 0) for pm in performance_metrics]
        }

        # 3. ë°ì´í„° í¬ë§· ë¹„êµ
        data_formats = [s.get('data_format', {}) for s in all_systems]
        comparison['data_format_comparison'] = {
            'sample_counts': {
                'combined_width': [df.get('combined_shape', [0, 0])[1] if df.get('combined_shape') else 0 for df in data_formats],
                'port_width': [df.get('port_shape', [0, 0])[1] if df.get('port_shape') else 0 for df in data_formats],
                'starboard_width': [df.get('starboard_shape', [0, 0])[1] if df.get('starboard_shape') else 0 for df in data_formats]
            },
            'value_ranges': {
                'max_values': [df.get('value_range', {}).get('combined', [0, 0])[1] if df.get('value_range', {}).get('combined') else 0 for df in data_formats]
            }
        }

        # 4. íŠ¹ì„± ë¹„êµ
        all_features = list(set().union(*[s['unique_features'] for s in all_systems]))
        feature_matrix = {}
        for feature in all_features:
            feature_matrix[feature] = {
                system_id: feature in system_data['unique_features']
                for system_id, system_data in analysis_results.items()
            }
        comparison['feature_comparison'] = feature_matrix

        # 5. ê¶Œì¥ì‚¬í•­ ìƒì„±
        comparison['recommendations'] = generate_recommendations(analysis_results, comparison)

        logger.info("ì†Œë‚˜ ì‹œìŠ¤í…œ ë¹„êµ ë¶„ì„ ì™„ë£Œ")

    except Exception as e:
        logger.error(f"ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

    return comparison


def generate_recommendations(analysis_results, comparison):
    """ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±"""

    recommendations = {
        'processing_optimization': [],
        'quality_improvement': [],
        'feature_utilization': [],
        'system_specific': {}
    }

    try:
        # ì²˜ë¦¬ ìµœì í™” ê¶Œì¥ì‚¬í•­
        max_samples = max([
            s.get('data_format', {}).get('combined_shape', [0, 0])[1]
            for s in analysis_results.values()
        ])

        if max_samples > 6500:
            recommendations['processing_optimization'].append(
                "ê³ í•´ìƒë„ ë°ì´í„°(>6500 samples)ì— ëŒ€í•´ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬ í•„ìš”"
            )

        # í’ˆì§ˆ ê°œì„  ê¶Œì¥ì‚¬í•­
        snr_values = [
            s.get('performance_metrics', {}).get('intensity_statistics', {}).get('signal_to_noise_estimate', 0)
            for s in analysis_results.values()
        ]

        if any(snr < 10 for snr in snr_values):
            recommendations['quality_improvement'].append(
                "ë‚®ì€ SNR ì‹œìŠ¤í…œì— ëŒ€í•´ ë…¸ì´ì¦ˆ í•„í„°ë§ ì ìš© ê¶Œì¥"
            )

        # íŠ¹ì„± í™œìš© ê¶Œì¥ì‚¬í•­
        edgetech_count = len([s for s in analysis_results.values() if s['manufacturer'] == 'EdgeTech'])
        klein_count = len([s for s in analysis_results.values() if s['manufacturer'] == 'Klein'])

        if edgetech_count > 0 and klein_count > 0:
            recommendations['feature_utilization'].append(
                "ë‹¤ì¤‘ ì œì¡°ì‚¬ ë°ì´í„° ìœµí•©ì„ í†µí•œ ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥"
            )

        # ì‹œìŠ¤í…œë³„ ê¶Œì¥ì‚¬í•­
        for system_id, system_data in analysis_results.items():
            system_rec = []

            if 'high_dynamic_range' in system_data['unique_features']:
                system_rec.append("ë†’ì€ ë™ì  ë²”ìœ„ í™œìš©í•œ ì„¸ë°€í•œ ê°ì²´ íƒì§€ ê°€ëŠ¥")

            if 'dual_frequency_capable' in system_data['unique_features']:
                system_rec.append("ë“€ì–¼ ì£¼íŒŒìˆ˜ ë°ì´í„° ìœµí•© ì²˜ë¦¬ ê¶Œì¥")

            recommendations['system_specific'][system_id] = system_rec

    except Exception as e:
        logger.warning(f"ê¶Œì¥ì‚¬í•­ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

    return recommendations


def save_analysis_results(analysis_results, comparison_results):
    """ë¶„ì„ ê²°ê³¼ ì €ì¥"""

    output_dir = Path("analysis_results/sonar_system_analysis")
    output_dir.mkdir(parents=True, exist_ok=True)

    try:
        # JSON ë°ì´í„° ì €ì¥
        full_results = {
            'analysis_timestamp': datetime.now().isoformat(),
            'individual_analysis': analysis_results,
            'comparative_analysis': comparison_results,
            'summary': {
                'total_systems_analyzed': len(analysis_results),
                'manufacturers': list(set(s['manufacturer'] for s in analysis_results.values())),
                'models': list(set(s['model'] for s in analysis_results.values())),
                'frequencies': list(set(s['frequency'] for s in analysis_results.values()))
            }
        }

        json_file = output_dir / "sonar_system_analysis_data.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(full_results, f, indent=2, ensure_ascii=False, default=str)

        # ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±
        generate_markdown_report(full_results, output_dir)

        logger.info(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_dir}")

    except Exception as e:
        logger.error(f"ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")


def generate_markdown_report(full_results, output_dir):
    """ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±"""

    analysis_results = full_results['individual_analysis']
    comparison_results = full_results['comparative_analysis']

    report_lines = []
    report_lines.append("# ì‚¬ì´ë“œ ìŠ¤ìº” ì†Œë‚˜ ê¸°ì¢…ë³„ ì°¨ì´ì  ë¶„ì„ ë³´ê³ ì„œ")
    report_lines.append(f"**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append(f"**ë¶„ì„ì**: YMARX")
    report_lines.append("")

    # ìš”ì•½
    summary = full_results['summary']
    report_lines.append("## ğŸ“Š **ë¶„ì„ ìš”ì•½**")
    report_lines.append(f"- **ë¶„ì„ëœ ì‹œìŠ¤í…œ**: {summary['total_systems_analyzed']}ê°œ")
    report_lines.append(f"- **ì œì¡°ì‚¬**: {', '.join(summary['manufacturers'])}")
    report_lines.append(f"- **ëª¨ë¸**: {', '.join(summary['models'])}")
    report_lines.append(f"- **ì£¼íŒŒìˆ˜**: {', '.join(summary['frequencies'])}")
    report_lines.append("")

    # ê°œë³„ ì‹œìŠ¤í…œ ë¶„ì„
    report_lines.append("## ğŸ” **ê°œë³„ ì‹œìŠ¤í…œ ë¶„ì„**")
    report_lines.append("")

    for system_id, system_data in analysis_results.items():
        report_lines.append(f"### {system_data['manufacturer']} {system_data['model']} ({system_data['frequency']})")

        # íŒŒì¼ íŠ¹ì„±
        file_char = system_data.get('file_characteristics', {})
        report_lines.append(f"- **ì´ Ping ìˆ˜**: {file_char.get('total_pings', 'N/A'):,}")
        report_lines.append(f"- **ì†Œë‚˜ ì±„ë„**: {file_char.get('sonar_channels', 'N/A')}")

        # ë°ì´í„° í¬ë§·
        data_format = system_data.get('data_format', {})
        if data_format.get('combined_shape'):
            report_lines.append(f"- **ë°ì´í„° í¬ê¸°**: {data_format['combined_shape'][0]} Ã— {data_format['combined_shape'][1]}")

        # ì„±ëŠ¥ ì§€í‘œ
        perf = system_data.get('performance_metrics', {})
        if perf:
            intensity_stats = perf.get('intensity_statistics', {})
            report_lines.append(f"- **í‰ê·  ê°•ë„**: {intensity_stats.get('mean', 0):.1f}")
            report_lines.append(f"- **ë™ì  ë²”ìœ„**: {intensity_stats.get('dynamic_range', 0):.1f}")
            report_lines.append(f"- **SNR ì¶”ì •**: {intensity_stats.get('signal_to_noise_estimate', 0):.2f}")

        # ê³ ìœ  íŠ¹ì„±
        features = system_data.get('unique_features', [])
        if features:
            report_lines.append(f"- **ê³ ìœ  íŠ¹ì„±**: {', '.join(features)}")

        report_lines.append("")

    # ë¹„êµ ë¶„ì„
    if comparison_results:
        report_lines.append("## âš–ï¸ **ë¹„êµ ë¶„ì„**")
        report_lines.append("")

        # ì œì¡°ì‚¬ë³„ ë¹„êµ
        mfg_comp = comparison_results.get('manufacturer_comparison', {})
        if mfg_comp:
            report_lines.append("### ì œì¡°ì‚¬ë³„ ë¹„êµ")

            for mfg, data in mfg_comp.items():
                if data['count'] > 0:
                    report_lines.append(f"**{mfg}**:")
                    report_lines.append(f"- ë¶„ì„ëœ ì‹œìŠ¤í…œ: {data['count']}ê°œ")
                    report_lines.append(f"- í‰ê·  Ping ìˆ˜: {data['avg_pings']:,.0f}")
                    report_lines.append(f"- ê³ ìœ  íŠ¹ì„±: {', '.join(data['unique_features'])}")
                    report_lines.append("")

        # ì„±ëŠ¥ ë¹„êµ
        perf_comp = comparison_results.get('performance_comparison', {})
        if perf_comp:
            report_lines.append("### ì„±ëŠ¥ ë¹„êµ")

            dynamic_ranges = perf_comp.get('intensity_quality', {}).get('dynamic_range', [])
            if dynamic_ranges:
                report_lines.append(f"- **ë™ì  ë²”ìœ„**: ìµœì†Œ {min(dynamic_ranges):.0f}, ìµœëŒ€ {max(dynamic_ranges):.0f}")

            coverage_areas = perf_comp.get('spatial_coverage', [])
            if coverage_areas and any(area > 0 for area in coverage_areas):
                valid_areas = [area for area in coverage_areas if area > 0]
                report_lines.append(f"- **ê³µê°„ ì»¤ë²„ë¦¬ì§€**: í‰ê·  {np.mean(valid_areas):.2f} kmÂ²")

            report_lines.append("")

    # ê¶Œì¥ì‚¬í•­
    recommendations = comparison_results.get('recommendations', {})
    if recommendations:
        report_lines.append("## ğŸ’¡ **ê¶Œì¥ì‚¬í•­**")
        report_lines.append("")

        for category, recs in recommendations.items():
            if recs and category != 'system_specific':
                category_name = {
                    'processing_optimization': 'ì²˜ë¦¬ ìµœì í™”',
                    'quality_improvement': 'í’ˆì§ˆ ê°œì„ ',
                    'feature_utilization': 'íŠ¹ì„± í™œìš©'
                }.get(category, category)

                report_lines.append(f"### {category_name}")
                for rec in recs:
                    report_lines.append(f"- {rec}")
                report_lines.append("")

    # ë³´ê³ ì„œ ì €ì¥
    report_file = output_dir / "SONAR_SYSTEM_ANALYSIS_REPORT.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))

    logger.info(f"ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ì €ì¥: {report_file}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ì‚¬ì´ë“œ ìŠ¤ìº” ì†Œë‚˜ ê¸°ì¢…ë³„ ì°¨ì´ì  ë¶„ì„ ì‹œì‘")

    try:
        analysis_results, comparison_results = analyze_sonar_system_differences()

        # ìš”ì•½ ì¶œë ¥
        print("\n" + "="*70)
        print("ì‚¬ì´ë“œ ìŠ¤ìº” ì†Œë‚˜ ê¸°ì¢…ë³„ ì°¨ì´ì  ë¶„ì„ ì™„ë£Œ")
        print("="*70)

        if analysis_results:
            print(f"ğŸ“Š ë¶„ì„ëœ ì‹œìŠ¤í…œ: {len(analysis_results)}ê°œ")

            manufacturers = list(set(s['manufacturer'] for s in analysis_results.values()))
            models = list(set(s['model'] for s in analysis_results.values()))

            print(f"ğŸ­ ì œì¡°ì‚¬: {', '.join(manufacturers)}")
            print(f"ğŸ“± ëª¨ë¸: {', '.join(models)}")

            # ì£¼ìš” ì°¨ì´ì  ìš”ì•½
            if len(manufacturers) > 1:
                print(f"\nğŸ” ì£¼ìš” ì°¨ì´ì :")

                # ë°ì´í„° í¬ê¸° ë¹„êµ
                data_sizes = []
                for s in analysis_results.values():
                    shape = s.get('data_format', {}).get('combined_shape')
                    if shape:
                        data_sizes.append(shape[1])

                if data_sizes:
                    print(f"   - ìƒ˜í”Œ ìˆ˜ ë²”ìœ„: {min(data_sizes)} ~ {max(data_sizes)}")

                # ë™ì  ë²”ìœ„ ë¹„êµ
                dynamic_ranges = []
                for s in analysis_results.values():
                    dr = s.get('performance_metrics', {}).get('intensity_statistics', {}).get('dynamic_range', 0)
                    if dr > 0:
                        dynamic_ranges.append(dr)

                if dynamic_ranges:
                    print(f"   - ë™ì  ë²”ìœ„: {min(dynamic_ranges):.0f} ~ {max(dynamic_ranges):.0f}")

        print(f"\nğŸ“ ìƒì„¸ ê²°ê³¼: analysis_results/sonar_system_analysis/")
        return 0

    except Exception as e:
        logger.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 1


if __name__ == "__main__":
    exit(main())