#!/usr/bin/env python3
"""
Location_MDGPSì™€ ë¶€ì‚°ìœ„ì¹˜ìë£Œ ë¹„êµ ë¶„ì„

ëª©ì : í¬í•­ Location_MDGPS ìœ„ì¹˜ì™€ ë¶€ì‚° ìœ„ì¹˜ ìë£Œì˜ ì¤‘ë³µë„ ë° ê±°ë¦¬ ë¶„ì„
"""

import pandas as pd
import numpy as np
import re
from geopy.distance import geodesic
from datetime import datetime
import logging
import matplotlib.pyplot as plt

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def parse_coordinate(coord_str):
    """ë„ë¶„ì´ˆ ì¢Œí‘œë¥¼ ì‹­ì§„ë„ë¡œ ë³€í™˜"""

    if pd.isna(coord_str) or coord_str == '':
        return None

    coord_str = str(coord_str).strip()

    # íŒ¨í„´ 1: ì´ë¯¸ ì‹­ì§„ë„ í˜•íƒœ (36.5933983 N)
    pattern1 = r'^(\d+\.?\d*)\s*([NSEW])$'
    match1 = re.match(pattern1, coord_str)
    if match1:
        value = float(match1.group(1))
        direction = match1.group(2)
        if direction in ['S', 'W']:
            value = -value
        return value

    # íŒ¨í„´ 2: ë„ ë¶„ í˜•íƒœ (129 30.557773 E)
    pattern2 = r'^(\d+)\s+(\d+\.?\d*)\s*([NSEW])$'
    match2 = re.match(pattern2, coord_str)
    if match2:
        degrees = float(match2.group(1))
        minutes = float(match2.group(2))
        direction = match2.group(3)

        value = degrees + minutes / 60.0
        if direction in ['S', 'W']:
            value = -value
        return value

    # íŒ¨í„´ 3: ë„ ë¶„ ì´ˆ í˜•íƒœ (129 30 33.4641 E)
    pattern3 = r'^(\d+)\s+(\d+)\s+(\d+\.?\d*)\s*([NSEW])$'
    match3 = re.match(pattern3, coord_str)
    if match3:
        degrees = float(match3.group(1))
        minutes = float(match3.group(2))
        seconds = float(match3.group(3))
        direction = match3.group(4)

        value = degrees + minutes / 60.0 + seconds / 3600.0
        if direction in ['S', 'W']:
            value = -value
        return value

    return None

def load_pohang_data():
    """í¬í•­ Location_MDGPS ë°ì´í„° ë¡œë“œ"""

    print("ğŸ“ í¬í•­ Location_MDGPS ë°ì´í„° ë¡œë“œ ì¤‘...")

    try:
        df = pd.read_excel("datasets/Location_MDGPS.xlsx")

        # ì¢Œí‘œ ë³€í™˜
        df['ìœ„ë„_ì‹­ì§„ë„'] = df['ìœ„ë„'].apply(parse_coordinate)
        df['ê²½ë„_ì‹­ì§„ë„'] = df['ê²½ë„'].apply(parse_coordinate)

        valid_coords = df.dropna(subset=['ìœ„ë„_ì‹­ì§„ë„', 'ê²½ë„_ì‹­ì§„ë„'])

        print(f"   í¬í•­ ë°ì´í„°: {len(valid_coords)}ê°œ ì¢Œí‘œ")
        print(f"   ìœ„ë„ ë²”ìœ„: {valid_coords['ìœ„ë„_ì‹­ì§„ë„'].min():.6f} ~ {valid_coords['ìœ„ë„_ì‹­ì§„ë„'].max():.6f}")
        print(f"   ê²½ë„ ë²”ìœ„: {valid_coords['ê²½ë„_ì‹­ì§„ë„'].min():.6f} ~ {valid_coords['ê²½ë„_ì‹­ì§„ë„'].max():.6f}")

        return valid_coords[['ì •ì ', 'ìœ„ë„_ì‹­ì§„ë„', 'ê²½ë„_ì‹­ì§„ë„']].copy()

    except Exception as e:
        print(f"âŒ í¬í•­ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def load_busan_data():
    """ë¶€ì‚° ìœ„ì¹˜ìë£Œ ë°ì´í„° ë¡œë“œ"""

    print("\nğŸ“ ë¶€ì‚° ìœ„ì¹˜ìë£Œ ë°ì´í„° ë¡œë“œ ì¤‘...")

    busan_file = "[ìƒ˜í”Œ]ë°ì´í„°/[ìœ„ì¹˜]ë¶€ì‚°ìœ„ì¹˜ìë£Œ-ë„ë¶„ì´ˆ-ìœ„ê²½ë„ë³€í™˜.xlsx"

    try:
        # Excel íŒŒì¼ ì½ê¸° (ì‹œíŠ¸ê°€ ì—¬ëŸ¬ ê°œ ìˆì„ ìˆ˜ ìˆìŒ)
        try:
            df = pd.read_excel(busan_file)
        except:
            # ì²« ë²ˆì§¸ ì‹œíŠ¸ë§Œ ì½ê¸°
            df = pd.read_excel(busan_file, sheet_name=0)

        print(f"   ë¶€ì‚° ë°ì´í„° ê¸°ë³¸ ì •ë³´:")
        print(f"   í–‰ ìˆ˜: {len(df)}")
        print(f"   ì»¬ëŸ¼: {list(df.columns)}")

        # ìƒìœ„ ëª‡ í–‰ ì¶œë ¥
        print(f"\n   ë°ì´í„° ìƒ˜í”Œ:")
        print(df.head().to_string())

        # ì¢Œí‘œ ì»¬ëŸ¼ ì°¾ê¸°
        lat_columns = []
        lon_columns = []

        for col in df.columns:
            col_lower = str(col).lower()
            if any(term in col_lower for term in ['lat', 'ìœ„ë„', 'latitude']):
                lat_columns.append(col)
            elif any(term in col_lower for term in ['lon', 'lng', 'ê²½ë„', 'longitude']):
                lon_columns.append(col)

        print(f"\n   ì¢Œí‘œ ì»¬ëŸ¼:")
        print(f"   ìœ„ë„: {lat_columns}")
        print(f"   ê²½ë„: {lon_columns}")

        # ì¢Œí‘œ ë³€í™˜
        if lat_columns and lon_columns:
            lat_col = lat_columns[0]
            lon_col = lon_columns[0]

            df['ìœ„ë„_ì‹­ì§„ë„'] = df[lat_col].apply(parse_coordinate)
            df['ê²½ë„_ì‹­ì§„ë„'] = df[lon_col].apply(parse_coordinate)

            valid_coords = df.dropna(subset=['ìœ„ë„_ì‹­ì§„ë„', 'ê²½ë„_ì‹­ì§„ë„'])

            print(f"\n   ë³€í™˜ ê²°ê³¼:")
            print(f"   ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ëœ ì¢Œí‘œ: {len(valid_coords)}/{len(df)}")

            if len(valid_coords) > 0:
                print(f"   ìœ„ë„ ë²”ìœ„: {valid_coords['ìœ„ë„_ì‹­ì§„ë„'].min():.6f} ~ {valid_coords['ìœ„ë„_ì‹­ì§„ë„'].max():.6f}")
                print(f"   ê²½ë„ ë²”ìœ„: {valid_coords['ê²½ë„_ì‹­ì§„ë„'].min():.6f} ~ {valid_coords['ê²½ë„_ì‹­ì§„ë„'].max():.6f}")

                # ì •ì ëª… ì»¬ëŸ¼ ì°¾ê¸°
                point_col = None
                for col in df.columns:
                    col_lower = str(col).lower()
                    if any(term in col_lower for term in ['ì •ì ', 'point', 'station', 'ë²ˆí˜¸', 'id']):
                        point_col = col
                        break

                if point_col:
                    return valid_coords[[point_col, 'ìœ„ë„_ì‹­ì§„ë„', 'ê²½ë„_ì‹­ì§„ë„']].copy().rename(columns={point_col: 'ì •ì '})
                else:
                    # ì¸ë±ìŠ¤ë¥¼ ì •ì ëª…ìœ¼ë¡œ ì‚¬ìš©
                    valid_coords['ì •ì '] = 'BS_' + (valid_coords.index + 1).astype(str)
                    return valid_coords[['ì •ì ', 'ìœ„ë„_ì‹­ì§„ë„', 'ê²½ë„_ì‹­ì§„ë„']].copy()

        return None

    except Exception as e:
        print(f"âŒ ë¶€ì‚° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None

def calculate_distances_and_overlaps(pohang_data, busan_data):
    """ë‘ ë°ì´í„°ì…‹ ê°„ ê±°ë¦¬ ê³„ì‚° ë° ì¤‘ë³µ ë¶„ì„"""

    print(f"\nğŸ” ê±°ë¦¬ ë¶„ì„ ë° ì¤‘ë³µë„ ê³„ì‚° ì¤‘...")

    results = {
        'pohang_count': len(pohang_data),
        'busan_count': len(busan_data),
        'distance_matrix': [],
        'closest_pairs': [],
        'overlap_analysis': {},
        'regional_analysis': {}
    }

    # ê° í¬í•­ ì¢Œí‘œì— ëŒ€í•´ ë¶€ì‚° ì¢Œí‘œì™€ì˜ ìµœë‹¨ ê±°ë¦¬ ê³„ì‚°
    for _, ph_row in pohang_data.iterrows():
        ph_point = (ph_row['ìœ„ë„_ì‹­ì§„ë„'], ph_row['ê²½ë„_ì‹­ì§„ë„'])
        ph_name = ph_row['ì •ì ']

        min_distance = float('inf')
        closest_busan = None

        distances_to_busan = []

        for _, bs_row in busan_data.iterrows():
            bs_point = (bs_row['ìœ„ë„_ì‹­ì§„ë„'], bs_row['ê²½ë„_ì‹­ì§„ë„'])
            bs_name = bs_row['ì •ì ']

            distance = geodesic(ph_point, bs_point).kilometers
            distances_to_busan.append({
                'pohang_point': ph_name,
                'busan_point': bs_name,
                'distance_km': distance,
                'pohang_coords': ph_point,
                'busan_coords': bs_point
            })

            if distance < min_distance:
                min_distance = distance
                closest_busan = bs_name

        results['distance_matrix'].extend(distances_to_busan)
        results['closest_pairs'].append({
            'pohang_point': ph_name,
            'closest_busan_point': closest_busan,
            'distance_km': min_distance,
            'pohang_coords': ph_point
        })

    # ê±°ë¦¬ í†µê³„
    all_distances = [pair['distance_km'] for pair in results['closest_pairs']]

    results['distance_stats'] = {
        'min_distance': min(all_distances),
        'max_distance': max(all_distances),
        'mean_distance': np.mean(all_distances),
        'median_distance': np.median(all_distances),
        'std_distance': np.std(all_distances)
    }

    # ì¤‘ë³µë„ ë¶„ì„ (ê±°ë¦¬ ê¸°ì¤€)
    overlap_thresholds = [1, 5, 10, 20, 50, 100]
    for threshold in overlap_thresholds:
        overlap_count = len([d for d in all_distances if d <= threshold])
        overlap_percentage = (overlap_count / len(all_distances)) * 100
        results['overlap_analysis'][f'{threshold}km'] = {
            'count': overlap_count,
            'percentage': overlap_percentage
        }

    print(f"   ê±°ë¦¬ í†µê³„:")
    print(f"   ìµœë‹¨ ê±°ë¦¬: {results['distance_stats']['min_distance']:.1f} km")
    print(f"   ìµœì¥ ê±°ë¦¬: {results['distance_stats']['max_distance']:.1f} km")
    print(f"   í‰ê·  ê±°ë¦¬: {results['distance_stats']['mean_distance']:.1f} km")
    print(f"   ì¤‘ê°„ ê±°ë¦¬: {results['distance_stats']['median_distance']:.1f} km")

    return results

def analyze_regional_distribution(pohang_data, busan_data, results):
    """ì§€ì—­ë³„ ë¶„í¬ ë¶„ì„"""

    print(f"\nğŸ—ºï¸ ì§€ì—­ë³„ ë¶„í¬ ë¶„ì„...")

    # í¬í•­ ë°ì´í„° ì¤‘ì‹¬ì 
    ph_center_lat = pohang_data['ìœ„ë„_ì‹­ì§„ë„'].mean()
    ph_center_lon = pohang_data['ê²½ë„_ì‹­ì§„ë„'].mean()

    # ë¶€ì‚° ë°ì´í„° ì¤‘ì‹¬ì 
    bs_center_lat = busan_data['ìœ„ë„_ì‹­ì§„ë„'].mean()
    bs_center_lon = busan_data['ê²½ë„_ì‹­ì§„ë„'].mean()

    # ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬
    center_distance = geodesic((ph_center_lat, ph_center_lon), (bs_center_lat, bs_center_lon)).kilometers

    print(f"   í¬í•­ ë°ì´í„° ì¤‘ì‹¬: {ph_center_lat:.6f}, {ph_center_lon:.6f}")
    print(f"   ë¶€ì‚° ë°ì´í„° ì¤‘ì‹¬: {bs_center_lat:.6f}, {bs_center_lon:.6f}")
    print(f"   ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬: {center_distance:.1f} km")

    # ì§€ì—­ íŒë‹¨
    def get_region(lat, lon):
        if lat >= 36.0 and lon >= 129.0:
            if lat >= 36.5:
                return "í¬í•­ ë¶ë¶€ í•´ì—­"
            else:
                return "í¬í•­ ë‚¨ë¶€ í•´ì—­"
        elif lat >= 35.0 and lat < 36.0 and lon >= 128.5:
            return "ë¶€ì‚°/ìš¸ì‚° í•´ì—­"
        elif lat >= 35.0 and lat < 36.0 and lon < 128.5:
            return "ë‚¨í•´ ì„œë¶€"
        else:
            return "ê¸°íƒ€ í•´ì—­"

    ph_region = get_region(ph_center_lat, ph_center_lon)
    bs_region = get_region(bs_center_lat, bs_center_lon)

    results['regional_analysis'] = {
        'pohang_center': (ph_center_lat, ph_center_lon),
        'busan_center': (bs_center_lat, bs_center_lon),
        'center_distance': center_distance,
        'pohang_region': ph_region,
        'busan_region': bs_region,
        'same_region': ph_region == bs_region
    }

    print(f"   í¬í•­ ë°ì´í„° ì§€ì—­: {ph_region}")
    print(f"   ë¶€ì‚° ë°ì´í„° ì§€ì—­: {bs_region}")
    print(f"   ë™ì¼ ì§€ì—­ ì—¬ë¶€: {'ì˜ˆ' if results['regional_analysis']['same_region'] else 'ì•„ë‹ˆì˜¤'}")

    return results

def generate_comparison_report(results):
    """ë¹„êµ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""

    from pathlib import Path
    import json

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path("analysis_results/busan_pohang_comparison")
    output_dir.mkdir(parents=True, exist_ok=True)

    # JSON ê²°ê³¼ ì €ì¥ (ê±°ë¦¬ ë§¤íŠ¸ë¦­ìŠ¤ëŠ” ë„ˆë¬´ í¬ë¯€ë¡œ ìš”ì•½ë§Œ)
    summary_results = results.copy()
    summary_results['distance_matrix'] = f"ì´ {len(results['distance_matrix'])}ê°œ ê±°ë¦¬ ê³„ì‚°"

    detail_file = output_dir / "busan_pohang_comparison_detail.json"
    with open(detail_file, 'w', encoding='utf-8') as f:
        json.dump(summary_results, f, indent=2, ensure_ascii=False, default=str)

    # ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±
    report_file = output_dir / "BUSAN_POHANG_LOCATION_COMPARISON_REPORT.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(f"""# ë¶€ì‚°-í¬í•­ ìœ„ì¹˜ ë°ì´í„° ë¹„êµ ë¶„ì„ ë³´ê³ ì„œ
**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ë¶„ì„ì**: YMARX

## ğŸ¯ **ë¶„ì„ ëª©ì **
Location_MDGPS(í¬í•­)ì™€ ë¶€ì‚°ìœ„ì¹˜ìë£Œì˜ ì§€ë¦¬ì  ì¤‘ë³µë„ ë° ê´€ê³„ ë¶„ì„

## ğŸ“Š **ë°ì´í„° ê°œìš”**
- **í¬í•­ ë°ì´í„°**: {results['pohang_count']}ê°œ ì¢Œí‘œ
- **ë¶€ì‚° ë°ì´í„°**: {results['busan_count']}ê°œ ì¢Œí‘œ
- **ì´ ê±°ë¦¬ ê³„ì‚°**: {len(results['distance_matrix'])}íšŒ

## ğŸ“ **ê±°ë¦¬ ë¶„ì„ ê²°ê³¼**

### í†µê³„ ìš”ì•½
- **ìµœë‹¨ ê±°ë¦¬**: {results['distance_stats']['min_distance']:.1f} km
- **ìµœì¥ ê±°ë¦¬**: {results['distance_stats']['max_distance']:.1f} km
- **í‰ê·  ê±°ë¦¬**: {results['distance_stats']['mean_distance']:.1f} km
- **ì¤‘ê°„ê°’ ê±°ë¦¬**: {results['distance_stats']['median_distance']:.1f} km
- **í‘œì¤€í¸ì°¨**: {results['distance_stats']['std_distance']:.1f} km

### ê±°ë¦¬ë³„ ì¤‘ë³µë„ ë¶„ì„
""")

        for threshold, data in results['overlap_analysis'].items():
            f.write(f"- **{threshold} ì´ë‚´**: {data['count']}ê°œ ({data['percentage']:.1f}%)\n")

        f.write(f"""

## ğŸ—ºï¸ **ì§€ì—­ ë¶„ì„**

### ì¤‘ì‹¬ì  ìœ„ì¹˜
- **í¬í•­ ë°ì´í„° ì¤‘ì‹¬**: {results['regional_analysis']['pohang_center'][0]:.6f}Â°N, {results['regional_analysis']['pohang_center'][1]:.6f}Â°E
- **ë¶€ì‚° ë°ì´í„° ì¤‘ì‹¬**: {results['regional_analysis']['busan_center'][0]:.6f}Â°N, {results['regional_analysis']['busan_center'][1]:.6f}Â°E
- **ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬**: {results['regional_analysis']['center_distance']:.1f} km

### ì§€ì—­ ë¶„ë¥˜
- **í¬í•­ ë°ì´í„°**: {results['regional_analysis']['pohang_region']}
- **ë¶€ì‚° ë°ì´í„°**: {results['regional_analysis']['busan_region']}
- **ë™ì¼ ì§€ì—­**: {'ì˜ˆ' if results['regional_analysis']['same_region'] else 'ì•„ë‹ˆì˜¤'}

## ğŸ¯ **ì¤‘ë³µë„ í‰ê°€**

### ë†’ì€ ì¤‘ë³µë„ (< 10km)
""")

        high_overlap = results['overlap_analysis']['10km']
        f.write(f"- **ì¤‘ë³µ í¬ì¸íŠ¸**: {high_overlap['count']}ê°œ ({high_overlap['percentage']:.1f}%)\n")

        if high_overlap['percentage'] > 50:
            overlap_level = "ë§¤ìš° ë†’ìŒ"
            explanation = "ë‘ ë°ì´í„°ì…‹ì´ ê±°ì˜ ê°™ì€ ì§€ì—­ì„ ëŒ€ìƒìœ¼ë¡œ í•¨"
        elif high_overlap['percentage'] > 20:
            overlap_level = "ë†’ìŒ"
            explanation = "ìƒë‹¹ ë¶€ë¶„ ì¤‘ë³µë˜ëŠ” ì§€ì—­ì´ ì¡´ì¬"
        elif high_overlap['percentage'] > 5:
            overlap_level = "ë³´í†µ"
            explanation = "ë¶€ë¶„ì ìœ¼ë¡œ ì¤‘ë³µë˜ëŠ” ì˜ì—­ì´ ìˆìŒ"
        else:
            overlap_level = "ë‚®ìŒ"
            explanation = "ì„œë¡œ ë‹¤ë¥¸ ì§€ì—­ì˜ ë°ì´í„°"

        f.write(f"- **ì¤‘ë³µë„ í‰ê°€**: {overlap_level}\n")
        f.write(f"- **í•´ì„**: {explanation}\n")

        f.write(f"""

## ğŸ” **ê°€ì¥ ê°€ê¹Œìš´ í¬ì¸íŠ¸ë“¤**

""")

        # ìƒìœ„ 5ê°œ ê°€ì¥ ê°€ê¹Œìš´ ìŒë“¤
        closest_pairs = sorted(results['closest_pairs'], key=lambda x: x['distance_km'])[:5]
        for i, pair in enumerate(closest_pairs, 1):
            f.write(f"### {i}. {pair['pohang_point']} â†” {pair['closest_busan_point']}\n")
            f.write(f"- **ê±°ë¦¬**: {pair['distance_km']:.1f} km\n")
            f.write(f"- **í¬í•­ ì¢Œí‘œ**: {pair['pohang_coords'][0]:.6f}, {pair['pohang_coords'][1]:.6f}\n\n")

        f.write(f"""

## ğŸ’¡ **ê²°ë¡ **

### ì§€ë¦¬ì  ê´€ê³„
""")

        if results['distance_stats']['mean_distance'] < 50:
            f.write("- **ê·¼ì ‘í•œ í•´ì—­**: ë‘ ë°ì´í„°ì…‹ ëª¨ë‘ ì¸ì ‘í•œ í•´ì—­ì— ìœ„ì¹˜\n")
        elif results['distance_stats']['mean_distance'] < 200:
            f.write("- **ê°™ì€ ê¶Œì—­**: ë™ì¼í•œ í•´ì—­ ê¶Œì—­ ë‚´ ì„œë¡œ ë‹¤ë¥¸ ì§€ì \n")
        else:
            f.write("- **ì„œë¡œ ë‹¤ë¥¸ í•´ì—­**: ì§€ë¦¬ì ìœ¼ë¡œ ë¶„ë¦¬ëœ ë³„ê°œ í•´ì—­\n")

        f.write(f"""
### ë°ì´í„° íŠ¹ì„±
- **í‰ê·  ê±°ë¦¬ {results['distance_stats']['mean_distance']:.1f}km**: """)

        if results['distance_stats']['mean_distance'] < 20:
            f.write("ê±°ì˜ ë™ì¼í•œ ì¡°ì‚¬ êµ¬ì—­\n")
        elif results['distance_stats']['mean_distance'] < 100:
            f.write("ì¸ì ‘í•œ ì¡°ì‚¬ êµ¬ì—­ë“¤\n")
        else:
            f.write("ì„œë¡œ ë‹¤ë¥¸ ì¡°ì‚¬ ëª©ì ì˜ ë³„ê°œ êµ¬ì—­\n")

        f.write(f"""
### ìµœì¢… íŒë‹¨
""")

        if high_overlap['percentage'] > 30:
            f.write("**ë†’ì€ ì¤‘ë³µë„**: ë‘ ë°ì´í„°ëŠ” ìƒë‹¹ ë¶€ë¶„ ì¤‘ë³µë˜ëŠ” ì§€ì—­ì„ ë‹¤ë£¸\n")
        elif high_overlap['percentage'] > 10:
            f.write("**ë¶€ë¶„ ì¤‘ë³µ**: ì¼ë¶€ ì§€ì—­ì—ì„œ ì¤‘ë³µë˜ëŠ” ì¡°ì‚¬ ì§€ì  ì¡´ì¬\n")
        else:
            f.write("**ë³„ê°œ ì§€ì—­**: ì„œë¡œ ë‹¤ë¥¸ ëª©ì ì˜ ë…ë¦½ì ì¸ ì¡°ì‚¬ ì§€ì—­\n")

    print(f"\nğŸ“ ë³´ê³ ì„œ ì €ì¥: {report_file}")
    return report_file

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print("="*70)
    print("ë¶€ì‚°-í¬í•­ ìœ„ì¹˜ ë°ì´í„° ë¹„êµ ë¶„ì„")
    print("="*70)

    try:
        # 1. í¬í•­ ë°ì´í„° ë¡œë“œ
        pohang_data = load_pohang_data()
        if pohang_data is None:
            return False

        # 2. ë¶€ì‚° ë°ì´í„° ë¡œë“œ
        busan_data = load_busan_data()
        if busan_data is None:
            return False

        # 3. ê±°ë¦¬ ë° ì¤‘ë³µë„ ê³„ì‚°
        results = calculate_distances_and_overlaps(pohang_data, busan_data)

        # 4. ì§€ì—­ ë¶„ì„
        results = analyze_regional_distribution(pohang_data, busan_data, results)

        # 5. ë³´ê³ ì„œ ìƒì„±
        report_file = generate_comparison_report(results)

        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print(f"\n{'='*70}")
        print("ğŸ¯ ë¹„êµ ë¶„ì„ ê²°ê³¼")
        print(f"{'='*70}")

        print(f"\nğŸ“Š ê¸°ë³¸ ì •ë³´:")
        print(f"   í¬í•­ ì¢Œí‘œ: {results['pohang_count']}ê°œ")
        print(f"   ë¶€ì‚° ì¢Œí‘œ: {results['busan_count']}ê°œ")

        print(f"\nğŸ“ ê±°ë¦¬ ë¶„ì„:")
        print(f"   í‰ê·  ê±°ë¦¬: {results['distance_stats']['mean_distance']:.1f} km")
        print(f"   ìµœë‹¨ ê±°ë¦¬: {results['distance_stats']['min_distance']:.1f} km")
        print(f"   ìµœì¥ ê±°ë¦¬: {results['distance_stats']['max_distance']:.1f} km")

        print(f"\nğŸ¯ ì¤‘ë³µë„ ë¶„ì„:")
        for threshold in ['10km', '50km', '100km']:
            data = results['overlap_analysis'][threshold]
            print(f"   {threshold} ì´ë‚´: {data['count']}ê°œ ({data['percentage']:.1f}%)")

        print(f"\nğŸ—ºï¸ ì§€ì—­ ë¶„ì„:")
        print(f"   ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬: {results['regional_analysis']['center_distance']:.1f} km")
        print(f"   í¬í•­ ì§€ì—­: {results['regional_analysis']['pohang_region']}")
        print(f"   ë¶€ì‚° ì§€ì—­: {results['regional_analysis']['busan_region']}")

        return True

    except Exception as e:
        logger.error(f"ë¹„êµ ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ ë¶€ì‚°-í¬í•­ ìœ„ì¹˜ ë°ì´í„° ë¹„êµ ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("\nâŒ ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")