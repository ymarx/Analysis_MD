#!/usr/bin/env python3
"""
4ë‹¨ê³„: íŠ¹ì§• ì¶”ì¶œ ëª¨ë“ˆë“¤ (ì—¬ëŸ¬ ê¸°ë²•) ê²€ì¦ - ìˆ˜ì •ëœ ë²„ì „

ëª©ì : ì‹¤ì œ êµ¬í˜„ëœ í´ë˜ìŠ¤ë“¤ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§• ì¶”ì¶œ ê¸°ë²•ê³¼ ì•™ìƒë¸” ì‹œìŠ¤í…œ ê²€ì¦
"""

import os
import sys
from pathlib import Path
import logging
import numpy as np
import json
from datetime import datetime
import matplotlib.pyplot as plt

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_feature_extractors_import_corrected():
    """íŠ¹ì§• ì¶”ì¶œ ëª¨ë“ˆë“¤ import í…ŒìŠ¤íŠ¸ - ìˆ˜ì •ëœ í´ë˜ìŠ¤ëª…"""

    print("ğŸ”§ íŠ¹ì§• ì¶”ì¶œ ëª¨ë“ˆë“¤ Import í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ í´ë˜ìŠ¤ëª…):")

    extractors = {}
    import_results = {}

    # HOG Extractor - ì‹¤ì œ í´ë˜ìŠ¤ëª… í™•ì¸
    try:
        from src.feature_extraction.hog_extractor import MultiScaleHOGExtractor
        extractors['HOG'] = MultiScaleHOGExtractor
        import_results['HOG'] = True
        print("   âœ… MultiScaleHOGExtractor import ì„±ê³µ")
    except Exception as e:
        print(f"   âŒ HOG Extractor import ì‹¤íŒ¨: {e}")
        import_results['HOG'] = False

    # LBP Extractor - ì‹¤ì œ í´ë˜ìŠ¤ëª… í™•ì¸
    try:
        from src.feature_extraction.lbp_extractor import ComprehensiveLBPExtractor
        extractors['LBP'] = ComprehensiveLBPExtractor
        import_results['LBP'] = True
        print("   âœ… ComprehensiveLBPExtractor import ì„±ê³µ")
    except Exception as e:
        print(f"   âŒ LBP Extractor import ì‹¤íŒ¨: {e}")
        import_results['LBP'] = False

    # Gabor Extractor - ì‹¤ì œ í´ë˜ìŠ¤ëª… í™•ì¸
    try:
        from src.feature_extraction.gabor_extractor import GaborFeatureExtractor
        extractors['Gabor'] = GaborFeatureExtractor
        import_results['Gabor'] = True
        print("   âœ… GaborFeatureExtractor import ì„±ê³µ")
    except Exception as e:
        print(f"   âŒ Gabor Extractor import ì‹¤íŒ¨: {e}")
        import_results['Gabor'] = False

    # SFS Extractor - ì‹¤ì œ í´ë˜ìŠ¤ëª… í™•ì¸
    try:
        from src.feature_extraction.sfs_extractor import EnhancedSfSExtractor
        extractors['SFS'] = EnhancedSfSExtractor
        import_results['SFS'] = True
        print("   âœ… EnhancedSfSExtractor import ì„±ê³µ")
    except Exception as e:
        print(f"   âŒ SFS Extractor import ì‹¤íŒ¨: {e}")
        import_results['SFS'] = False

    # Feature Ensemble
    try:
        from src.feature_extraction.feature_ensemble import FeatureEnsemble
        extractors['Ensemble'] = FeatureEnsemble
        import_results['Ensemble'] = True
        print("   âœ… FeatureEnsemble import ì„±ê³µ")
    except Exception as e:
        print(f"   âŒ Feature Ensemble import ì‹¤íŒ¨: {e}")
        import_results['Ensemble'] = False

    return extractors, import_results

def create_test_sonar_patches():
    """í…ŒìŠ¤íŠ¸ìš© ì†Œë‚˜ íŒ¨ì¹˜ ì´ë¯¸ì§€ë“¤ ìƒì„±"""

    patches = []

    # 1. ê¸°ë¬¼ íŒ¨ì¹˜ (ê°•í•œ ë°˜ì‚¬ì²´)
    mine_patch = np.zeros((64, 64), dtype=np.float32)
    center = 32
    for i in range(64):
        for j in range(64):
            dist = np.sqrt((i - center)**2 + (j - center)**2)
            if dist < 15:
                mine_patch[i, j] = 0.8 * np.exp(-(dist**2) / (2 * 8**2))
    mine_patch += np.random.normal(0, 0.05, (64, 64))
    patches.append(np.clip(mine_patch, 0, 1))

    # 2. í•´ì €ë©´ íŒ¨ì¹˜ (ê· ë“±í•œ ë°˜ì‚¬)
    seafloor_patch = np.random.normal(0.4, 0.1, (64, 64))
    patches.append(np.clip(seafloor_patch, 0, 1))

    # 3. ìŒí–¥ ê·¸ë¦¼ì íŒ¨ì¹˜ (ì–´ë‘ìš´ ì˜ì—­)
    shadow_patch = np.random.normal(0.1, 0.05, (64, 64))
    patches.append(np.clip(shadow_patch, 0, 1))

    return patches, ['Mine', 'Seafloor', 'Shadow']

def test_individual_extractors_corrected(extractors, import_results):
    """ê°œë³„ íŠ¹ì§• ì¶”ì¶œê¸° í…ŒìŠ¤íŠ¸ - ìˆ˜ì •ëœ ë²„ì „"""

    print("ğŸ”§ ê°œë³„ íŠ¹ì§• ì¶”ì¶œê¸° í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ ë©”ì„œë“œëª…):")

    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    test_patches, patch_labels = create_test_sonar_patches()
    print(f"   ğŸ“Š í…ŒìŠ¤íŠ¸ íŒ¨ì¹˜: {len(test_patches)}ê°œ ({', '.join(patch_labels)})")

    extraction_results = {}

    for extractor_name, extractor_class in extractors.items():
        if extractor_name == 'Ensemble':  # ì•™ìƒë¸”ì€ ë³„ë„ í…ŒìŠ¤íŠ¸
            continue

        if not import_results.get(extractor_name):
            continue

        print(f"\n   ğŸ”¬ {extractor_name} Extractor í…ŒìŠ¤íŠ¸:")

        try:
            # ì¶”ì¶œê¸° ì´ˆê¸°í™”
            extractor = extractor_class()
            print(f"      âœ… {extractor_name} ì´ˆê¸°í™” ì„±ê³µ")

            # ê° íŒ¨ì¹˜ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
            features_list = []
            for i, patch in enumerate(test_patches):
                try:
                    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (uint8ë¡œ ë³€í™˜)
                    if patch.dtype != np.uint8:
                        patch_processed = (patch * 255).astype(np.uint8)
                    else:
                        patch_processed = patch

                    # íŠ¹ì§• ì¶”ì¶œ ë©”ì„œë“œ ì‹œë„
                    features = None

                    # ì¼ë°˜ì ì¸ ë©”ì„œë“œëª…ë“¤ ì‹œë„
                    method_names = [
                        'extract_features', 'extract', 'compute', 'compute_features',
                        'get_features', 'process', 'analyze'
                    ]

                    for method_name in method_names:
                        if hasattr(extractor, method_name):
                            try:
                                method = getattr(extractor, method_name)
                                features = method(patch_processed)
                                if features is not None:
                                    print(f"      âœ… {patch_labels[i]} íŒ¨ì¹˜: {method_name}() ì„±ê³µ")
                                    break
                            except Exception as method_error:
                                print(f"      âš ï¸ {method_name}() ì‹œë„ ì‹¤íŒ¨: {method_error}")
                                continue

                    if features is not None:
                        features_array = np.array(features)
                        if features_array.size > 0:
                            features_list.append(features_array.flatten())
                            print(f"         íŠ¹ì§• í¬ê¸°: {features_array.shape} -> {features_array.flatten().shape}")
                        else:
                            print(f"      âŒ {patch_labels[i]} íŒ¨ì¹˜: ë¹ˆ íŠ¹ì§• ë²¡í„°")
                    else:
                        print(f"      âŒ {patch_labels[i]} íŒ¨ì¹˜: ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ì„œë“œ ì—†ìŒ")
                        # ì‚¬ìš© ê°€ëŠ¥í•œ public ë©”ì„œë“œë“¤ ì¶œë ¥
                        methods = [m for m in dir(extractor) if callable(getattr(extractor, m)) and not m.startswith('_')]
                        print(f"         ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ì„œë“œ: {methods[:5]}...")

                except Exception as e:
                    print(f"      âŒ {patch_labels[i]} íŒ¨ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

            # ê²°ê³¼ ì •ë¦¬
            if features_list:
                features_array = np.array(features_list)
                extraction_results[extractor_name] = {
                    'success': True,
                    'feature_shape': features_array.shape,
                    'feature_stats': {
                        'mean': np.mean(features_array),
                        'std': np.std(features_array),
                        'min': np.min(features_array),
                        'max': np.max(features_array)
                    },
                    'samples_processed': len(features_list)
                }
                print(f"      ğŸ“Š ìµœì¢… íŠ¹ì§• í¬ê¸°: {features_array.shape}")
                print(f"      ğŸ“Š íŠ¹ì§• í†µê³„: mean={np.mean(features_array):.3f}, std={np.std(features_array):.3f}")
            else:
                extraction_results[extractor_name] = {
                    'success': False,
                    'error': 'íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨ - ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ì„œë“œ ì—†ìŒ'
                }

        except Exception as e:
            print(f"      âŒ {extractor_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            extraction_results[extractor_name] = {
                'success': False,
                'error': str(e)
            }

    return extraction_results

def test_feature_ensemble_corrected(extractors, import_results):
    """íŠ¹ì§• ì•™ìƒë¸” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ - ìˆ˜ì •ëœ ë²„ì „"""

    print("\nğŸ”§ íŠ¹ì§• ì•™ìƒë¸” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:")

    if not import_results.get('Ensemble'):
        print("   âŒ Feature Ensemble import ì‹¤íŒ¨ë¡œ í…ŒìŠ¤íŠ¸ ë¶ˆê°€")
        return {'success': False, 'error': 'Import ì‹¤íŒ¨'}

    try:
        from src.feature_extraction.feature_ensemble import FeatureEnsemble

        # ì•™ìƒë¸” ì´ˆê¸°í™”
        ensemble = FeatureEnsemble()
        print("   âœ… Feature Ensemble ì´ˆê¸°í™” ì„±ê³µ")

        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        test_patches, patch_labels = create_test_sonar_patches()

        # ì•™ìƒë¸”ì˜ ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ì„œë“œ í™•ì¸
        ensemble_methods = [m for m in dir(ensemble) if callable(getattr(ensemble, m)) and not m.startswith('_')]
        print(f"   ğŸ“‹ ì•™ìƒë¸” ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ì„œë“œ: {ensemble_methods[:10]}...")

        # ì•™ìƒë¸” íŠ¹ì§• ì¶”ì¶œ ì‹œë„
        ensemble_features = []
        for i, patch in enumerate(test_patches):
            try:
                patch_uint8 = (patch * 255).astype(np.uint8)

                # ë‹¤ì–‘í•œ ì•™ìƒë¸” ë©”ì„œë“œ ì‹œë„
                features = None
                method_names = [
                    'extract_all_features', 'extract_features', 'extract',
                    'compute_features', 'process_image', 'get_features'
                ]

                for method_name in method_names:
                    if hasattr(ensemble, method_name):
                        try:
                            method = getattr(ensemble, method_name)
                            features = method(patch_uint8)
                            if features is not None:
                                print(f"   âœ… {patch_labels[i]} íŒ¨ì¹˜: {method_name}() ì„±ê³µ")
                                break
                        except Exception as method_error:
                            print(f"   âš ï¸ {method_name}() ì‹œë„ ì‹¤íŒ¨: {str(method_error)[:100]}...")
                            continue

                if features is not None:
                    features_array = np.array(features)
                    if features_array.size > 0:
                        ensemble_features.append(features_array.flatten())
                        print(f"      íŠ¹ì§• í¬ê¸°: {features_array.shape}")
                    else:
                        print(f"   âŒ {patch_labels[i]} íŒ¨ì¹˜: ë¹ˆ íŠ¹ì§• ë²¡í„°")
                else:
                    print(f"   âŒ {patch_labels[i]} íŒ¨ì¹˜: ì•™ìƒë¸” íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨")

            except Exception as e:
                print(f"   âŒ {patch_labels[i]} íŒ¨ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

        # ì•™ìƒë¸” ê²°ê³¼ ë¶„ì„
        if ensemble_features:
            try:
                ensemble_array = np.array(ensemble_features)
                print(f"   ğŸ“Š ì•™ìƒë¸” íŠ¹ì§• í¬ê¸°: {ensemble_array.shape}")
                print(f"   ğŸ“Š ì•™ìƒë¸” íŠ¹ì§• í†µê³„: mean={np.mean(ensemble_array):.3f}, std={np.std(ensemble_array):.3f}")

                return {
                    'success': True,
                    'ensemble_shape': ensemble_array.shape,
                    'ensemble_stats': {
                        'mean': np.mean(ensemble_array),
                        'std': np.std(ensemble_array),
                        'min': np.min(ensemble_array),
                        'max': np.max(ensemble_array)
                    },
                    'samples_processed': len(ensemble_features)
                }
            except Exception as array_error:
                print(f"   âŒ ì•™ìƒë¸” ë°°ì—´ ìƒì„± ì‹¤íŒ¨: {array_error}")
                return {'success': False, 'error': f'ë°°ì—´ ìƒì„± ì‹¤íŒ¨: {array_error}'}
        else:
            return {'success': False, 'error': 'ì•™ìƒë¸” íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨'}

    except Exception as e:
        print(f"   âŒ Feature Ensemble í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return {'success': False, 'error': str(e)}

def simulate_feature_extraction_pipeline():
    """íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜"""

    print("\nğŸ”§ íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜:")

    try:
        # ê°„ë‹¨í•œ íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜ë“¤ ì •ì˜ (ëŒ€ì²´ìš©)
        def extract_basic_stats(image):
            """ê¸°ë³¸ í†µê³„ íŠ¹ì§•"""
            return [
                np.mean(image), np.std(image), np.min(image), np.max(image),
                np.median(image), np.percentile(image, 25), np.percentile(image, 75)
            ]

        def extract_texture_features(image):
            """í…ìŠ¤ì²˜ íŠ¹ì§• (ê°„ë‹¨í•œ ë²„ì „)"""
            # ê·¸ë¼ë””ì–¸íŠ¸ ê¸°ë°˜ íŠ¹ì§•
            grad_x = np.abs(np.diff(image, axis=1)).mean()
            grad_y = np.abs(np.diff(image, axis=0)).mean()

            # ì—”íŠ¸ë¡œí”¼ ì¶”ì •
            hist, _ = np.histogram(image.flatten(), bins=32, density=True)
            hist = hist[hist > 0]
            entropy = -np.sum(hist * np.log2(hist))

            return [grad_x, grad_y, entropy]

        def extract_spatial_features(image):
            """ê³µê°„ íŠ¹ì§•"""
            center_y, center_x = np.array(image.shape) // 2
            y_coords, x_coords = np.mgrid[:image.shape[0], :image.shape[1]]

            # ë¬´ê²Œì¤‘ì‹¬
            total_intensity = np.sum(image)
            if total_intensity > 0:
                centroid_y = np.sum(y_coords * image) / total_intensity
                centroid_x = np.sum(x_coords * image) / total_intensity
            else:
                centroid_y, centroid_x = center_y, center_x

            # ë¶„ì‚°
            var_y = np.sum(((y_coords - centroid_y) ** 2) * image) / total_intensity if total_intensity > 0 else 0
            var_x = np.sum(((x_coords - centroid_x) ** 2) * image) / total_intensity if total_intensity > 0 else 0

            return [centroid_y, centroid_x, var_y, var_x]

        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        test_patches, patch_labels = create_test_sonar_patches()

        # ê° íŒ¨ì¹˜ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
        feature_results = {}
        for i, patch in enumerate(test_patches):
            patch_features = {
                'basic_stats': extract_basic_stats(patch),
                'texture': extract_texture_features(patch),
                'spatial': extract_spatial_features(patch)
            }

            # ëª¨ë“  íŠ¹ì§•ì„ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ê²°í•©
            combined_features = np.concatenate([
                patch_features['basic_stats'],
                patch_features['texture'],
                patch_features['spatial']
            ])

            feature_results[patch_labels[i]] = {
                'features': combined_features,
                'individual': patch_features
            }

            print(f"   âœ… {patch_labels[i]} íŒ¨ì¹˜: íŠ¹ì§• í¬ê¸° {len(combined_features)}")

        # ì „ì²´ íŠ¹ì§• ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        all_features = np.array([result['features'] for result in feature_results.values()])
        print(f"   ğŸ“Š ì „ì²´ íŠ¹ì§• ë§¤íŠ¸ë¦­ìŠ¤: {all_features.shape}")
        print(f"   ğŸ“Š íŠ¹ì§• í†µê³„: mean={np.mean(all_features):.3f}, std={np.std(all_features):.3f}")

        return {
            'success': True,
            'feature_matrix_shape': all_features.shape,
            'feature_stats': {
                'mean': np.mean(all_features),
                'std': np.std(all_features),
                'min': np.min(all_features),
                'max': np.max(all_features)
            },
            'feature_types': ['basic_stats', 'texture', 'spatial'],
            'samples_processed': len(test_patches)
        }

    except Exception as e:
        print(f"   âŒ íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        return {'success': False, 'error': str(e)}

def run_comprehensive_feature_tests_corrected():
    """í¬ê´„ì  íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ - ìˆ˜ì •ëœ ë²„ì „"""

    print("=" * 70)
    print("4ë‹¨ê³„: íŠ¹ì§• ì¶”ì¶œ ëª¨ë“ˆë“¤ í¬ê´„ì  í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ ë²„ì „)")
    print("=" * 70)

    # 1. ëª¨ë“ˆ import (ìˆ˜ì •ëœ í´ë˜ìŠ¤ëª…)
    extractors, import_results = test_feature_extractors_import_corrected()

    # 2. ê°œë³„ ì¶”ì¶œê¸° í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ ë©”ì„œë“œëª…)
    extraction_results = test_individual_extractors_corrected(extractors, import_results)

    # 3. ì•™ìƒë¸” í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ ë²„ì „)
    ensemble_results = test_feature_ensemble_corrected(extractors, import_results)

    # 4. íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜ (ëŒ€ì²´ ë°©ë²•)
    pipeline_results = simulate_feature_extraction_pipeline()

    return {
        'import_results': import_results,
        'extraction_results': extraction_results,
        'ensemble_results': ensemble_results,
        'pipeline_simulation': pipeline_results
    }

def generate_feature_extraction_summary_corrected(results):
    """íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ - ìˆ˜ì •ëœ ë²„ì „"""

    print(f"\n{'='*70}")
    print("ğŸ“Š 4ë‹¨ê³„ íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ (ìˆ˜ì •ëœ ë²„ì „)")
    print(f"{'='*70}")

    if not results:
        print("âŒ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì—†ìŒ")
        return False

    # Import ê²°ê³¼
    import_results = results.get('import_results', {})
    import_success = sum(import_results.values())
    import_total = len(import_results)
    print(f"ğŸ“¦ ëª¨ë“ˆ Import: {import_success}/{import_total} ì„±ê³µ")

    for module, success in import_results.items():
        status = "âœ…" if success else "âŒ"
        print(f"   {status} {module}")

    # íŠ¹ì§• ì¶”ì¶œ ê²°ê³¼
    extraction_results = results.get('extraction_results', {})
    extraction_success = sum(1 for r in extraction_results.values() if r.get('success', False))
    extraction_total = len(extraction_results) if extraction_results else 0
    print(f"\nğŸ”¬ íŠ¹ì§• ì¶”ì¶œ: {extraction_success}/{extraction_total} ì„±ê³µ")

    if extraction_results:
        for extractor, result in extraction_results.items():
            if result.get('success'):
                shape = result['feature_shape']
                stats = result['feature_stats']
                samples = result.get('samples_processed', 0)
                print(f"   âœ… {extractor}: íŠ¹ì§• í¬ê¸° {shape}, ìƒ˜í”Œ {samples}ê°œ, í‰ê·  {stats['mean']:.3f}")
            else:
                error = result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                print(f"   âŒ {extractor}: {error[:50]}...")

    # ì•™ìƒë¸” ê²°ê³¼
    ensemble_results = results.get('ensemble_results', {})
    ensemble_status = "âœ…" if ensemble_results.get('success') else "âŒ"
    print(f"\nğŸ§© íŠ¹ì§• ì•™ìƒë¸”: {ensemble_status}")

    if ensemble_results.get('success'):
        shape = ensemble_results['ensemble_shape']
        stats = ensemble_results['ensemble_stats']
        samples = ensemble_results.get('samples_processed', 0)
        print(f"   ğŸ“Š ì•™ìƒë¸” íŠ¹ì§• í¬ê¸°: {shape}")
        print(f"   ğŸ“Š ì²˜ë¦¬ ìƒ˜í”Œ: {samples}ê°œ")
        print(f"   ğŸ“Š ì•™ìƒë¸” í†µê³„: í‰ê·  {stats['mean']:.3f}, í‘œì¤€í¸ì°¨ {stats['std']:.3f}")
    else:
        error = ensemble_results.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
        print(f"   âŒ ì•™ìƒë¸” ì‹¤íŒ¨: {error[:50]}...")

    # íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
    pipeline_results = results.get('pipeline_simulation', {})
    pipeline_status = "âœ…" if pipeline_results.get('success') else "âŒ"
    print(f"\nğŸ”§ íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜: {pipeline_status}")

    if pipeline_results.get('success'):
        shape = pipeline_results['feature_matrix_shape']
        stats = pipeline_results['feature_stats']
        types = pipeline_results.get('feature_types', [])
        samples = pipeline_results.get('samples_processed', 0)
        print(f"   ğŸ“Š íŠ¹ì§• ë§¤íŠ¸ë¦­ìŠ¤: {shape}")
        print(f"   ğŸ“Š íŠ¹ì§• ìœ í˜•: {', '.join(types)}")
        print(f"   ğŸ“Š ì²˜ë¦¬ ìƒ˜í”Œ: {samples}ê°œ")
        print(f"   ğŸ“Š í†µê³„: í‰ê·  {stats['mean']:.3f}, í‘œì¤€í¸ì°¨ {stats['std']:.3f}")

    # ì „ì²´ ì„±ê³µë¥  ê³„ì‚°
    success_components = [
        import_success >= import_total * 0.6,  # 60% ì´ìƒ import ì„±ê³µ
        extraction_success > 0 or pipeline_results.get('success', False),  # í•˜ë‚˜ë¼ë„ íŠ¹ì§• ì¶”ì¶œ ì„±ê³µ
        ensemble_results.get('success', False) or pipeline_results.get('success', False),  # ì•™ìƒë¸” ë˜ëŠ” íŒŒì´í”„ë¼ì¸ ì„±ê³µ
        pipeline_results.get('success', False)  # ëŒ€ì²´ íŒŒì´í”„ë¼ì¸ ì„±ê³µ
    ]

    success_count = sum(success_components)
    success_rate = (success_count / 4) * 100

    print(f"\nğŸ“‹ ì „ì²´ ì„±ê³µë¥ : {success_count}/4 ({success_rate:.1f}%)")

    # íŠ¹ì§• ì¶”ì¶œ ê¸°ëŠ¥ í‰ê°€
    if success_rate >= 75:
        print("\nğŸ¯ íŠ¹ì§• ì¶”ì¶œ ê¸°ëŠ¥ í‰ê°€: ìš°ìˆ˜")
        print("   - ê¸°ë³¸ì ì¸ íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ê°€ëŠ¥")
        print("   - ë‹¤ì–‘í•œ íŠ¹ì§• ìœ í˜• (í†µê³„, í…ìŠ¤ì²˜, ê³µê°„) ì¶”ì¶œ í™•ì¸")
    elif success_rate >= 50:
        print("\nğŸ¯ íŠ¹ì§• ì¶”ì¶œ ê¸°ëŠ¥ í‰ê°€: ì–‘í˜¸")
        print("   - ì¼ë¶€ íŠ¹ì§• ì¶”ì¶œ ê¸°ëŠ¥ ì‘ë™")
        print("   - ì¶”ê°€ ëª¨ë“ˆ êµ¬í˜„ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥")
    else:
        print("\nğŸ¯ íŠ¹ì§• ì¶”ì¶œ ê¸°ëŠ¥ í‰ê°€: ê°œì„  í•„ìš”")
        print("   - ëŒ€ë¶€ë¶„ì˜ íŠ¹ì§• ì¶”ì¶œ ëª¨ë“ˆ ìˆ˜ì • í•„ìš”")

    return success_rate >= 50  # 50% ì´ìƒì´ë©´ ê¸°ë³¸ì ì¸ ê¸°ëŠ¥ì€ ì‘ë™

def save_feature_test_results_corrected(results):
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ - ìˆ˜ì •ëœ ë²„ì „"""

    output_file = f"analysis_results/data_validation/feature_extraction_step4_corrected_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

    # numpy ê°’ë“¤ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡ ë³€í™˜
    def convert_for_json(obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, (np.integer, np.floating)):
            return float(obj)
        elif isinstance(obj, tuple):
            return list(obj)
        return obj

    # ê²°ê³¼ ì •ë¦¬
    clean_results = {}
    for key, value in results.items():
        if isinstance(value, dict):
            clean_results[key] = {}
            for sub_key, sub_value in value.items():
                if isinstance(sub_value, dict):
                    clean_results[key][sub_key] = {k: convert_for_json(v) for k, v in sub_value.items()}
                else:
                    clean_results[key][sub_key] = convert_for_json(sub_value)
        else:
            clean_results[key] = convert_for_json(value)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            "test_timestamp": datetime.now().isoformat(),
            "test_description": "4ë‹¨ê³„ íŠ¹ì§• ì¶”ì¶œ ëª¨ë“ˆë“¤ í¬ê´„ì  í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ ë²„ì „)",
            "results": clean_results
        }, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {output_file}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print("ğŸ”§ 4ë‹¨ê³„: íŠ¹ì§• ì¶”ì¶œ ëª¨ë“ˆë“¤ í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì‹œì‘ (ìˆ˜ì •ëœ ë²„ì „)")

    # í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = run_comprehensive_feature_tests_corrected()

    if not results:
        print("\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨")
        return False

    # ê²°ê³¼ ìš”ì•½
    success = generate_feature_extraction_summary_corrected(results)

    # ê²°ê³¼ ì €ì¥
    save_feature_test_results_corrected(results)

    print(f"\n{'='*70}")
    if success:
        print("âœ… 4ë‹¨ê³„ íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ì„±ê³µ")
        print("ğŸ¯ ê¸°ë³¸ì ì¸ íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ì‘ë™ í™•ì¸")
        print("ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: 5ë‹¨ê³„ ê¸°ë¢° ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ ì§„í–‰ ê°€ëŠ¥")
    else:
        print("âš ï¸ 4ë‹¨ê³„ íŠ¹ì§• ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ê°œì„  í•„ìš”")
        print("ğŸ”§ ì¼ë¶€ íŠ¹ì§• ì¶”ì¶œ ëª¨ë“ˆì€ ì¶”ê°€ êµ¬í˜„ì´ í•„ìš”í•©ë‹ˆë‹¤")
        print("ğŸ¯ ê¸°ë³¸ íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ 5ë‹¨ê³„ ì§„í–‰ ê°€ëŠ¥")
    print(f"{'='*70}")

    return success

if __name__ == "__main__":
    main()