#!/usr/bin/env python3
"""
XTF ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

ëª©ì : 121â†’12 ê°™ì€ ì¢Œí‘œ ì¶”ì¶œ ì˜¤ë¥˜ê°€ ìˆì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ 
      ì‹¤ì œ ì¢Œí‘œì™€ ì´ì „ ë¶„ì„ ê²°ê³¼ ë¹„êµ
"""

import os
import sys
import numpy as np
import pandas as pd
from datetime import datetime
import logging
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import json
import pyxtf

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.data_processing.xtf_reader import XTFReader

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def verify_xtf_coordinate_extraction():
    """XTF ì¢Œí‘œ ì¶”ì¶œ ê²€ì¦ ë° ì˜¤ë¥˜ íƒì§€"""

    logger.info("XTF ì¢Œí‘œ ì¶”ì¶œ ê²€ì¦ ì‹œì‘")
    print("="*70)
    print("XTF ë©”íƒ€ë°ì´í„° ì¢Œí‘œ ì¶”ì¶œ ê²€ì¦")
    print("="*70)

    # XTF íŒŒì¼ ê²½ë¡œ
    xtf_files = [
        "datasets/Pohang_Eardo_1_Edgetech4205_800_050_20241012110900_001_04/original/Pohang_Eardo_1_Edgetech4205_800_050_20241012110900_001_04.xtf",
        "datasets/Pohang_Eardo_1_Klein3900_900_050_20241011171100_001_04/original/Pohang_Eardo_1_Klein3900_900_050_20241011171100_001_04.xtf",
        "datasets/Pohang_Eardo_1_Edgetech4205_800_050_20241012181900_001_04/original/Pohang_Eardo_1_Edgetech4205_800_050_20241012181900_001_04.xtf"
    ]

    verification_results = []

    for xtf_path in xtf_files:
        if not os.path.exists(xtf_path):
            logger.warning(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {xtf_path}")
            continue

        logger.info(f"ê²€ì¦ ì¤‘: {xtf_path}")
        result = verify_single_xtf(xtf_path)
        if result:
            verification_results.append(result)

    # ì¢…í•© ë¶„ì„
    comprehensive_analysis = analyze_coordinate_discrepancies(verification_results)

    # ê²°ê³¼ ì €ì¥
    save_verification_results(verification_results, comprehensive_analysis)

    return verification_results, comprehensive_analysis

def verify_single_xtf(xtf_path: str) -> Dict:
    """ë‹¨ì¼ XTF íŒŒì¼ì˜ ì¢Œí‘œ ì¶”ì¶œ ê²€ì¦"""

    filename = os.path.basename(xtf_path)
    print(f"\n{'='*50}")
    print(f"íŒŒì¼: {filename}")
    print(f"{'='*50}")

    try:
        # 1. pyxtf ì§ì ‘ ì‚¬ìš©ìœ¼ë¡œ ì›ì‹œ ì¢Œí‘œ í™•ì¸
        raw_coordinates = extract_raw_coordinates_pyxtf(xtf_path)

        # 2. XTF Reader ì‚¬ìš©ìœ¼ë¡œ ì²˜ë¦¬ëœ ì¢Œí‘œ í™•ì¸
        reader_coordinates = extract_coordinates_xtf_reader(xtf_path)

        # 3. ì¢Œí‘œ ë¹„êµ ë° ì˜¤ë¥˜ íƒì§€
        comparison_result = compare_coordinate_extractions(raw_coordinates, reader_coordinates)

        result = {
            'file_path': xtf_path,
            'filename': filename,
            'raw_coordinates': raw_coordinates,
            'reader_coordinates': reader_coordinates,
            'comparison': comparison_result,
            'verification_timestamp': datetime.now().isoformat()
        }

        # ê²°ê³¼ ì¶œë ¥
        print_verification_results(result)

        return result

    except Exception as e:
        logger.error(f"íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨ {xtf_path}: {e}")
        return None

def extract_raw_coordinates_pyxtf(xtf_path: str) -> Dict:
    """pyxtfë¡œ ì§ì ‘ ì›ì‹œ ì¢Œí‘œ ì¶”ì¶œ"""

    logger.info("pyxtfë¡œ ì›ì‹œ ì¢Œí‘œ ì¶”ì¶œ ì¤‘...")

    try:
        coordinates = []
        coordinate_fields = []
        packet_count = 0

        for packet in pyxtf.xtf_read_gen(xtf_path):
            packet_count += 1

            # ì†Œë‚˜ íŒ¨í‚·ë§Œ ì²˜ë¦¬
            if hasattr(packet, 'data') and packet.data is not None:
                coord_info = {}

                # ëª¨ë“  ì¢Œí‘œ ê´€ë ¨ ì†ì„± ìˆ˜ì§‘
                coord_attrs = [
                    'SensorXcoordinate', 'SensorYcoordinate',
                    'SensorX', 'SensorY',
                    'ShipXcoordinate', 'ShipYcoordinate',
                    'ShipX', 'ShipY'
                ]

                for attr in coord_attrs:
                    if hasattr(packet, attr):
                        value = getattr(packet, attr)
                        coord_info[attr] = value
                        if attr not in coordinate_fields:
                            coordinate_fields.append(attr)

                if coord_info:
                    coordinates.append(coord_info)

            # ì²˜ìŒ 1000ê°œ íŒ¨í‚·ë§Œ ì²˜ë¦¬ (ëŒ€í‘œì„±ì„ ìœ„í•´)
            if packet_count >= 1000:
                break

        # í†µê³„ ê³„ì‚°
        if coordinates:
            result = {
                'total_packets': packet_count,
                'coordinate_packets': len(coordinates),
                'available_fields': coordinate_fields,
                'coordinate_samples': coordinates[:5],  # ì²˜ìŒ 5ê°œ ìƒ˜í”Œ
                'coordinate_statistics': calculate_coordinate_statistics(coordinates, coordinate_fields)
            }
        else:
            result = {
                'total_packets': packet_count,
                'coordinate_packets': 0,
                'available_fields': [],
                'coordinate_samples': [],
                'coordinate_statistics': {}
            }

        logger.info(f"pyxtf ì¶”ì¶œ ì™„ë£Œ: {len(coordinates)}ê°œ ì¢Œí‘œ")
        return result

    except Exception as e:
        logger.error(f"pyxtf ì›ì‹œ ì¢Œí‘œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return {'error': str(e)}

def extract_coordinates_xtf_reader(xtf_path: str) -> Dict:
    """XTF Readerë¡œ ì²˜ë¦¬ëœ ì¢Œí‘œ ì¶”ì¶œ"""

    logger.info("XTF Readerë¡œ ì¢Œí‘œ ì¶”ì¶œ ì¤‘...")

    try:
        # XTF Reader ì‚¬ìš©
        reader = XTFReader(xtf_path, max_pings=1000)
        reader.load_file()
        ping_data = reader.parse_pings()

        if not ping_data:
            return {'error': 'No ping data extracted'}

        # ì¢Œí‘œ ë°ì´í„° ìˆ˜ì§‘
        coordinates = []
        for ping in ping_data:
            coord_info = {
                'latitude': ping.latitude,
                'longitude': ping.longitude,
                'ship_x': ping.ship_x,
                'ship_y': ping.ship_y,
                'ping_number': ping.ping_number
            }
            coordinates.append(coord_info)

        # í†µê³„ ê³„ì‚°
        latitudes = [ping.latitude for ping in ping_data]
        longitudes = [ping.longitude for ping in ping_data]

        result = {
            'extracted_pings': len(ping_data),
            'coordinate_samples': coordinates[:5],  # ì²˜ìŒ 5ê°œ ìƒ˜í”Œ
            'latitude_stats': {
                'min': float(np.min(latitudes)),
                'max': float(np.max(latitudes)),
                'mean': float(np.mean(latitudes)),
                'std': float(np.std(latitudes))
            },
            'longitude_stats': {
                'min': float(np.min(longitudes)),
                'max': float(np.max(longitudes)),
                'mean': float(np.mean(longitudes)),
                'std': float(np.std(longitudes))
            }
        }

        logger.info(f"XTF Reader ì¶”ì¶œ ì™„ë£Œ: {len(ping_data)}ê°œ ping")
        return result

    except Exception as e:
        logger.error(f"XTF Reader ì¢Œí‘œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return {'error': str(e)}

def calculate_coordinate_statistics(coordinates: List[Dict], fields: List[str]) -> Dict:
    """ì¢Œí‘œ í†µê³„ ê³„ì‚°"""

    stats = {}

    for field in fields:
        values = []
        for coord in coordinates:
            if field in coord and coord[field] is not None:
                try:
                    values.append(float(coord[field]))
                except (ValueError, TypeError):
                    continue

        if values:
            stats[field] = {
                'count': len(values),
                'min': float(np.min(values)),
                'max': float(np.max(values)),
                'mean': float(np.mean(values)),
                'std': float(np.std(values))
            }

    return stats

def compare_coordinate_extractions(raw_coords: Dict, reader_coords: Dict) -> Dict:
    """ë‘ ì¶”ì¶œ ë°©ë²• ê°„ ì¢Œí‘œ ë¹„êµ"""

    comparison = {
        'coordinate_consistency': {},
        'potential_errors': [],
        'coordinate_ranges': {},
        'extraction_method_comparison': {}
    }

    # ì˜¤ë¥˜ í™•ì¸ì´ ì—†ëŠ” ê²½ìš°
    if 'error' in raw_coords or 'error' in reader_coords:
        comparison['extraction_method_comparison'] = {
            'raw_extraction_status': 'error' if 'error' in raw_coords else 'success',
            'reader_extraction_status': 'error' if 'error' in reader_coords else 'success'
        }
        return comparison

    # ì¢Œí‘œ ë²”ìœ„ ë¹„êµ
    try:
        # Raw coordinatesì—ì„œ sensor ì¢Œí‘œ ì°¾ê¸°
        raw_stats = raw_coords.get('coordinate_statistics', {})
        sensor_x_stats = raw_stats.get('SensorXcoordinate') or raw_stats.get('SensorX')
        sensor_y_stats = raw_stats.get('SensorYcoordinate') or raw_stats.get('SensorY')

        # Reader coordinates í†µê³„
        reader_lat_stats = reader_coords.get('latitude_stats', {})
        reader_lon_stats = reader_coords.get('longitude_stats', {})

        if sensor_x_stats and sensor_y_stats and reader_lat_stats and reader_lon_stats:
            # ì¢Œí‘œ ë²”ìœ„ ë¹„êµ
            comparison['coordinate_ranges'] = {
                'raw_longitude_range': (sensor_x_stats['min'], sensor_x_stats['max']),
                'raw_latitude_range': (sensor_y_stats['min'], sensor_y_stats['max']),
                'reader_longitude_range': (reader_lon_stats['min'], reader_lon_stats['max']),
                'reader_latitude_range': (reader_lat_stats['min'], reader_lat_stats['max'])
            }

            # ì˜¤ì°¨ ê²€ì¶œ
            lon_diff = abs(sensor_x_stats['mean'] - reader_lon_stats['mean'])
            lat_diff = abs(sensor_y_stats['mean'] - reader_lat_stats['mean'])

            comparison['coordinate_consistency'] = {
                'longitude_difference': lon_diff,
                'latitude_difference': lat_diff,
                'significant_longitude_difference': lon_diff > 0.1,  # 0.1ë„ ì´ìƒ ì°¨ì´
                'significant_latitude_difference': lat_diff > 0.1
            }

            # ì ì¬ì  ì˜¤ë¥˜ íƒì§€
            if lon_diff > 0.1:
                comparison['potential_errors'].append(f"ê²½ë„ ì°¨ì´ {lon_diff:.6f}ë„ - ì¶”ì¶œ ë°©ë²• ê°„ ë¶ˆì¼ì¹˜")

            if lat_diff > 0.1:
                comparison['potential_errors'].append(f"ìœ„ë„ ì°¨ì´ {lat_diff:.6f}ë„ - ì¶”ì¶œ ë°©ë²• ê°„ ë¶ˆì¼ì¹˜")

            # 121 â†’ 12 ê°™ì€ ìë¦¿ìˆ˜ ì˜¤ë¥˜ íƒì§€
            if sensor_x_stats['mean'] > 100 and reader_lon_stats['mean'] < 100:
                comparison['potential_errors'].append("ê²½ë„ ìë¦¿ìˆ˜ ì˜¤ë¥˜ ì˜ì‹¬: ì›ì‹œê°’ì€ 3ìë¦¬, ì¶”ì¶œê°’ì€ 2ìë¦¬")

            if sensor_y_stats['mean'] > 100 and reader_lat_stats['mean'] < 100:
                comparison['potential_errors'].append("ìœ„ë„ ìë¦¿ìˆ˜ ì˜¤ë¥˜ ì˜ì‹¬: ì›ì‹œê°’ì€ 3ìë¦¬, ì¶”ì¶œê°’ì€ 2ìë¦¬")

    except Exception as e:
        comparison['potential_errors'].append(f"ì¢Œí‘œ ë¹„êµ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    return comparison

def print_verification_results(result: Dict):
    """ê²€ì¦ ê²°ê³¼ ì¶œë ¥"""

    filename = result['filename']
    raw_coords = result['raw_coordinates']
    reader_coords = result['reader_coordinates']
    comparison = result['comparison']

    print(f"\nğŸ“Š {filename} ê²€ì¦ ê²°ê³¼:")

    # Raw coordinates ê²°ê³¼
    if 'error' not in raw_coords:
        print(f"   ğŸ” ì›ì‹œ ì¢Œí‘œ ì¶”ì¶œ:")
        print(f"      íŒ¨í‚· ìˆ˜: {raw_coords['total_packets']}")
        print(f"      ì¢Œí‘œ íŒ¨í‚·: {raw_coords['coordinate_packets']}")
        print(f"      ì¢Œí‘œ í•„ë“œ: {raw_coords['available_fields']}")

        # ì¢Œí‘œ ë²”ìœ„ ì¶œë ¥
        stats = raw_coords.get('coordinate_statistics', {})
        for field, stat in stats.items():
            if 'coordinate' in field.lower() or field in ['SensorX', 'SensorY']:
                print(f"      {field}: {stat['min']:.6f} ~ {stat['max']:.6f} (í‰ê· : {stat['mean']:.6f})")

    # Reader coordinates ê²°ê³¼
    if 'error' not in reader_coords:
        print(f"   ğŸ“– XTF Reader ì¶”ì¶œ:")
        print(f"      ì¶”ì¶œ ping: {reader_coords['extracted_pings']}")
        lat_stats = reader_coords['latitude_stats']
        lon_stats = reader_coords['longitude_stats']
        print(f"      ìœ„ë„: {lat_stats['min']:.6f} ~ {lat_stats['max']:.6f} (í‰ê· : {lat_stats['mean']:.6f})")
        print(f"      ê²½ë„: {lon_stats['min']:.6f} ~ {lon_stats['max']:.6f} (í‰ê· : {lon_stats['mean']:.6f})")

    # ë¹„êµ ê²°ê³¼
    print(f"   âš–ï¸ ë¹„êµ ë¶„ì„:")
    if comparison['potential_errors']:
        print(f"      âš ï¸ ì ì¬ì  ì˜¤ë¥˜:")
        for error in comparison['potential_errors']:
            print(f"         - {error}")
    else:
        print(f"      âœ… ì¢Œí‘œ ì¶”ì¶œ ì¼ê´€ì„± í™•ì¸")

    # ì¢Œí‘œ ì¼ê´€ì„±
    consistency = comparison.get('coordinate_consistency', {})
    if consistency:
        lon_diff = consistency.get('longitude_difference', 0)
        lat_diff = consistency.get('latitude_difference', 0)
        print(f"      ì°¨ì´: ê²½ë„ {lon_diff:.6f}ë„, ìœ„ë„ {lat_diff:.6f}ë„")

def analyze_coordinate_discrepancies(results: List[Dict]) -> Dict:
    """ì¢Œí‘œ ë¶ˆì¼ì¹˜ ì¢…í•© ë¶„ì„"""

    logger.info("ì¢Œí‘œ ë¶ˆì¼ì¹˜ ì¢…í•© ë¶„ì„ ìˆ˜í–‰ ì¤‘...")

    analysis = {
        'total_files_analyzed': len(results),
        'files_with_errors': 0,
        'files_with_coordinate_discrepancies': 0,
        'common_error_patterns': [],
        'coordinate_range_summary': {},
        'impact_on_location_analysis': {}
    }

    all_errors = []
    coordinate_ranges = []

    for result in results:
        comparison = result.get('comparison', {})
        potential_errors = comparison.get('potential_errors', [])

        if potential_errors:
            analysis['files_with_errors'] += 1
            all_errors.extend(potential_errors)

        # ì¢Œí‘œ ë¶ˆì¼ì¹˜ í™•ì¸
        consistency = comparison.get('coordinate_consistency', {})
        if consistency.get('significant_longitude_difference') or consistency.get('significant_latitude_difference'):
            analysis['files_with_coordinate_discrepancies'] += 1

        # ì¢Œí‘œ ë²”ìœ„ ìˆ˜ì§‘
        coord_ranges = comparison.get('coordinate_ranges', {})
        if coord_ranges:
            coordinate_ranges.append({
                'filename': result['filename'],
                'ranges': coord_ranges
            })

    # ê³µí†µ ì˜¤ë¥˜ íŒ¨í„´ ë¶„ì„
    error_patterns = {}
    for error in all_errors:
        if 'ìë¦¿ìˆ˜ ì˜¤ë¥˜' in error:
            error_patterns['digit_truncation'] = error_patterns.get('digit_truncation', 0) + 1
        elif 'ì°¨ì´' in error and 'ë„' in error:
            error_patterns['coordinate_difference'] = error_patterns.get('coordinate_difference', 0) + 1

    analysis['common_error_patterns'] = error_patterns
    analysis['coordinate_range_summary'] = coordinate_ranges

    # Location_MDGPS ë¶„ì„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ í‰ê°€
    if analysis['files_with_coordinate_discrepancies'] > 0:
        analysis['impact_on_location_analysis'] = {
            'affected_files': analysis['files_with_coordinate_discrepancies'],
            'potential_location_shift': True,
            'requires_reanalysis': True,
            'estimated_error_magnitude': 'Unknown - requires detailed investigation'
        }
    else:
        analysis['impact_on_location_analysis'] = {
            'affected_files': 0,
            'potential_location_shift': False,
            'requires_reanalysis': False,
            'estimated_error_magnitude': 'No significant errors detected'
        }

    return analysis

def save_verification_results(results: List[Dict], analysis: Dict):
    """ê²€ì¦ ê²°ê³¼ ì €ì¥"""

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path("analysis_results/xtf_metadata_verification")
    output_dir.mkdir(parents=True, exist_ok=True)

    # ìƒì„¸ ê²°ê³¼ ì €ì¥ (coordinate_samples ì œì™¸í•˜ì—¬ í¬ê¸° ì¶•ì†Œ)
    simplified_results = []
    for result in results:
        simplified_result = result.copy()
        if 'raw_coordinates' in simplified_result:
            raw_coords = simplified_result['raw_coordinates'].copy()
            if 'coordinate_samples' in raw_coords:
                raw_coords['coordinate_samples'] = raw_coords['coordinate_samples'][:2]  # ì²˜ìŒ 2ê°œë§Œ
            simplified_result['raw_coordinates'] = raw_coords

        if 'reader_coordinates' in simplified_result:
            reader_coords = simplified_result['reader_coordinates'].copy()
            if 'coordinate_samples' in reader_coords:
                reader_coords['coordinate_samples'] = reader_coords['coordinate_samples'][:2]  # ì²˜ìŒ 2ê°œë§Œ
            simplified_result['reader_coordinates'] = reader_coords

        simplified_results.append(simplified_result)

    detail_file = output_dir / "xtf_metadata_verification_detail.json"
    with open(detail_file, 'w', encoding='utf-8') as f:
        json.dump({
            'verification_results': simplified_results,
            'comprehensive_analysis': analysis,
            'verification_timestamp': datetime.now().isoformat()
        }, f, indent=2, ensure_ascii=False)

    # ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
    report_file = output_dir / "XTF_METADATA_VERIFICATION_REPORT.md"
    generate_verification_report(results, analysis, report_file)

    logger.info(f"ê²€ì¦ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_dir}")
    print(f"\nğŸ“ ê²€ì¦ ê²°ê³¼ ì €ì¥: {output_dir}/")

def generate_verification_report(results: List[Dict], analysis: Dict, output_file: Path):
    """ê²€ì¦ ë³´ê³ ì„œ ìƒì„±"""

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(f"""# XTF ë©”íƒ€ë°ì´í„° ì¢Œí‘œ ì¶”ì¶œ ê²€ì¦ ë³´ê³ ì„œ
**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ë¶„ì„ì**: YMARX

## ğŸ¯ **ê²€ì¦ ëª©ì **
XTF íŒŒì¼ì—ì„œ ì¢Œí‘œ ì¶”ì¶œ ê³¼ì •ì—ì„œ "121â†’12" ê°™ì€ ìë¦¿ìˆ˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸í•˜ê³ ,
ì´ê²ƒì´ Original XTFì™€ Location_MDGPS ê°„ ìœ„ì¹˜ ì°¨ì´ ë¶„ì„ì— ì˜í–¥ì„ ì£¼ì—ˆëŠ”ì§€ ê²€ì¦

## ğŸ“Š **ê²€ì¦ ê°œìš”**
- **ë¶„ì„ íŒŒì¼ ìˆ˜**: {analysis['total_files_analyzed']}
- **ì˜¤ë¥˜ ë°œê²¬ íŒŒì¼**: {analysis['files_with_errors']}
- **ì¢Œí‘œ ë¶ˆì¼ì¹˜ íŒŒì¼**: {analysis['files_with_coordinate_discrepancies']}

## ğŸ” **ê°œë³„ íŒŒì¼ ê²€ì¦ ê²°ê³¼**

""")

        for result in results:
            filename = result['filename']
            comparison = result.get('comparison', {})
            potential_errors = comparison.get('potential_errors', [])

            f.write(f"""### {filename}
""")

            if potential_errors:
                f.write(f"âš ï¸ **ë°œê²¬ëœ ë¬¸ì œì **:\n")
                for error in potential_errors:
                    f.write(f"- {error}\n")
            else:
                f.write(f"âœ… **ë¬¸ì œ ì—†ìŒ**: ì¢Œí‘œ ì¶”ì¶œ ì¼ê´€ì„± í™•ì¸\n")

            # ì¢Œí‘œ ë²”ìœ„ ì •ë³´
            coord_ranges = comparison.get('coordinate_ranges', {})
            if coord_ranges:
                f.write(f"\n**ì¢Œí‘œ ë²”ìœ„**:\n")
                raw_lon = coord_ranges.get('raw_longitude_range', (0, 0))
                raw_lat = coord_ranges.get('raw_latitude_range', (0, 0))
                reader_lon = coord_ranges.get('reader_longitude_range', (0, 0))
                reader_lat = coord_ranges.get('reader_latitude_range', (0, 0))

                f.write(f"- ì›ì‹œ ê²½ë„: {raw_lon[0]:.6f} ~ {raw_lon[1]:.6f}\n")
                f.write(f"- ì¶”ì¶œ ê²½ë„: {reader_lon[0]:.6f} ~ {reader_lon[1]:.6f}\n")
                f.write(f"- ì›ì‹œ ìœ„ë„: {raw_lat[0]:.6f} ~ {raw_lat[1]:.6f}\n")
                f.write(f"- ì¶”ì¶œ ìœ„ë„: {reader_lat[0]:.6f} ~ {reader_lat[1]:.6f}\n")

            f.write(f"\n")

        # ì¢…í•© ë¶„ì„
        f.write(f"""## ğŸ“ˆ **ì¢…í•© ë¶„ì„ ê²°ê³¼**

### ì˜¤ë¥˜ íŒ¨í„´ ë¶„ì„
""")

        error_patterns = analysis.get('common_error_patterns', {})
        if error_patterns:
            for pattern, count in error_patterns.items():
                pattern_korean = {
                    'digit_truncation': 'ìë¦¿ìˆ˜ ì ˆë‹¨ ì˜¤ë¥˜',
                    'coordinate_difference': 'ì¢Œí‘œ ì°¨ì´'
                }.get(pattern, pattern)
                f.write(f"- **{pattern_korean}**: {count}ê±´\n")
        else:
            f.write(f"- ê³µí†µ ì˜¤ë¥˜ íŒ¨í„´ ë°œê²¬ë˜ì§€ ì•ŠìŒ\n")

        # ìœ„ì¹˜ ë¶„ì„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
        impact = analysis.get('impact_on_location_analysis', {})
        f.write(f"""
### Location_MDGPS ë¶„ì„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥

**ì˜í–¥ë°›ì€ íŒŒì¼**: {impact.get('affected_files', 0)}ê°œ
**ìœ„ì¹˜ ì´ë™ ê°€ëŠ¥ì„±**: {'ìˆìŒ' if impact.get('potential_location_shift') else 'ì—†ìŒ'}
**ì¬ë¶„ì„ í•„ìš”ì„±**: {'í•„ìš”' if impact.get('requires_reanalysis') else 'ë¶ˆí•„ìš”'}
**ì˜¤ì°¨ í¬ê¸° ì¶”ì •**: {impact.get('estimated_error_magnitude', 'Unknown')}

## ğŸ’¡ **ê²°ë¡ **

""")

        if analysis['files_with_coordinate_discrepancies'] > 0:
            f.write(f"""### âš ï¸ ì¢Œí‘œ ì¶”ì¶œ ì˜¤ë¥˜ ë°œê²¬
{analysis['files_with_coordinate_discrepancies']}ê°œ íŒŒì¼ì—ì„œ ì¢Œí‘œ ì¶”ì¶œ ë¶ˆì¼ì¹˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.

**ì ì¬ì  ì˜í–¥**:
- Original XTF ì¢Œí‘œ ì •í™•ì„±ì— ì˜ë¬¸
- Location_MDGPSì™€ì˜ ê±°ë¦¬ ê³„ì‚° ì˜¤ì°¨ ê°€ëŠ¥ì„±
- ì´ì „ ë¶„ì„ ê²°ê³¼ ì¬ê²€í†  í•„ìš”

**ê¶Œì¥ì‚¬í•­**:
1. ì˜¬ë°”ë¥¸ ì¢Œí‘œ ì¶”ì¶œ ë°©ë²•ìœ¼ë¡œ ì¬ë¶„ì„
2. pyxtf ì§ì ‘ ì‚¬ìš©ìœ¼ë¡œ ì •í™•í•œ ì¢Œí‘œ í™•ë³´
3. Location_MDGPSì™€ì˜ ê±°ë¦¬ ì¬ê³„ì‚°

""")
        else:
            f.write(f"""### âœ… ì¢Œí‘œ ì¶”ì¶œ ì •í™•ì„± í™•ì¸
ëª¨ë“  íŒŒì¼ì—ì„œ ì¢Œí‘œ ì¶”ì¶œì´ ì •í™•í•˜ê²Œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.

**ê²°ë¡ **:
- "121â†’12" ê°™ì€ ìë¦¿ìˆ˜ ì˜¤ë¥˜ëŠ” ë°œê²¬ë˜ì§€ ì•ŠìŒ
- Original XTFì™€ Location_MDGPS ê°„ 55km ê±°ë¦¬ ì°¨ì´ëŠ” ì‹¤ì œ ì§€ë¦¬ì  ë¶„ë¦¬
- ì´ì „ ë¶„ì„ ê²°ê³¼ê°€ ì •í™•í•¨

**í™•ì¸ì‚¬í•­**:
- XTF Readerì˜ ì¢Œí‘œ ì¶”ì¶œ ë°©ë²•ì´ ì˜¬ë°”ë¦„
- ì¢Œí‘œ ë³€í™˜ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ì—†ìŒ
- ê±°ë¦¬ ê³„ì‚° ê²°ê³¼ ì‹ ë¢°í•  ìˆ˜ ìˆìŒ

""")

        f.write(f"""## ğŸ”§ **ê²€ì¦ ë°©ë²•ë¡ **

### ê²€ì¦ ê³¼ì •
1. **ì›ì‹œ ì¢Œí‘œ ì¶”ì¶œ**: pyxtf.xtf_read_gen()ìœ¼ë¡œ ì§ì ‘ íŒ¨í‚·ì—ì„œ ì¢Œí‘œ ì¶”ì¶œ
2. **ì²˜ë¦¬ëœ ì¢Œí‘œ ì¶”ì¶œ**: XTF Reader í´ë˜ìŠ¤ë¥¼ í†µí•œ ì¢Œí‘œ ì¶”ì¶œ
3. **ë¹„êµ ë¶„ì„**: ë‘ ë°©ë²• ê°„ ì¢Œí‘œ ì¼ì¹˜ì„± ê²€ì¦
4. **ì˜¤ë¥˜ íƒì§€**: ìë¦¿ìˆ˜ ì ˆë‹¨, ë‹¨ìœ„ ë³€í™˜ ì˜¤ë¥˜ ë“± íƒì§€

### ê²€ì¦ ê¸°ì¤€
- ê²½ë„/ìœ„ë„ ì°¨ì´ 0.1ë„ ì´ìƒ ì‹œ ìœ ì˜í•œ ì°¨ì´ë¡œ íŒë‹¨
- 3ìë¦¬â†’2ìë¦¬ ë³€í™˜ ì‹œ ìë¦¿ìˆ˜ ì˜¤ë¥˜ë¡œ ì˜ì‹¬
- ì¢Œí‘œ ë²”ìœ„ì˜ ì¼ê´€ì„± ê²€ì¦

## ğŸ“‹ **í›„ì† ì¡°ì¹˜**

""")

        if analysis['files_with_coordinate_discrepancies'] > 0:
            f.write(f"""### ì˜¤ë¥˜ ë°œê²¬ ì‹œ ì¡°ì¹˜
1. **ì •í™•í•œ ì¢Œí‘œ ì¬ì¶”ì¶œ**: pyxtf ì§ì ‘ ì‚¬ìš©
2. **ê±°ë¦¬ ì¬ê³„ì‚°**: Location_MDGPSì™€ì˜ ì •í™•í•œ ê±°ë¦¬
3. **ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸**: ì´ì „ ë¶„ì„ ë³´ê³ ì„œ ìˆ˜ì •
4. **ì‹œìŠ¤í…œ ê°œì„ **: XTF Reader ì¢Œí‘œ ì¶”ì¶œ ë¡œì§ ìˆ˜ì •

""")
        else:
            f.write(f"""### ì •í™•ì„± í™•ì¸ ì‹œ ì¡°ì¹˜
1. **ë¶„ì„ ê²°ê³¼ í™•ì •**: í˜„ì¬ ë¶„ì„ ê²°ê³¼ê°€ ì •í™•í•¨
2. **ì‹ ë¢°ë„ í–¥ìƒ**: ê²€ì¦ ê³¼ì •ì„ í†µí•œ ì‹ ë¢°ë„ í™•ë³´
3. **ë¬¸ì„œí™”**: ê²€ì¦ ê³¼ì • ë° ê²°ê³¼ ë¬¸ì„œí™”

""")

    logger.info(f"ê²€ì¦ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {output_file}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print("XTF ë©”íƒ€ë°ì´í„° ì¢Œí‘œ ì¶”ì¶œ ê²€ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    try:
        # ì¢Œí‘œ ì¶”ì¶œ ê²€ì¦ ì‹¤í–‰
        results, analysis = verify_xtf_coordinate_extraction()

        print(f"\n{'='*70}")
        print("ğŸ¯ ê²€ì¦ ê²°ê³¼ ìš”ì•½")
        print(f"{'='*70}")

        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print(f"\nğŸ“Š ê¸°ë³¸ ì •ë³´:")
        print(f"   ë¶„ì„ íŒŒì¼: {analysis['total_files_analyzed']}ê°œ")
        print(f"   ì˜¤ë¥˜ ë°œê²¬ íŒŒì¼: {analysis['files_with_errors']}ê°œ")
        print(f"   ì¢Œí‘œ ë¶ˆì¼ì¹˜ íŒŒì¼: {analysis['files_with_coordinate_discrepancies']}ê°œ")

        print(f"\nğŸ” ì˜¤ë¥˜ íŒ¨í„´:")
        error_patterns = analysis.get('common_error_patterns', {})
        if error_patterns:
            for pattern, count in error_patterns.items():
                pattern_korean = {
                    'digit_truncation': 'ìë¦¿ìˆ˜ ì ˆë‹¨ ì˜¤ë¥˜',
                    'coordinate_difference': 'ì¢Œí‘œ ì°¨ì´'
                }.get(pattern, pattern)
                print(f"   {pattern_korean}: {count}ê±´")
        else:
            print(f"   ê³µí†µ ì˜¤ë¥˜ íŒ¨í„´ ì—†ìŒ")

        print(f"\nğŸ’¡ Location_MDGPS ë¶„ì„ ì˜í–¥:")
        impact = analysis.get('impact_on_location_analysis', {})
        print(f"   ìœ„ì¹˜ ì´ë™ ê°€ëŠ¥ì„±: {'ìˆìŒ' if impact.get('potential_location_shift') else 'ì—†ìŒ'}")
        print(f"   ì¬ë¶„ì„ í•„ìš”ì„±: {'í•„ìš”' if impact.get('requires_reanalysis') else 'ë¶ˆí•„ìš”'}")

        # ìµœì¢… ê²°ë¡ 
        if analysis['files_with_coordinate_discrepancies'] > 0:
            print(f"\nâš ï¸ ê²°ë¡ : ì¢Œí‘œ ì¶”ì¶œ ì˜¤ë¥˜ ë°œê²¬ - ì¬ë¶„ì„ ê¶Œì¥")
        else:
            print(f"\nâœ… ê²°ë¡ : ì¢Œí‘œ ì¶”ì¶œ ì •í™•ì„± í™•ì¸ - ì´ì „ ë¶„ì„ ê²°ê³¼ ìœ íš¨")

        print(f"\nğŸ“ ìƒì„¸ ê²°ê³¼: analysis_results/xtf_metadata_verification/")

    except Exception as e:
        logger.error(f"ê²€ì¦ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return False

    return True

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ XTF ë©”íƒ€ë°ì´í„° ì¢Œí‘œ ì¶”ì¶œ ê²€ì¦ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("\nâŒ ê²€ì¦ ê³¼ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)