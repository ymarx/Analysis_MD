#!/usr/bin/env python3
"""
XTF Reader & Intensity Extractor ê²€ì¦ í…ŒìŠ¤íŠ¸
=============================================
ë‘ ì¢…ë¥˜ ê¸°ì¢…(EdgeTech 4205, Klein 3900)ì˜ ì‚¬ì´ë“œ ìŠ¤ìº” ì†Œë‚˜ì—ì„œ
íŒ¨í‚· ì •ë³´, ë©”íƒ€ë°ì´í„°, ë„˜íŒŒì´ ë°°ì—´ í˜•íƒœì˜ ê°•ë„ ë°ì´í„° ì¶”ì¶œì„ ê²€ì¦í•©ë‹ˆë‹¤.

Author: YMARX
Date: 2025-09-22
"""

import sys
import logging
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import json

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# Import custom modules
from src.data_processing.xtf_reader import XTFReader, BatchXTFProcessor, PingData, XTFMetadata
from src.data_processing.xtf_intensity_extractor import XTFIntensityExtractor, IntensityMetadata, IntensityPing

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_xtf_reader_extraction():
    """XTF Readerì˜ íŒ¨í‚· ì •ë³´ ë° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ê²€ì¦"""

    logger.info("="*70)
    logger.info("XTF READER ê²€ì¦ í…ŒìŠ¤íŠ¸")
    logger.info("="*70)

    # í…ŒìŠ¤íŠ¸í•  XTF íŒŒì¼ë“¤ (ë‘ ê¸°ì¢…)
    test_files = [
        {
            'path': "datasets/Pohang_Eardo_1_Edgetech4205_800_050_20241012110900_001_04/original/Pohang_Eardo_1_Edgetech4205_800_050_20241012110900_001_04.xtf",
            'type': 'EdgeTech 4205',
            'frequency': '800 kHz'
        },
        {
            'path': "datasets/Pohang_Eardo_1_Klein3900_900_050_20241011171100_001_04/original/Pohang_Eardo_1_Klein3900_900_050_20241011171100_001_04.xtf",
            'type': 'Klein 3900',
            'frequency': '900 kHz'
        },
        {
            'path': "datasets/Pohang_Eardo_1_Edgetech4205_800_050_20241012181900_001_04/original/Pohang_Eardo_1_Edgetech4205_800_050_20241012181900_001_04.xtf",
            'type': 'EdgeTech 4205',
            'frequency': '800 kHz'
        }
    ]

    results = {}

    for file_info in test_files:
        file_path = Path(file_info['path'])

        if not file_path.exists():
            logger.warning(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            continue

        logger.info(f"\n{'='*50}")
        logger.info(f"í…ŒìŠ¤íŠ¸: {file_info['type']} - {file_path.name}")
        logger.info(f"ì£¼íŒŒìˆ˜: {file_info['frequency']}")

        try:
            # XTF Reader ì´ˆê¸°í™” ë° ë¡œë“œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ 1000 pingìœ¼ë¡œ ì œí•œ)
            reader = XTFReader(file_path, max_pings=1000)

            # 1. íŒŒì¼ ë¡œë“œ í…ŒìŠ¤íŠ¸
            load_success = reader.load_file()
            logger.info(f"íŒŒì¼ ë¡œë“œ: {'âœ… ì„±ê³µ' if load_success else 'âŒ ì‹¤íŒ¨'}")

            if not load_success:
                continue

            # 2. ë©”íƒ€ë°ì´í„° ê²€ì¦
            metadata = reader.metadata
            if metadata:
                logger.info(f"ë©”íƒ€ë°ì´í„° ìƒì„±: âœ… ì„±ê³µ")
                logger.info(f"  - ì´ ping ìˆ˜: {metadata.total_pings:,}")
                logger.info(f"  - ì†Œë‚˜ ì±„ë„ ìˆ˜: {metadata.num_sonar_channels}")
                logger.info(f"  - ì£¼íŒŒìˆ˜ ì •ë³´: {metadata.frequency_info}")
                logger.info(f"  - ì¢Œí‘œ ë²”ìœ„: {metadata.coordinate_bounds}")
                logger.info(f"  - ì‹œê°„ ë²”ìœ„: {metadata.time_range}")
            else:
                logger.warning("ë©”íƒ€ë°ì´í„° ìƒì„± ì‹¤íŒ¨")

            # 3. Ping ë°ì´í„° íŒŒì‹± í…ŒìŠ¤íŠ¸
            ping_data = reader.parse_pings()
            logger.info(f"Ping ë°ì´í„° íŒŒì‹±: {'âœ… ì„±ê³µ' if ping_data else 'âŒ ì‹¤íŒ¨'}")
            logger.info(f"  - íŒŒì‹±ëœ ping ìˆ˜: {len(ping_data):,}")

            if ping_data:
                # ìƒ˜í”Œ ping ë°ì´í„° ê²€ì¦
                sample_ping = ping_data[0]
                logger.info(f"  - ìƒ˜í”Œ ping ì •ë³´:")
                logger.info(f"    * Ping ë²ˆí˜¸: {sample_ping.ping_number}")
                logger.info(f"    * íƒ€ì„ìŠ¤íƒ¬í”„: {sample_ping.timestamp}")
                logger.info(f"    * ìœ„ë„: {sample_ping.latitude:.6f}")
                logger.info(f"    * ê²½ë„: {sample_ping.longitude:.6f}")
                logger.info(f"    * ì£¼íŒŒìˆ˜: {sample_ping.frequency} Hz")
                logger.info(f"    * ë°ì´í„° í¬ê¸°: {sample_ping.data.shape if sample_ping.data.size > 0 else 'N/A'}")
                logger.info(f"    * ìƒ˜í”Œ ìˆ˜: {sample_ping.range_samples}")

            # 4. Intensity ë§¤íŠ¸ë¦­ìŠ¤ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
            intensity_matrix = reader.extract_intensity_matrix()
            logger.info(f"Intensity ë§¤íŠ¸ë¦­ìŠ¤ ì¶”ì¶œ: {'âœ… ì„±ê³µ' if intensity_matrix.size > 0 else 'âŒ ì‹¤íŒ¨'}")
            if intensity_matrix.size > 0:
                logger.info(f"  - ë§¤íŠ¸ë¦­ìŠ¤ í¬ê¸°: {intensity_matrix.shape}")
                logger.info(f"  - ë°ì´í„° íƒ€ì…: {intensity_matrix.dtype}")
                logger.info(f"  - ê°’ ë²”ìœ„: [{intensity_matrix.min():.3f}, {intensity_matrix.max():.3f}]")
                logger.info(f"  - í‰ê·  ê°•ë„: {intensity_matrix.mean():.3f}")

            # 5. ìœ„ì¹˜ ì •ë³´ ë°ì´í„°í”„ë ˆì„ í…ŒìŠ¤íŠ¸
            georef_df = reader.get_georeferenced_data()
            logger.info(f"ìœ„ì¹˜ ì •ë³´ ë°ì´í„°í”„ë ˆì„: {'âœ… ì„±ê³µ' if not georef_df.empty else 'âŒ ì‹¤íŒ¨'}")
            if not georef_df.empty:
                logger.info(f"  - ë°ì´í„°í”„ë ˆì„ í¬ê¸°: {georef_df.shape}")
                logger.info(f"  - ì»¬ëŸ¼: {list(georef_df.columns)}")

                # ì¢Œí‘œ í†µê³„
                if 'latitude' in georef_df.columns and 'longitude' in georef_df.columns:
                    lat_stats = georef_df['latitude'].describe()
                    lon_stats = georef_df['longitude'].describe()
                    logger.info(f"  - ìœ„ë„ ë²”ìœ„: [{lat_stats['min']:.6f}, {lat_stats['max']:.6f}]")
                    logger.info(f"  - ê²½ë„ ë²”ìœ„: [{lon_stats['min']:.6f}, {lon_stats['max']:.6f}]")

            # 6. ìš”ì•½ ì •ë³´ í…ŒìŠ¤íŠ¸
            summary = reader.get_summary()
            logger.info(f"ìš”ì•½ ì •ë³´: {'âœ… ì„±ê³µ' if summary else 'âŒ ì‹¤íŒ¨'}")

            # ê²°ê³¼ ì €ì¥
            results[file_path.name] = {
                'file_type': file_info['type'],
                'frequency': file_info['frequency'],
                'load_success': load_success,
                'metadata_valid': metadata is not None,
                'ping_count': len(ping_data) if ping_data else 0,
                'intensity_matrix_shape': intensity_matrix.shape if intensity_matrix.size > 0 else None,
                'georef_data_valid': not georef_df.empty,
                'summary_valid': bool(summary)
            }

        except Exception as e:
            logger.error(f"XTF Reader í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())

    return results


def test_intensity_extractor():
    """Intensity Extractorì˜ ê°•ë„ ë°ì´í„° ì¶”ì¶œ ê²€ì¦"""

    logger.info("="*70)
    logger.info("INTENSITY EXTRACTOR ê²€ì¦ í…ŒìŠ¤íŠ¸")
    logger.info("="*70)

    # í…ŒìŠ¤íŠ¸í•  XTF íŒŒì¼ë“¤
    test_files = [
        {
            'path': "datasets/Pohang_Eardo_1_Edgetech4205_800_050_20241012110900_001_04/original/Pohang_Eardo_1_Edgetech4205_800_050_20241012110900_001_04.xtf",
            'type': 'EdgeTech 4205'
        },
        {
            'path': "datasets/Pohang_Eardo_1_Klein3900_900_050_20241011171100_001_04/original/Pohang_Eardo_1_Klein3900_900_050_20241011171100_001_04.xtf",
            'type': 'Klein 3900'
        }
    ]

    results = {}

    # Intensity Extractor ì´ˆê¸°í™”
    extractor = XTFIntensityExtractor(max_memory_mb=512)  # ë©”ëª¨ë¦¬ ì œí•œ

    for file_info in test_files:
        file_path = Path(file_info['path'])

        if not file_path.exists():
            logger.warning(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            continue

        logger.info(f"\n{'='*50}")
        logger.info(f"í…ŒìŠ¤íŠ¸: {file_info['type']} - {file_path.name}")

        try:
            # ê°•ë„ ë°ì´í„° ì¶”ì¶œ (ping ì œí•œìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
            output_dir = f"analysis_results/xtf_extraction_test/{file_path.stem}"
            extracted_data = extractor.extract_intensity_data(
                str(file_path),
                output_dir=output_dir,
                ping_range=(0, 500)  # ì²˜ìŒ 500 pingë§Œ í…ŒìŠ¤íŠ¸
            )

            # 1. ë©”íƒ€ë°ì´í„° ê²€ì¦
            metadata = extracted_data.get('metadata')
            if metadata:
                logger.info(f"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ: âœ… ì„±ê³µ")
                logger.info(f"  - íŒŒì¼ ê²½ë¡œ: {metadata.file_path}")
                logger.info(f"  - Ping ìˆ˜: {metadata.ping_count}")
                logger.info(f"  - ì±„ë„ ìˆ˜: {metadata.channel_count}")
                logger.info(f"  - ì£¼íŒŒìˆ˜: {metadata.frequency} Hz")
                logger.info(f"  - ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜: {metadata.sample_rate} Hz")
                logger.info(f"  - ê±°ë¦¬ í•´ìƒë„: {metadata.range_resolution} m")
                logger.info(f"  - ì‹œê°„ ë²”ìœ„: {metadata.timestamp_range}")
                logger.info(f"  - ì¢Œí‘œ ë²”ìœ„: {metadata.coordinate_bounds}")
            else:
                logger.warning("ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨")

            # 2. Ping ë°ì´í„° ê²€ì¦
            ping_data = extracted_data.get('ping_data', [])
            logger.info(f"Ping ë°ì´í„° ì¶”ì¶œ: {'âœ… ì„±ê³µ' if ping_data else 'âŒ ì‹¤íŒ¨'}")
            logger.info(f"  - ì¶”ì¶œëœ ping ìˆ˜: {len(ping_data)}")

            if ping_data:
                sample_ping = ping_data[0]
                logger.info(f"  - ìƒ˜í”Œ ping ì •ë³´:")
                logger.info(f"    * Ping ë²ˆí˜¸: {sample_ping.ping_number}")
                logger.info(f"    * íƒ€ì„ìŠ¤íƒ¬í”„: {sample_ping.timestamp}")
                logger.info(f"    * ìœ„ì¹˜: ({sample_ping.latitude:.6f}, {sample_ping.longitude:.6f})")
                logger.info(f"    * ë°©í–¥: {sample_ping.heading}Â°")
                logger.info(f"    * Port ë°ì´í„°: {sample_ping.port_intensity.shape}")
                logger.info(f"    * Starboard ë°ì´í„°: {sample_ping.starboard_intensity.shape}")

            # 3. Intensity ì´ë¯¸ì§€ ê²€ì¦
            intensity_images = extracted_data.get('intensity_images', {})
            logger.info(f"Intensity ì´ë¯¸ì§€ ìƒì„±: {'âœ… ì„±ê³µ' if intensity_images else 'âŒ ì‹¤íŒ¨'}")

            for img_type, img_array in intensity_images.items():
                if img_array.size > 0:
                    logger.info(f"  - {img_type.upper()} ì´ë¯¸ì§€:")
                    logger.info(f"    * í¬ê¸°: {img_array.shape}")
                    logger.info(f"    * ë°ì´í„° íƒ€ì…: {img_array.dtype}")
                    logger.info(f"    * ê°’ ë²”ìœ„: [{img_array.min():.3f}, {img_array.max():.3f}]")
                    logger.info(f"    * í‰ê· : {img_array.mean():.3f}")
                    logger.info(f"    * í‘œì¤€í¸ì°¨: {img_array.std():.3f}")
                else:
                    logger.warning(f"  - {img_type.upper()} ì´ë¯¸ì§€: ë°ì´í„° ì—†ìŒ")

            # 4. Navigation ë°ì´í„° ê²€ì¦
            nav_data = extracted_data.get('navigation_data', {})
            logger.info(f"Navigation ë°ì´í„° ì¶”ì¶œ: {'âœ… ì„±ê³µ' if nav_data else 'âŒ ì‹¤íŒ¨'}")

            if nav_data:
                for data_type, data_array in nav_data.items():
                    if isinstance(data_array, np.ndarray) and data_array.size > 0:
                        logger.info(f"  - {data_type}: {data_array.shape}, ë²”ìœ„ [{data_array.min():.3f}, {data_array.max():.3f}]")

            # 5. ë°ì´í„° í’ˆì§ˆ ê²€ì¦
            quality_score = assess_data_quality(extracted_data)
            logger.info(f"ë°ì´í„° í’ˆì§ˆ ì ìˆ˜: {quality_score:.2f}/100")

            # ê²°ê³¼ ì €ì¥
            results[file_path.name] = {
                'file_type': file_info['type'],
                'extraction_success': bool(extracted_data),
                'metadata_valid': metadata is not None,
                'ping_count': len(ping_data),
                'intensity_images': {k: v.shape if v.size > 0 else None for k, v in intensity_images.items()},
                'navigation_data_valid': bool(nav_data),
                'quality_score': quality_score,
                'output_directory': output_dir
            }

        except Exception as e:
            logger.error(f"Intensity Extractor í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())

    return results


def assess_data_quality(extracted_data):
    """ì¶”ì¶œëœ ë°ì´í„°ì˜ í’ˆì§ˆ í‰ê°€"""
    score = 0

    # ë©”íƒ€ë°ì´í„° í’ˆì§ˆ (25ì )
    metadata = extracted_data.get('metadata')
    if metadata:
        score += 10
        if metadata.ping_count > 0:
            score += 5
        if metadata.frequency > 0:
            score += 5
        if metadata.coordinate_bounds:
            score += 5

    # Ping ë°ì´í„° í’ˆì§ˆ (25ì )
    ping_data = extracted_data.get('ping_data', [])
    if ping_data:
        score += 10
        if len(ping_data) > 100:
            score += 5
        # ì¢Œí‘œ ìœ íš¨ì„± ê²€ì‚¬
        valid_coords = sum(1 for ping in ping_data if ping.latitude != 0 and ping.longitude != 0)
        if valid_coords > len(ping_data) * 0.8:  # 80% ì´ìƒ ìœ íš¨í•œ ì¢Œí‘œ
            score += 5
        # ê°•ë„ ë°ì´í„° ìœ íš¨ì„±
        valid_intensity = sum(1 for ping in ping_data if ping.port_intensity.size > 0 or ping.starboard_intensity.size > 0)
        if valid_intensity > len(ping_data) * 0.9:  # 90% ì´ìƒ ìœ íš¨í•œ ê°•ë„ ë°ì´í„°
            score += 5

    # ì´ë¯¸ì§€ í’ˆì§ˆ (25ì )
    intensity_images = extracted_data.get('intensity_images', {})
    if intensity_images:
        valid_images = sum(1 for img in intensity_images.values() if img.size > 0)
        score += min(valid_images * 8, 25)  # ìµœëŒ€ 25ì 

    # Navigation ë°ì´í„° í’ˆì§ˆ (25ì )
    nav_data = extracted_data.get('navigation_data', {})
    if nav_data:
        valid_nav = sum(1 for data in nav_data.values() if isinstance(data, np.ndarray) and data.size > 0)
        score += min(valid_nav * 5, 25)  # ìµœëŒ€ 25ì 

    return score


def test_batch_processing():
    """ë°°ì¹˜ í”„ë¡œì„¸ì‹± í…ŒìŠ¤íŠ¸"""

    logger.info("="*70)
    logger.info("BATCH PROCESSING ê²€ì¦ í…ŒìŠ¤íŠ¸")
    logger.info("="*70)

    # ëª¨ë“  XTF íŒŒì¼
    file_paths = [
        "datasets/Pohang_Eardo_1_Edgetech4205_800_050_20241012110900_001_04/original/Pohang_Eardo_1_Edgetech4205_800_050_20241012110900_001_04.xtf",
        "datasets/Pohang_Eardo_1_Klein3900_900_050_20241011171100_001_04/original/Pohang_Eardo_1_Klein3900_900_050_20241011171100_001_04.xtf",
        "datasets/Pohang_Eardo_1_Edgetech4205_800_050_20241012181900_001_04/original/Pohang_Eardo_1_Edgetech4205_800_050_20241012181900_001_04.xtf"
    ]

    # ì¡´ì¬í•˜ëŠ” íŒŒì¼ë§Œ í•„í„°ë§
    existing_files = [fp for fp in file_paths if Path(fp).exists()]
    logger.info(f"ë°°ì¹˜ ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {len(existing_files)}")

    try:
        # ë°°ì¹˜ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        batch_processor = BatchXTFProcessor(existing_files, max_pings_per_file=500)

        # ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
        readers = batch_processor.process_all()
        logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼: {len(readers)}/{len(existing_files)} íŒŒì¼ ì„±ê³µ")

        # ì¢…í•© ìš”ì•½ ì •ë³´
        combined_summary = batch_processor.get_combined_summary()
        logger.info(f"ì¢…í•© ìš”ì•½:")
        logger.info(f"  - ì´ íŒŒì¼ ìˆ˜: {combined_summary.get('total_files', 0)}")
        logger.info(f"  - ì´ ping ìˆ˜: {combined_summary.get('total_pings', 0):,}")
        logger.info(f"  - ì£¼íŒŒìˆ˜ ì¢…ë¥˜: {combined_summary.get('unique_frequencies', [])}")
        logger.info(f"  - ì±„ë„ ì¢…ë¥˜: {combined_summary.get('channels', [])}")

        return True

    except Exception as e:
        logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


def generate_test_report(reader_results, extractor_results, batch_success):
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""

    report_lines = []
    report_lines.append("# XTF Reader & Intensity Extractor ê²€ì¦ ë³´ê³ ì„œ")
    report_lines.append(f"**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append(f"**ë¶„ì„ì**: YMARX")
    report_lines.append("")

    # XTF Reader ê²°ê³¼
    report_lines.append("## ğŸ” **XTF Reader ê²€ì¦ ê²°ê³¼**")
    report_lines.append("")

    if reader_results:
        for filename, result in reader_results.items():
            status = "âœ…" if result['load_success'] else "âŒ"
            report_lines.append(f"### {status} {filename}")
            report_lines.append(f"- **ê¸°ì¢…**: {result['file_type']}")
            report_lines.append(f"- **ì£¼íŒŒìˆ˜**: {result['frequency']}")
            report_lines.append(f"- **íŒŒì¼ ë¡œë“œ**: {'ì„±ê³µ' if result['load_success'] else 'ì‹¤íŒ¨'}")
            report_lines.append(f"- **ë©”íƒ€ë°ì´í„°**: {'ìœ íš¨' if result['metadata_valid'] else 'ë¬´íš¨'}")
            report_lines.append(f"- **Ping ìˆ˜**: {result['ping_count']:,}")
            report_lines.append(f"- **Intensity ë§¤íŠ¸ë¦­ìŠ¤**: {result['intensity_matrix_shape'] if result['intensity_matrix_shape'] else 'N/A'}")
            report_lines.append(f"- **ìœ„ì¹˜ ë°ì´í„°**: {'ìœ íš¨' if result['georef_data_valid'] else 'ë¬´íš¨'}")
            report_lines.append("")
    else:
        report_lines.append("âŒ XTF Reader í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì—†ìŒ")
        report_lines.append("")

    # Intensity Extractor ê²°ê³¼
    report_lines.append("## ğŸ¨ **Intensity Extractor ê²€ì¦ ê²°ê³¼**")
    report_lines.append("")

    if extractor_results:
        for filename, result in extractor_results.items():
            status = "âœ…" if result['extraction_success'] else "âŒ"
            report_lines.append(f"### {status} {filename}")
            report_lines.append(f"- **ê¸°ì¢…**: {result['file_type']}")
            report_lines.append(f"- **ì¶”ì¶œ ì„±ê³µ**: {'ì„±ê³µ' if result['extraction_success'] else 'ì‹¤íŒ¨'}")
            report_lines.append(f"- **ë©”íƒ€ë°ì´í„°**: {'ìœ íš¨' if result['metadata_valid'] else 'ë¬´íš¨'}")
            report_lines.append(f"- **Ping ìˆ˜**: {result['ping_count']:,}")
            report_lines.append(f"- **í’ˆì§ˆ ì ìˆ˜**: {result['quality_score']:.1f}/100")

            if result['intensity_images']:
                report_lines.append(f"- **Intensity ì´ë¯¸ì§€**:")
                for img_type, shape in result['intensity_images'].items():
                    report_lines.append(f"  - {img_type.upper()}: {shape if shape else 'N/A'}")

            report_lines.append(f"- **Navigation ë°ì´í„°**: {'ìœ íš¨' if result['navigation_data_valid'] else 'ë¬´íš¨'}")
            report_lines.append(f"- **ì¶œë ¥ ë””ë ‰í† ë¦¬**: {result['output_directory']}")
            report_lines.append("")
    else:
        report_lines.append("âŒ Intensity Extractor í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì—†ìŒ")
        report_lines.append("")

    # ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼
    report_lines.append("## ğŸ”„ **ë°°ì¹˜ ì²˜ë¦¬ ê²€ì¦ ê²°ê³¼**")
    report_lines.append("")
    report_lines.append(f"**ë°°ì¹˜ ì²˜ë¦¬**: {'âœ… ì„±ê³µ' if batch_success else 'âŒ ì‹¤íŒ¨'}")
    report_lines.append("")

    # ì¢…í•© ê²°ë¡ 
    report_lines.append("## ğŸ¯ **ì¢…í•© ê²°ë¡ **")
    report_lines.append("")

    # XTF Reader ì„±ê³µë¥ 
    reader_success_rate = 0
    if reader_results:
        successful_readers = sum(1 for r in reader_results.values() if r['load_success'])
        reader_success_rate = successful_readers / len(reader_results) * 100

    # Intensity Extractor ì„±ê³µë¥ 
    extractor_success_rate = 0
    if extractor_results:
        successful_extractors = sum(1 for r in extractor_results.values() if r['extraction_success'])
        extractor_success_rate = successful_extractors / len(extractor_results) * 100

    # í‰ê·  í’ˆì§ˆ ì ìˆ˜
    avg_quality = 0
    if extractor_results:
        quality_scores = [r['quality_score'] for r in extractor_results.values()]
        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0

    report_lines.append(f"- **XTF Reader ì„±ê³µë¥ **: {reader_success_rate:.1f}%")
    report_lines.append(f"- **Intensity Extractor ì„±ê³µë¥ **: {extractor_success_rate:.1f}%")
    report_lines.append(f"- **í‰ê·  ë°ì´í„° í’ˆì§ˆ**: {avg_quality:.1f}/100")
    report_lines.append(f"- **ë°°ì¹˜ ì²˜ë¦¬**: {'ì„±ê³µ' if batch_success else 'ì‹¤íŒ¨'}")
    report_lines.append("")

    if reader_success_rate >= 80 and extractor_success_rate >= 80 and avg_quality >= 70:
        report_lines.append("### âœ… **ì „ì²´ ê²€ì¦ ì„±ê³µ**")
        report_lines.append("ë‘ ì¢…ë¥˜ ê¸°ì¢…ì˜ ì‚¬ì´ë“œ ìŠ¤ìº” ì†Œë‚˜ì—ì„œ íŒ¨í‚· ì •ë³´, ë©”íƒ€ë°ì´í„°, ë„˜íŒŒì´ ë°°ì—´ í˜•íƒœì˜ ê°•ë„ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œë©ë‹ˆë‹¤.")
    else:
        report_lines.append("### âš ï¸ **ë¶€ë¶„ì  ê²€ì¦ ì„±ê³µ**")
        report_lines.append("ì¼ë¶€ ê¸°ëŠ¥ì—ì„œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    # ë³´ê³ ì„œ ì €ì¥
    output_dir = Path("analysis_results/xtf_extraction_test")
    output_dir.mkdir(parents=True, exist_ok=True)

    report_file = output_dir / "XTF_EXTRACTION_VERIFICATION_REPORT.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))

    # JSON ê²°ê³¼ë„ ì €ì¥
    json_data = {
        'xtf_reader_results': reader_results,
        'intensity_extractor_results': extractor_results,
        'batch_processing_success': batch_success,
        'summary': {
            'reader_success_rate': reader_success_rate,
            'extractor_success_rate': extractor_success_rate,
            'average_quality_score': avg_quality
        },
        'test_timestamp': datetime.now().isoformat()
    }

    json_file = output_dir / "xtf_extraction_verification_data.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False, default=str)

    logger.info(f"ê²€ì¦ ë³´ê³ ì„œ ì €ì¥: {report_file}")
    logger.info(f"ê²€ì¦ ë°ì´í„° ì €ì¥: {json_file}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("XTF Reader & Intensity Extractor ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹œì‘")

    try:
        # 1. XTF Reader í…ŒìŠ¤íŠ¸
        logger.info("1ë‹¨ê³„: XTF Reader ê²€ì¦")
        reader_results = test_xtf_reader_extraction()

        # 2. Intensity Extractor í…ŒìŠ¤íŠ¸
        logger.info("\n2ë‹¨ê³„: Intensity Extractor ê²€ì¦")
        extractor_results = test_intensity_extractor()

        # 3. ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        logger.info("\n3ë‹¨ê³„: ë°°ì¹˜ ì²˜ë¦¬ ê²€ì¦")
        batch_success = test_batch_processing()

        # 4. ë³´ê³ ì„œ ìƒì„±
        logger.info("\n4ë‹¨ê³„: ê²€ì¦ ë³´ê³ ì„œ ìƒì„±")
        generate_test_report(reader_results, extractor_results, batch_success)

        # ìš”ì•½ ì¶œë ¥
        print("\n" + "="*70)
        print("XTF EXTRACTION ê²€ì¦ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        print("="*70)

        reader_success = sum(1 for r in reader_results.values() if r['load_success']) if reader_results else 0
        extractor_success = sum(1 for r in extractor_results.values() if r['extraction_success']) if extractor_results else 0

        print(f"ğŸ“ XTF Reader: {reader_success}/{len(reader_results) if reader_results else 0} ì„±ê³µ")
        print(f"ğŸ¨ Intensity Extractor: {extractor_success}/{len(extractor_results) if extractor_results else 0} ì„±ê³µ")
        print(f"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬: {'ì„±ê³µ' if batch_success else 'ì‹¤íŒ¨'}")
        print(f"ğŸ“Š ê²°ê³¼ ì €ì¥: analysis_results/xtf_extraction_test/")

        return 0

    except Exception as e:
        logger.error(f"ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 1


if __name__ == "__main__":
    exit(main())