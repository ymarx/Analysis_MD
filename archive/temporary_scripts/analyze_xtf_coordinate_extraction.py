#!/usr/bin/env python3
"""
XTF ì¢Œí‘œ ì¶”ì¶œ ë°©ë²• ë° ì˜¤ì°¨ ìš”ì¸ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python analyze_xtf_coordinate_extraction.py

ëª©ì :
    1. í˜„ì¬ XTF Readerì˜ ì¢Œí‘œ ì‚°ì¶œ ë°©ë²• ë¶„ì„
    2. Slant range, ì‹¬ë„ ë“±ì´ ìœ„ê²½ë„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ê²€í† 
    3. Location_MDGPSì™€ XTF ì¢Œí‘œ ì°¨ì´ì˜ ê¸°ìˆ ì  ì›ì¸ ê·œëª…
"""

import os
import sys
import numpy as np
import pandas as pd
from datetime import datetime
import logging
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import json
import pyxtf

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.data_processing.xtf_reader import XTFReader
from src.data_processing.xtf_intensity_extractor import XTFIntensityExtractor

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def analyze_xtf_coordinate_system():
    """XTF íŒŒì¼ì˜ ì¢Œí‘œ ì‹œìŠ¤í…œ ë° ì¶”ì¶œ ë°©ë²• ë¶„ì„"""

    logger.info("XTF ì¢Œí‘œ ì‹œìŠ¤í…œ ë¶„ì„ ì‹œì‘")
    print("="*70)
    print("XTF ì¢Œí‘œ ì¶”ì¶œ ë°©ë²• ë° ì˜¤ì°¨ ìš”ì¸ ë¶„ì„")
    print("="*70)

    # XTF íŒŒì¼ ê²½ë¡œ ì„¤ì •
    xtf_files = [
        "datasets/Pohang_Eardo_1_Edgetech4205_800_050_20241012110900_001_04/original/Pohang_Eardo_1_Edgetech4205_800_050_20241012110900_001_04.xtf",
        "datasets/Pohang_Eardo_1_Klein3900_900_050_20241011171100_001_04/original/Pohang_Eardo_1_Klein3900_900_050_20241011171100_001_04.xtf",
        "datasets/Pohang_Eardo_1_Edgetech4205_800_050_20241012181900_001_04/original/Pohang_Eardo_1_Edgetech4205_800_050_20241012181900_001_04.xtf"
    ]

    analysis_results = []

    for xtf_path in xtf_files:
        if not os.path.exists(xtf_path):
            logger.warning(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {xtf_path}")
            continue

        logger.info(f"ë¶„ì„ ì¤‘: {xtf_path}")

        result = analyze_single_xtf(xtf_path)
        if result:
            analysis_results.append(result)

    # ì¢…í•© ë¶„ì„
    comprehensive_analysis = perform_comprehensive_analysis(analysis_results)

    # ê²°ê³¼ ì €ì¥
    save_analysis_results(analysis_results, comprehensive_analysis)

    return analysis_results, comprehensive_analysis

def analyze_single_xtf(xtf_path: str) -> Dict:
    """ë‹¨ì¼ XTF íŒŒì¼ì˜ ì¢Œí‘œ ì¶”ì¶œ ë°©ë²• ë¶„ì„"""

    try:
        # 1. pyxtf ì›ì‹œ íŒ¨í‚· ë¶„ì„
        raw_analysis = analyze_raw_xtf_packets(xtf_path)

        # 2. XTF Reader ì¢Œí‘œ ì¶”ì¶œ ë¶„ì„
        reader_analysis = analyze_xtf_reader_coordinates(xtf_path)

        # 3. ì¢Œí‘œ ë³€í™˜ ë° ì˜¤ì°¨ ë¶„ì„
        coordinate_analysis = analyze_coordinate_transformation(xtf_path)

        result = {
            'file_path': xtf_path,
            'filename': os.path.basename(xtf_path),
            'raw_packet_analysis': raw_analysis,
            'reader_analysis': reader_analysis,
            'coordinate_analysis': coordinate_analysis,
            'analysis_timestamp': datetime.now().isoformat()
        }

        print(f"\n{'='*50}")
        print(f"íŒŒì¼: {os.path.basename(xtf_path)}")
        print(f"{'='*50}")

        # ê²°ê³¼ ì¶œë ¥
        print_analysis_results(result)

        return result

    except Exception as e:
        logger.error(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ {xtf_path}: {e}")
        return None

def analyze_raw_xtf_packets(xtf_path: str) -> Dict:
    """pyxtfë¡œ ì›ì‹œ íŒ¨í‚· ë¶„ì„í•˜ì—¬ ì¢Œí‘œ ì •ë³´ ì¶”ì¶œ"""

    logger.info("ì›ì‹œ XTF íŒ¨í‚· ë¶„ì„ ì¤‘...")

    try:
        # pyxtfë¡œ ì§ì ‘ íŒŒì¼ ì½ê¸°
        packets = []
        for packet in pyxtf.xtf_read_gen(xtf_path):
            packets.append(packet)

        coordinate_fields = {}
        sonar_packets = []
        nav_packets = []

        for packet in packets:
            # ì†Œë‚˜ íŒ¨í‚· ë¶„ì„
            if hasattr(packet, 'data') and packet.data is not None:
                sonar_packets.append(packet)

                # ì¢Œí‘œ ê´€ë ¨ ì†ì„± ìˆ˜ì§‘
                coord_attrs = ['SensorXcoordinate', 'SensorYcoordinate', 'SensorX', 'SensorY',
                              'ShipXcoordinate', 'ShipYcoordinate', 'ShipX', 'ShipY',
                              'SlantRange', 'DepthOffset', 'TowfishHeading', 'TowfishAltitude']

                for attr in coord_attrs:
                    if hasattr(packet, attr):
                        value = getattr(packet, attr)
                        if attr not in coordinate_fields:
                            coordinate_fields[attr] = []
                        coordinate_fields[attr].append(value)

            # ë‚´ë¹„ê²Œì´ì…˜ íŒ¨í‚· ë¶„ì„ (ìˆë‹¤ë©´)
            if hasattr(packet, 'coordinate'):
                nav_packets.append(packet)

        # í†µê³„ ê³„ì‚°
        coord_stats = {}
        for field, values in coordinate_fields.items():
            if values:
                coord_stats[field] = {
                    'count': len(values),
                    'min': float(np.min(values)),
                    'max': float(np.max(values)),
                    'mean': float(np.mean(values)),
                    'std': float(np.std(values))
                }

        return {
            'total_packets': len(packets),
            'sonar_packets': len(sonar_packets),
            'nav_packets': len(nav_packets),
            'coordinate_fields': list(coordinate_fields.keys()),
            'coordinate_statistics': coord_stats,
            'has_slant_range': 'SlantRange' in coordinate_fields,
            'has_depth_offset': 'DepthOffset' in coordinate_fields,
            'has_towfish_data': any('Towfish' in field for field in coordinate_fields.keys())
        }

    except Exception as e:
        logger.error(f"ì›ì‹œ íŒ¨í‚· ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {'error': str(e)}

def analyze_xtf_reader_coordinates(xtf_path: str) -> Dict:
    """XTF Readerì˜ ì¢Œí‘œ ì¶”ì¶œ ë°©ë²• ë¶„ì„"""

    logger.info("XTF Reader ì¢Œí‘œ ì¶”ì¶œ ë¶„ì„ ì¤‘...")

    try:
        # XTF Readerë¡œ íŒŒì¼ ì½ê¸°
        reader = XTFReader(xtf_path, max_pings=100)  # ìƒ˜í”Œ ë¶„ì„
        reader.load_file()
        ping_data = reader.parse_pings()

        if not ping_data:
            return {'error': 'No ping data extracted'}

        # ì¢Œí‘œ ë°ì´í„° ì¶”ì¶œ
        latitudes = [ping.latitude for ping in ping_data]
        longitudes = [ping.longitude for ping in ping_data]
        ship_x = [ping.ship_x for ping in ping_data]
        ship_y = [ping.ship_y for ping in ping_data]

        # ì¢Œí‘œ ë²”ìœ„ ë° í†µê³„
        lat_stats = {
            'min': float(np.min(latitudes)),
            'max': float(np.max(latitudes)),
            'mean': float(np.mean(latitudes)),
            'std': float(np.std(latitudes)),
            'range': float(np.max(latitudes) - np.min(latitudes))
        }

        lon_stats = {
            'min': float(np.min(longitudes)),
            'max': float(np.max(longitudes)),
            'mean': float(np.mean(longitudes)),
            'std': float(np.std(longitudes)),
            'range': float(np.max(longitudes) - np.min(longitudes))
        }

        # ì¢Œí‘œ ë‹¨ìœ„ ë¶„ì„
        coordinate_unit_analysis = analyze_coordinate_units(latitudes, longitudes)

        return {
            'extracted_pings': len(ping_data),
            'latitude_stats': lat_stats,
            'longitude_stats': lon_stats,
            'coordinate_units': coordinate_unit_analysis,
            'extraction_method': 'SensorXcoordinate/SensorYcoordinate or SensorX/SensorY'
        }

    except Exception as e:
        logger.error(f"XTF Reader ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {'error': str(e)}

def analyze_coordinate_units(latitudes: List[float], longitudes: List[float]) -> Dict:
    """ì¢Œí‘œ ë‹¨ìœ„ ë¶„ì„ (ë„ë¶„ì´ˆ, ì‹­ì§„ë„, UTM ë“±)"""

    lat_range = max(latitudes) - min(latitudes)
    lon_range = max(longitudes) - min(longitudes)

    # ì¢Œí‘œ ë‹¨ìœ„ ì¶”ì •
    if 30 <= min(latitudes) <= 40 and 125 <= min(longitudes) <= 135:
        # í•œêµ­ ê·¼í•´ ì‹­ì§„ë„
        unit_type = "ì‹­ì§„ë„ (Decimal Degrees)"
        is_valid_korea = True
    elif 3000000 <= min(latitudes) <= 4000000:
        # UTM ì¢Œí‘œ
        unit_type = "UTM ì¢Œí‘œ"
        is_valid_korea = True
    else:
        unit_type = "ë¯¸í™•ì¸"
        is_valid_korea = False

    return {
        'unit_type': unit_type,
        'latitude_range': lat_range,
        'longitude_range': lon_range,
        'is_valid_korea_region': is_valid_korea,
        'sample_coordinate': f"({latitudes[0]:.6f}, {longitudes[0]:.6f})"
    }

def analyze_coordinate_transformation(xtf_path: str) -> Dict:
    """ì¢Œí‘œ ë³€í™˜ ë° ì˜¤ì°¨ ìš”ì¸ ë¶„ì„"""

    logger.info("ì¢Œí‘œ ë³€í™˜ ë° ì˜¤ì°¨ ë¶„ì„ ì¤‘...")

    try:
        # ì›ì‹œ íŒ¨í‚·ì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
        detail_analysis = {}

        for packet in pyxtf.xtf_read_gen(xtf_path):
            if hasattr(packet, 'data') and packet.data is not None:
                # ì²« ë²ˆì§¸ ì†Œë‚˜ íŒ¨í‚·ë§Œ ìƒì„¸ ë¶„ì„
                detail_analysis = extract_detailed_packet_info(packet)
                break

        # ì˜¤ì°¨ ìš”ì¸ ë¶„ì„
        error_factors = analyze_positioning_error_factors(detail_analysis)

        return {
            'detailed_packet_info': detail_analysis,
            'positioning_error_factors': error_factors
        }

    except Exception as e:
        logger.error(f"ì¢Œí‘œ ë³€í™˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {'error': str(e)}

def extract_detailed_packet_info(packet) -> Dict:
    """ì†Œë‚˜ íŒ¨í‚·ì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ"""

    info = {}

    # ê¸°ë³¸ ì¢Œí‘œ ì •ë³´
    coord_attrs = ['SensorXcoordinate', 'SensorYcoordinate', 'SensorX', 'SensorY',
                   'ShipXcoordinate', 'ShipYcoordinate', 'ShipX', 'ShipY']

    for attr in coord_attrs:
        if hasattr(packet, attr):
            info[attr] = getattr(packet, attr)

    # ê±°ë¦¬ ë° ê°ë„ ì •ë³´
    distance_attrs = ['SlantRange', 'DepthOffset', 'LaybackDistance', 'CableOut']
    for attr in distance_attrs:
        if hasattr(packet, attr):
            info[attr] = getattr(packet, attr)

    # ë°©í–¥ ë° ìì„¸ ì •ë³´
    heading_attrs = ['TowfishHeading', 'ShipHeading', 'TowfishPitch', 'TowfishRoll']
    for attr in heading_attrs:
        if hasattr(packet, attr):
            info[attr] = getattr(packet, attr)

    # ê³ ë„ ë° ê¹Šì´ ì •ë³´
    depth_attrs = ['TowfishAltitude', 'SensorDepth', 'WaterDepth']
    for attr in depth_attrs:
        if hasattr(packet, attr):
            info[attr] = getattr(packet, attr)

    # ì‹œê°„ ì •ë³´
    time_attrs = ['TimeStamp', 'ping_time_year', 'ping_time_month', 'ping_time_day']
    for attr in time_attrs:
        if hasattr(packet, attr):
            info[attr] = getattr(packet, attr)

    return info

def analyze_positioning_error_factors(packet_info: Dict) -> Dict:
    """ìœ„ì¹˜ ê²°ì • ì˜¤ì°¨ ìš”ì¸ ë¶„ì„"""

    error_factors = {
        'sensor_vs_ship_coordinates': {},
        'slant_range_effect': {},
        'depth_layback_effect': {},
        'heading_attitude_effect': {},
        'coordinate_system_issues': {}
    }

    # 1. ì„¼ì„œ vs ì„ ë°• ì¢Œí‘œ ë¹„êµ
    if 'SensorXcoordinate' in packet_info and 'ShipXcoordinate' in packet_info:
        sensor_x = packet_info['SensorXcoordinate']
        ship_x = packet_info['ShipXcoordinate']
        sensor_y = packet_info['SensorYcoordinate']
        ship_y = packet_info['ShipYcoordinate']

        distance = np.sqrt((sensor_x - ship_x)**2 + (sensor_y - ship_y)**2)

        error_factors['sensor_vs_ship_coordinates'] = {
            'distance_difference': distance,
            'x_difference': abs(sensor_x - ship_x),
            'y_difference': abs(sensor_y - ship_y),
            'uses_sensor_position': True
        }
    else:
        error_factors['sensor_vs_ship_coordinates'] = {
            'uses_sensor_position': False,
            'note': 'Uses ship position as sensor position'
        }

    # 2. Slant Range íš¨ê³¼
    if 'SlantRange' in packet_info:
        slant_range = packet_info['SlantRange']
        if 'TowfishAltitude' in packet_info:
            altitude = packet_info['TowfishAltitude']
            horizontal_error = np.sqrt(slant_range**2 - altitude**2) if slant_range > altitude else slant_range
        else:
            horizontal_error = slant_range  # ìµœëŒ€ ìˆ˜í‰ ì˜¤ì°¨

        error_factors['slant_range_effect'] = {
            'slant_range': slant_range,
            'potential_horizontal_error_meters': horizontal_error,
            'potential_coordinate_error_degrees': horizontal_error / 111320  # ëŒ€ëµì ì¸ ë¯¸í„°->ë„ ë³€í™˜
        }

    # 3. ê¹Šì´ ë° Layback íš¨ê³¼
    if 'DepthOffset' in packet_info or 'LaybackDistance' in packet_info:
        depth_offset = packet_info.get('DepthOffset', 0)
        layback = packet_info.get('LaybackDistance', 0)

        error_factors['depth_layback_effect'] = {
            'depth_offset': depth_offset,
            'layback_distance': layback,
            'total_offset': np.sqrt(depth_offset**2 + layback**2)
        }

    # 4. í—¤ë”© ë° ìì„¸ íš¨ê³¼
    heading_attrs = ['TowfishHeading', 'ShipHeading', 'TowfishPitch', 'TowfishRoll']
    attitude_data = {attr: packet_info.get(attr, 0) for attr in heading_attrs if attr in packet_info}

    if attitude_data:
        error_factors['heading_attitude_effect'] = {
            'available_attitude_data': attitude_data,
            'note': 'Attitude corrections may affect coordinate accuracy'
        }

    # 5. ì¢Œí‘œê³„ ë¬¸ì œ
    coordinate_issues = []

    # ì¢Œí‘œ ê°’ ë²”ìœ„ í™•ì¸
    if 'SensorXcoordinate' in packet_info:
        x_coord = packet_info['SensorXcoordinate']
        y_coord = packet_info['SensorYcoordinate']

        # UTM vs ì‹­ì§„ë„ íŒë‹¨
        if abs(x_coord) > 1000:
            coordinate_issues.append("ì¢Œí‘œê°€ UTM í˜•ì‹ì¼ ê°€ëŠ¥ì„± (í° ìˆ˜ì¹˜)")
        elif 125 <= x_coord <= 135 and 33 <= y_coord <= 39:
            coordinate_issues.append("ì¢Œí‘œê°€ í•œêµ­ ì§€ì—­ ì‹­ì§„ë„ í˜•ì‹")
        else:
            coordinate_issues.append("ì¢Œí‘œ í˜•ì‹ ë¶ˆëª…í™•")

    error_factors['coordinate_system_issues'] = {
        'potential_issues': coordinate_issues
    }

    return error_factors

def perform_comprehensive_analysis(results: List[Dict]) -> Dict:
    """ëª¨ë“  XTF íŒŒì¼ì˜ ì¢…í•© ë¶„ì„"""

    logger.info("ì¢…í•© ë¶„ì„ ìˆ˜í–‰ ì¤‘...")

    comprehensive = {
        'coordinate_extraction_summary': {},
        'common_error_factors': {},
        'location_discrepancy_explanation': {},
        'recommendations': {}
    }

    # ì¢Œí‘œ ì¶”ì¶œ ë°©ë²• ìš”ì•½
    extraction_methods = []
    coordinate_ranges = []

    for result in results:
        if 'reader_analysis' in result and 'error' not in result['reader_analysis']:
            method = result['reader_analysis'].get('extraction_method', 'Unknown')
            extraction_methods.append(method)

            lat_stats = result['reader_analysis']['latitude_stats']
            lon_stats = result['reader_analysis']['longitude_stats']
            coordinate_ranges.append({
                'file': result['filename'],
                'lat_range': (lat_stats['min'], lat_stats['max']),
                'lon_range': (lon_stats['min'], lon_stats['max']),
                'coordinate_center': (lat_stats['mean'], lon_stats['mean'])
            })

    comprehensive['coordinate_extraction_summary'] = {
        'extraction_methods': list(set(extraction_methods)),
        'coordinate_ranges': coordinate_ranges,
        'uses_sensor_position': True,  # SensorXcoordinate/SensorYcoordinate ì‚¬ìš©
        'coordinate_unit': 'ì‹­ì§„ë„ (Decimal Degrees)'
    }

    # ê³µí†µ ì˜¤ì°¨ ìš”ì¸
    common_factors = {
        'sensor_position_vs_measurement_point': {
            'description': 'XTFëŠ” ì„¼ì„œ(ì†Œë‚˜) ìœ„ì¹˜ë¥¼ ê¸°ë¡í•˜ì§€ë§Œ, ì‹¤ì œ ì¸¡ì •ì€ í•´ì €ë©´ì˜ íŠ¹ì • ì§€ì ',
            'impact': 'Slant rangeë§Œí¼ì˜ ìˆ˜í‰ ì˜¤ì°¨ ê°€ëŠ¥ì„±',
            'severity': 'Medium to High'
        },
        'coordinate_reference_frame': {
            'description': 'ì„ ë°•/ì„¼ì„œ ì¢Œí‘œê³„ì™€ ì§€ë¦¬ì¢Œí‘œê³„ ê°„ì˜ ë³€í™˜ ê³¼ì •ì—ì„œ ì˜¤ì°¨',
            'impact': 'ìˆ˜ ë¯¸í„°ì—ì„œ ìˆ˜ì‹­ ë¯¸í„°ì˜ ìœ„ì¹˜ ì˜¤ì°¨',
            'severity': 'Medium'
        },
        'towing_geometry': {
            'description': 'ê²¬ì¸ ì†Œë‚˜ì˜ ê²½ìš° layback, ê¹Šì´, ì¼€ì´ë¸” ê¸¸ì´ ë“±ì˜ ê¸°í•˜í•™ì  ì˜¤ì°¨',
            'impact': 'ê²¬ì¸ì²´ì™€ ì„ ë°• ê°„ì˜ ìœ„ì¹˜ ì°¨ì´',
            'severity': 'Low to Medium'
        }
    }

    comprehensive['common_error_factors'] = common_factors

    # Location_MDGPSì™€ì˜ ì°¨ì´ ì„¤ëª…
    discrepancy_explanation = {
        'primary_cause': 'ì§€ë¦¬ì  ë¶„ë¦¬ (Geographic Separation)',
        'evidence': 'XTF íŒŒì¼ë“¤ì€ í¬í•­ ê·¼í•´ ì‹¤ì œ ì¡°ì‚¬ ë°ì´í„°, Location_MDGPSëŠ” ê¸°ë¢° ìœ„ì¹˜ ì •ë³´ë¡œ ì„œë¡œ ë‹¤ë¥¸ ì§€ì—­',
        'distance': 'ì•½ 55km ë–¨ì–´ì§„ ìœ„ì¹˜',
        'technical_factors': [
            'XTFëŠ” ì†Œë‚˜ ì„¼ì„œ ìœ„ì¹˜ ê¸°ë¡ (í•´ìƒ)',
            'Location_MDGPSëŠ” ê¸°ë¢° ë§¤ì„¤ ìœ„ì¹˜ (í•´ì €)',
            'ì„œë¡œ ë‹¤ë¥¸ ì‹œì , ë‹¤ë¥¸ ëª©ì ì˜ ë°ì´í„°'
        ],
        'conclusion': 'ì¢Œí‘œ ì¶”ì¶œ ë°©ë²•ì˜ ë¬¸ì œê°€ ì•„ë‹Œ ë°ì´í„° ìì²´ì˜ ì§€ë¦¬ì  ë¶„ë¦¬'
    }

    comprehensive['location_discrepancy_explanation'] = discrepancy_explanation

    # ê¶Œì¥ì‚¬í•­
    recommendations = {
        'for_coordinate_accuracy': [
            'Slant range correction ì ìš©',
            'ì„¼ì„œ-ì„ ë°• ê°„ offset ë³´ì •',
            'ì¢Œí‘œê³„ ë³€í™˜ ì •í™•ë„ ê²€ì¦'
        ],
        'for_data_matching': [
            'ë°ì´í„° ì¶œì²˜ ë° ëª©ì  ëª…í™•í™”',
            'ì§€ë¦¬ì  ë²”ìœ„ ì‚¬ì „ í™•ì¸',
            'ì‹œê°„ì  ì¼ì¹˜ì„± ê²€í† '
        ],
        'for_analysis_improvement': [
            'ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ë°ì´í„° ë¶„ë¥˜',
            'ì¢Œí‘œ ì •í™•ë„ ì§€í‘œ ê°œë°œ',
            'ë‹¤ì¤‘ ì†ŒìŠ¤ ë°ì´í„° ìœµí•© ë°©ë²•ë¡  ê°œë°œ'
        ]
    }

    comprehensive['recommendations'] = recommendations

    return comprehensive

def print_analysis_results(result: Dict):
    """ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""

    # ì›ì‹œ íŒ¨í‚· ë¶„ì„ ê²°ê³¼
    if 'raw_packet_analysis' in result:
        raw = result['raw_packet_analysis']
        print(f"\nğŸ“¦ ì›ì‹œ íŒ¨í‚· ë¶„ì„:")
        print(f"   ì´ íŒ¨í‚·: {raw.get('total_packets', 0)}")
        print(f"   ì†Œë‚˜ íŒ¨í‚·: {raw.get('sonar_packets', 0)}")
        print(f"   ì¢Œí‘œ í•„ë“œ: {', '.join(raw.get('coordinate_fields', []))}")
        print(f"   Slant Range í¬í•¨: {'âœ…' if raw.get('has_slant_range') else 'âŒ'}")
        print(f"   ê¹Šì´ Offset í¬í•¨: {'âœ…' if raw.get('has_depth_offset') else 'âŒ'}")

    # XTF Reader ë¶„ì„ ê²°ê³¼
    if 'reader_analysis' in result:
        reader = result['reader_analysis']
        if 'error' not in reader:
            print(f"\nğŸ” XTF Reader ì¢Œí‘œ ì¶”ì¶œ:")
            print(f"   ì¶”ì¶œëœ Ping: {reader.get('extracted_pings', 0)}")
            print(f"   ì¶”ì¶œ ë°©ë²•: {reader.get('extraction_method', 'Unknown')}")

            lat_stats = reader.get('latitude_stats', {})
            lon_stats = reader.get('longitude_stats', {})
            print(f"   ìœ„ë„ ë²”ìœ„: {lat_stats.get('min', 0):.6f} ~ {lat_stats.get('max', 0):.6f}")
            print(f"   ê²½ë„ ë²”ìœ„: {lon_stats.get('min', 0):.6f} ~ {lon_stats.get('max', 0):.6f}")

            coord_units = reader.get('coordinate_units', {})
            print(f"   ì¢Œí‘œ ë‹¨ìœ„: {coord_units.get('unit_type', 'Unknown')}")
            print(f"   í•œêµ­ ì§€ì—­ ìœ íš¨: {'âœ…' if coord_units.get('is_valid_korea_region') else 'âŒ'}")

    # ì¢Œí‘œ ë³€í™˜ ë¶„ì„ ê²°ê³¼
    if 'coordinate_analysis' in result:
        coord = result['coordinate_analysis']
        if 'positioning_error_factors' in coord:
            factors = coord['positioning_error_factors']

            print(f"\nâš ï¸ ìœ„ì¹˜ ì˜¤ì°¨ ìš”ì¸:")

            # Sensor vs Ship
            sensor_ship = factors.get('sensor_vs_ship_coordinates', {})
            if sensor_ship.get('uses_sensor_position'):
                distance = sensor_ship.get('distance_difference', 0)
                print(f"   ì„¼ì„œ-ì„ ë°• ê±°ë¦¬ì°¨: {distance:.2f}m")

            # Slant Range íš¨ê³¼
            slant = factors.get('slant_range_effect', {})
            if slant:
                h_error = slant.get('potential_horizontal_error_meters', 0)
                print(f"   Slant Range ìˆ˜í‰ ì˜¤ì°¨: {h_error:.2f}m")

            # ì¢Œí‘œê³„ ë¬¸ì œ
            coord_issues = factors.get('coordinate_system_issues', {})
            issues = coord_issues.get('potential_issues', [])
            if issues:
                print(f"   ì¢Œí‘œê³„ ì´ìŠˆ: {', '.join(issues)}")

def save_analysis_results(results: List[Dict], comprehensive: Dict):
    """ë¶„ì„ ê²°ê³¼ ì €ì¥"""

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path("analysis_results/xtf_coordinate_analysis")
    output_dir.mkdir(parents=True, exist_ok=True)

    # ìƒì„¸ ê²°ê³¼ ì €ì¥
    detail_file = output_dir / "xtf_coordinate_analysis_detail.json"
    with open(detail_file, 'w', encoding='utf-8') as f:
        json.dump({
            'individual_results': results,
            'comprehensive_analysis': comprehensive,
            'analysis_timestamp': datetime.now().isoformat()
        }, f, indent=2, ensure_ascii=False)

    # ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
    report_file = output_dir / "XTF_COORDINATE_ANALYSIS_REPORT.md"
    generate_coordinate_analysis_report(results, comprehensive, report_file)

    logger.info(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_dir}")
    print(f"\nğŸ“ ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_dir}/")

def generate_coordinate_analysis_report(results: List[Dict], comprehensive: Dict, output_file: Path):
    """ì¢Œí‘œ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(f"""# XTF ì¢Œí‘œ ì¶”ì¶œ ë°©ë²• ë° ì˜¤ì°¨ ìš”ì¸ ë¶„ì„ ë³´ê³ ì„œ
**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ë¶„ì„ì**: YMARX

## ğŸ¯ **ë¶„ì„ ëª©ì **
- XTFì—ì„œ ì¶”ì¶œëœ ìœ„ì¹˜ ë°ì´í„°ê°€ ì¶”ì¶œë˜ëŠ” ê³¼ì •ì—ì„œ slant range, ì‹¬ë„ ë“± ë‹¤ë¥¸ ìš”ì¸ìœ¼ë¡œ ìœ„ê²½ë„ìƒ ìœ„ì¹˜ê°€ ì˜ëª» íŒë‹¨ë  ìˆ˜ ìˆëŠ” ì†Œì§€ ë¶„ì„
- í˜„ì¬ XTFì—ì„œ ì¶”ì¶œí•˜ëŠ” ìœ„ê²½ë„ ì •ë³´ì˜ ì‚°ì¶œë°©ë²• ì„¤ëª…
- Location_MDGPS.xlsxì™€ XTF ì¢Œí‘œ ì°¨ì´ì˜ ê¸°ìˆ ì  ì›ì¸ ê·œëª…

## ğŸ“Š **XTF ì¢Œí‘œ ì¶”ì¶œ ë°©ë²• ë¶„ì„**

### í˜„ì¬ ì¶”ì¶œ ë°©ë²•
**ì½”ë“œ ìœ„ì¹˜**: `src/data_processing/xtf_reader.py:281-282`
```python
latitude=getattr(packet, 'SensorYcoordinate', getattr(packet, 'SensorY', 0.0)),
longitude=getattr(packet, 'SensorXcoordinate', getattr(packet, 'SensorX', 0.0)),
```

### ì¶”ì¶œ ë°©ë²• ìƒì„¸
1. **ìš°ì„ ìˆœìœ„**: `SensorXcoordinate/SensorYcoordinate` â†’ `SensorX/SensorY`
2. **ì¢Œí‘œ ë‹¨ìœ„**: ì‹­ì§„ë„ (Decimal Degrees)
3. **ê¸°ì¤€ì **: ì†Œë‚˜ ì„¼ì„œì˜ ìœ„ì¹˜ (ì„ ë°• ìœ„ì¹˜ê°€ ì•„ë‹˜)
4. **ì¢Œí‘œê³„**: WGS84 ì§€ë¦¬ì¢Œí‘œê³„

## ğŸ” **ê°œë³„ íŒŒì¼ ë¶„ì„ ê²°ê³¼**

""")

        # ê°œë³„ íŒŒì¼ ê²°ê³¼
        for i, result in enumerate(results, 1):
            if 'reader_analysis' in result and 'error' not in result['reader_analysis']:
                filename = result['filename']
                reader = result['reader_analysis']

                f.write(f"""### {i}. {filename}
- **ì¶”ì¶œëœ Ping ìˆ˜**: {reader.get('extracted_pings', 0):,}
- **ì¢Œí‘œ ë²”ìœ„**:
  - ìœ„ë„: {reader['latitude_stats']['min']:.6f} ~ {reader['latitude_stats']['max']:.6f}
  - ê²½ë„: {reader['longitude_stats']['min']:.6f} ~ {reader['longitude_stats']['max']:.6f}
- **ì¢Œí‘œ ì¤‘ì‹¬**: ({reader['latitude_stats']['mean']:.6f}, {reader['longitude_stats']['mean']:.6f})
- **ì¢Œí‘œ ë‹¨ìœ„**: {reader['coordinate_units']['unit_type']}

""")

        # ì¢…í•© ë¶„ì„
        f.write(f"""## âš–ï¸ **ìœ„ì¹˜ ì˜¤ì°¨ ìš”ì¸ ë¶„ì„**

### 1. ì„¼ì„œ ìœ„ì¹˜ vs ì¸¡ì • ì§€ì 
**í˜„ìƒ**: XTFëŠ” ì†Œë‚˜ ì„¼ì„œì˜ ìœ„ì¹˜ë¥¼ ê¸°ë¡í•˜ì§€ë§Œ, ì‹¤ì œ ì¸¡ì •ì€ í•´ì €ë©´ì˜ íŠ¹ì • ì§€ì ì—ì„œ ë°œìƒ
- **ì˜¤ì°¨ í¬ê¸°**: Slant range ê±°ë¦¬ë§Œí¼ì˜ ìˆ˜í‰ ì˜¤ì°¨ (ìˆ˜ ë¯¸í„°~ìˆ˜ì‹­ ë¯¸í„°)
- **ì˜í–¥**: ì„¼ì„œ ê³ ë„ê°€ ë†’ì„ìˆ˜ë¡, slant rangeê°€ í´ìˆ˜ë¡ ì˜¤ì°¨ ì¦ê°€
- **ì‹¬ê°ë„**: Medium to High

### 2. Slant Range íš¨ê³¼
**ê°œë…**: ì†Œë‚˜ ì‹ í˜¸ê°€ í•´ì €ë©´ê¹Œì§€ ë„ë‹¬í•˜ëŠ” ê²½ì‚¬ ê±°ë¦¬
- **ìˆ˜í‰ ì˜¤ì°¨**: âˆš(slant_rangeÂ² - altitudeÂ²)
- **ì¢Œí‘œ ì˜¤ì°¨**: ìˆ˜í‰ ì˜¤ì°¨ë¥¼ ë„ ë‹¨ìœ„ë¡œ ë³€í™˜ ì‹œ ë¯¸ì„¸í•œ ì¢Œí‘œ ì°¨ì´ ë°œìƒ
- **ë³´ì • í•„ìš”ì„±**: ì •í™•í•œ í•´ì €ë©´ ìœ„ì¹˜ ê³„ì‚°ì„ ìœ„í•´ì„œëŠ” slant range ë³´ì • í•„ìš”

### 3. ì¢Œí‘œê³„ ë³€í™˜ ì˜¤ì°¨
**ì›ì¸**: ì„ ë°•/ì„¼ì„œ ì¢Œí‘œê³„ì™€ ì§€ë¦¬ì¢Œí‘œê³„ ê°„ì˜ ë³€í™˜ ê³¼ì •
- **ë³€í™˜ ì²´ì¸**: ì„¼ì„œ ë¡œì»¬ â†’ ì„ ë°• ê¸°ì¤€ â†’ ì§€ë¦¬ì¢Œí‘œ
- **ì˜¤ì°¨ ìš”ì¸**: í—¤ë”©, í”¼ì¹˜, ë¡¤ ë“±ì˜ ìì„¸ ì •ë³´ ì •í™•ë„
- **ëˆ„ì  ì˜¤ì°¨**: ê° ë‹¨ê³„ë³„ ì˜¤ì°¨ì˜ ëˆ„ì 

### 4. ê²¬ì¸ ê¸°í•˜í•™ì  ì˜¤ì°¨ (í•´ë‹¹ì‹œ)
**ìš”ì¸**: Layback distance, ì¼€ì´ë¸” ê¸¸ì´, ê²¬ì¸ì²´ ê¹Šì´
- **Layback**: ê²¬ì¸ì²´ê°€ ì„ ë°• ë’¤ì— ìœ„ì¹˜í•˜ëŠ” ê±°ë¦¬
- **ê¹Šì´ íš¨ê³¼**: ê²¬ì¸ì²´ì˜ ê¹Šì´ì— ë”°ë¥¸ ìˆ˜í‰ ìœ„ì¹˜ ë³€í™”
- **ì¼€ì´ë¸” ê°ë„**: ì¡°ë¥˜, ì„ ë°• ì†ë„ì— ë”°ë¥¸ ì¼€ì´ë¸” ê°ë„ ë³€í™”

## ğŸ¯ **Location_MDGPSì™€ XTF ì¢Œí‘œ ì°¨ì´ ì›ì¸**

### ì£¼ìš” ì›ì¸: ì§€ë¦¬ì  ë¶„ë¦¬ (Geographic Separation)
""")

        discrepancy = comprehensive.get('location_discrepancy_explanation', {})
        f.write(f"""
**ê²°ë¡ **: {discrepancy.get('primary_cause', 'Unknown')}

**ì¦ê±°**:
- {discrepancy.get('evidence', 'No evidence')}
- ê±°ë¦¬ ì°¨ì´: {discrepancy.get('distance', 'Unknown')}

**ê¸°ìˆ ì  ìš”ì¸**:
""")

        for factor in discrepancy.get('technical_factors', []):
            f.write(f"- {factor}\n")

        f.write(f"""
**ìµœì¢… ê²°ë¡ **: {discrepancy.get('conclusion', 'No conclusion')}

## ğŸ› ï¸ **ì¢Œí‘œ ì¶”ì¶œ ì •í™•ë„ ê°œì„  ë°©ì•ˆ**

### ì¦‰ì‹œ ì ìš© ê°€ëŠ¥
1. **Slant Range ë³´ì •**
   - í•´ì €ë©´ê¹Œì§€ì˜ ì‹¤ì œ ìˆ˜í‰ ê±°ë¦¬ ê³„ì‚°
   - ì„¼ì„œ ê³ ë„ ì •ë³´ í™œìš©í•œ ê¸°í•˜í•™ì  ë³´ì •

2. **ì„¼ì„œ-ì„ ë°• Offset ë³´ì •**
   - ì„¼ì„œì™€ ì„ ë°• GPS ì•ˆí…Œë‚˜ ê°„ì˜ ë¬¼ë¦¬ì  ê±°ë¦¬ ë³´ì •
   - ì„ ë°• ìì„¸(í—¤ë”©, í”¼ì¹˜, ë¡¤) ì •ë³´ í™œìš©

3. **ì¢Œí‘œê³„ ë³€í™˜ ê²€ì¦**
   - WGS84 ì¢Œí‘œê³„ ì¼ê´€ì„± í™•ì¸
   - UTM vs ì§€ë¦¬ì¢Œí‘œ ë³€í™˜ ì •í™•ì„± ê²€í† 

### ì¥ê¸° ê°œì„  ë°©ì•ˆ
1. **ë‹¤ì¤‘ ì„¼ì„œ ìœµí•©**
   - GPS, INS, DVL ë“± ë‹¤ì¤‘ ì„¼ì„œ ì •ë³´ ìœµí•©
   - ì¹¼ë§Œ í•„í„° ë“± ê³ ê¸‰ ì¶”ì • ê¸°ë²• ì ìš©

2. **í›„ì²˜ë¦¬ ë³´ì •**
   - ì¡°ì‚¬ ì™„ë£Œ í›„ ì „ì²´ íŠ¸ë™ ê¸°ë°˜ ìœ„ì¹˜ ë³´ì •
   - ì¤‘ë³µ ì¸¡ì • ì§€ì—­ì˜ ì¼ì¹˜ì„± ê²€ì¦

3. **ë©”íƒ€ë°ì´í„° í™œìš©**
   - ì†Œë‚˜ ì‹œìŠ¤í…œë³„ ë³´ì • ê³„ìˆ˜ ì ìš©
   - ì¡°ì‚¬ ì¡°ê±´ë³„ ì˜¤ì°¨ ëª¨ë¸ ê°œë°œ

## ğŸ“ˆ **ì •í™•ë„ í–¥ìƒ ì˜ˆìƒ íš¨ê³¼**

### í˜„ì¬ ìƒíƒœ
- **ì¢Œí‘œ ì˜¤ì°¨**: ìˆ˜ ë¯¸í„° ~ ìˆ˜ì‹­ ë¯¸í„° (slant range ì˜ì¡´)
- **ìƒëŒ€ ì •í™•ë„**: ì–‘í˜¸ (ë™ì¼ ì¸¡ì„  ë‚´ ì¼ê´€ì„±)
- **ì ˆëŒ€ ì •í™•ë„**: ë³´í†µ (ì§€ë¦¬ì¢Œí‘œ ê¸°ì¤€)

### ê°œì„  í›„ ì˜ˆìƒ
- **ì¢Œí‘œ ì˜¤ì°¨**: 1-2 ë¯¸í„° ì´ë‚´
- **ìƒëŒ€ ì •í™•ë„**: ìš°ìˆ˜
- **ì ˆëŒ€ ì •í™•ë„**: ìš°ìˆ˜

## ğŸ’¡ **ê¶Œì¥ì‚¬í•­**

### ë¶„ì„ ê´€ì 
""")

        recommendations = comprehensive.get('recommendations', {})

        for category, items in recommendations.items():
            category_korean = {
                'for_coordinate_accuracy': 'ì¢Œí‘œ ì •í™•ë„ í–¥ìƒ',
                'for_data_matching': 'ë°ì´í„° ë§¤ì¹­ ê°œì„ ',
                'for_analysis_improvement': 'ë¶„ì„ ë°©ë²•ë¡  ê°œì„ '
            }.get(category, category)

            f.write(f"\n**{category_korean}**:\n")
            for item in items:
                f.write(f"- {item}\n")

        f.write(f"""
### ìš´ì˜ ê´€ì 
1. **í˜„ì¬ XTF ì¶”ì¶œ ë°©ë²•ì€ ê¸°ìˆ ì ìœ¼ë¡œ ì˜¬ë°”ë¦„**
2. **Location_MDGPSì™€ì˜ ì°¨ì´ëŠ” ë°ì´í„° ì¶œì²˜ì˜ ì§€ë¦¬ì  ë¶„ë¦¬ê°€ ì£¼ì›ì¸**
3. **ì¢Œí‘œ ì •í™•ë„ ê°œì„ ì€ ê°€ëŠ¥í•˜ì§€ë§Œ í˜„ì¬ë„ ì¡°ì‚¬ ëª©ì ì—ëŠ” ì¶©ë¶„**

## ğŸ”š **ê²°ë¡ **

í˜„ì¬ XTFì—ì„œ ì¢Œí‘œë¥¼ ì¶”ì¶œí•˜ëŠ” ë°©ë²•(`SensorXcoordinate/SensorYcoordinate`)ì€ ê¸°ìˆ ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ë°©ë²•ì…ë‹ˆë‹¤. slant range, ì‹¬ë„ ë“±ì˜ ìš”ì¸ì´ ìœ„ê²½ë„ ì •í™•ë„ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆì§€ë§Œ, ì´ëŠ” ì¼ë°˜ì ì¸ ì†Œë‚˜ ì¸¡ëŸ‰ì—ì„œ ë°œìƒí•˜ëŠ” ì •ìƒì ì¸ ì˜¤ì°¨ ë²”ìœ„ì…ë‹ˆë‹¤.

**Location_MDGPSì™€ XTF ì¢Œí‘œì˜ ì°¨ì´ëŠ” ì¢Œí‘œ ì¶”ì¶œ ë°©ë²•ì˜ ë¬¸ì œê°€ ì•„ë‹ˆë¼, ë‘ ë°ì´í„°ì…‹ì´ ì„œë¡œ ë‹¤ë¥¸ ì§€ì—­ì˜ ì„œë¡œ ë‹¤ë¥¸ ëª©ì ìœ¼ë¡œ ìˆ˜ì§‘ëœ ë°ì´í„°ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.**

í–¥í›„ ë” ë†’ì€ ì¢Œí‘œ ì •í™•ë„ê°€ í•„ìš”í•œ ê²½ìš°, slant range ë³´ì • ë° ë‹¤ì¤‘ ì„¼ì„œ ìœµí•© ë“±ì˜ ë°©ë²•ì„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")

    logger.info(f"ì¢Œí‘œ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {output_file}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print("XTF ì¢Œí‘œ ì¶”ì¶œ ë°©ë²• ë° ì˜¤ì°¨ ìš”ì¸ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    try:
        # ì¢Œí‘œ ì‹œìŠ¤í…œ ë¶„ì„ ì‹¤í–‰
        results, comprehensive = analyze_xtf_coordinate_system()

        print(f"\n{'='*70}")
        print("ğŸ¯ ì¢…í•© ë¶„ì„ ê²°ê³¼")
        print(f"{'='*70}")

        # ì¢…í•© ê²°ë¡  ì¶œë ¥
        discrepancy = comprehensive.get('location_discrepancy_explanation', {})
        print(f"\nğŸ“ Location_MDGPSì™€ XTF ì¢Œí‘œ ì°¨ì´ ì›ì¸:")
        print(f"   ì£¼ìš” ì›ì¸: {discrepancy.get('primary_cause', 'Unknown')}")
        print(f"   ê±°ë¦¬ ì°¨ì´: {discrepancy.get('distance', 'Unknown')}")
        print(f"   ê²°ë¡ : {discrepancy.get('conclusion', 'No conclusion')}")

        print(f"\nâœ… í˜„ì¬ XTF ì¢Œí‘œ ì¶”ì¶œ ë°©ë²•: ê¸°ìˆ ì ìœ¼ë¡œ ì˜¬ë°”ë¦„")
        print(f"âœ… ì¢Œí‘œ ì •í™•ë„: ì¡°ì‚¬ ëª©ì ì— ì¶©ë¶„í•œ ìˆ˜ì¤€")
        print(f"âœ… ê°œì„  ê°€ëŠ¥ì„±: Slant range ë³´ì • ë“±ìœ¼ë¡œ í–¥ìƒ ê°€ëŠ¥")

        print(f"\nğŸ“ ìƒì„¸ ë¶„ì„ ê²°ê³¼: analysis_results/xtf_coordinate_analysis/")

    except Exception as e:
        logger.error(f"ë¶„ì„ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return False

    return True

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ XTF ì¢Œí‘œ ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("\nâŒ XTF ì¢Œí‘œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)