#!/usr/bin/env python3
"""
Image Comparison Analysis
=========================
PH_annotation.bmpì™€ XTF ì´ë¯¸ì§€ë¥¼ ë¹„êµí•˜ì—¬ ë™ì¼í•œ ê¸°ë¢° ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ”ì§€ ë¶„ì„
180ë„ íšŒì „, ì¢Œìš° ë°˜ì „ í¬í•¨í•˜ì—¬ í˜•ìƒ ìœ ì‚¬ë„ ê²€ì¦

Author: YMARX
Date: 2025-09-22
"""

import sys
import logging
from pathlib import Path
import numpy as np
import cv2
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from datetime import datetime
import json
from skimage import measure
from scipy import ndimage
from sklearn.metrics import mean_squared_error

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_images():
    """ë‘ ì´ë¯¸ì§€ íŒŒì¼ ë¡œë“œ"""
    logger.info("Loading images for comparison")

    # Image file paths
    annotation_path = Path("datasets/PH_annotation.bmp")
    xtf_image_path = Path("datasets/Pohang_Eardo_1_Edgetech4205_800_050_20241012110900_001_04/original/Pohang_Eardo_1_Edgetech4205_800_050_20241012110900_001_04_IMG_00.BMP")

    images = {}

    # Load annotation image
    if annotation_path.exists():
        try:
            annotation_img = cv2.imread(str(annotation_path))
            if annotation_img is not None:
                # Convert BGR to RGB for matplotlib
                annotation_img = cv2.cvtColor(annotation_img, cv2.COLOR_BGR2RGB)
                images['annotation'] = {
                    'image': annotation_img,
                    'path': str(annotation_path),
                    'shape': annotation_img.shape,
                    'size_mb': annotation_path.stat().st_size / (1024*1024)
                }
                logger.info(f"Loaded PH_annotation.bmp: {annotation_img.shape}, {images['annotation']['size_mb']:.1f}MB")
            else:
                logger.error("Failed to load PH_annotation.bmp")
        except Exception as e:
            logger.error(f"Error loading PH_annotation.bmp: {e}")
    else:
        logger.error(f"PH_annotation.bmp not found at {annotation_path}")

    # Load XTF image
    if xtf_image_path.exists():
        try:
            xtf_img = cv2.imread(str(xtf_image_path))
            if xtf_img is not None:
                # Convert BGR to RGB for matplotlib
                xtf_img = cv2.cvtColor(xtf_img, cv2.COLOR_BGR2RGB)
                images['xtf'] = {
                    'image': xtf_img,
                    'path': str(xtf_image_path),
                    'shape': xtf_img.shape,
                    'size_mb': xtf_image_path.stat().st_size / (1024*1024)
                }
                logger.info(f"Loaded XTF image: {xtf_img.shape}, {images['xtf']['size_mb']:.1f}MB")
            else:
                logger.error("Failed to load XTF image")
        except Exception as e:
            logger.error(f"Error loading XTF image: {e}")
    else:
        logger.error(f"XTF image not found at {xtf_image_path}")

    return images


def apply_transformations(image):
    """ì´ë¯¸ì§€ì— ë‹¤ì–‘í•œ ë³€í™˜ ì ìš©"""
    transformations = {}

    # Original
    transformations['original'] = image.copy()

    # 180ë„ íšŒì „
    transformations['rotate_180'] = np.rot90(image, 2)

    # ì¢Œìš° ë°˜ì „
    transformations['flip_horizontal'] = np.fliplr(image)

    # ìƒí•˜ ë°˜ì „
    transformations['flip_vertical'] = np.flipud(image)

    # 180ë„ íšŒì „ + ì¢Œìš° ë°˜ì „
    transformations['rotate_flip'] = np.fliplr(np.rot90(image, 2))

    # 90ë„ íšŒì „
    transformations['rotate_90'] = np.rot90(image, 1)

    # 270ë„ íšŒì „
    transformations['rotate_270'] = np.rot90(image, 3)

    return transformations


def convert_to_grayscale(image):
    """ì´ë¯¸ì§€ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜"""
    if len(image.shape) == 3:
        return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    return image


def calculate_similarity_metrics(img1, img2):
    """ë‘ ì´ë¯¸ì§€ ê°„ì˜ ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    # í¬ê¸°ë¥¼ ê°™ê²Œ ë§ì¶”ê¸°
    h1, w1 = img1.shape[:2]
    h2, w2 = img2.shape[:2]

    # ë” ì‘ì€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
    target_h = min(h1, h2)
    target_w = min(w1, w2)

    img1_resized = cv2.resize(img1, (target_w, target_h))
    img2_resized = cv2.resize(img2, (target_w, target_h))

    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    gray1 = convert_to_grayscale(img1_resized)
    gray2 = convert_to_grayscale(img2_resized)

    # ì •ê·œí™”
    gray1 = gray1.astype(np.float32) / 255.0
    gray2 = gray2.astype(np.float32) / 255.0

    # ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ ê³„ì‚°
    metrics = {}

    # 1. Mean Squared Error (ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)
    metrics['mse'] = mean_squared_error(gray1.flatten(), gray2.flatten())

    # 2. Normalized Cross-Correlation (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)
    correlation = cv2.matchTemplate(gray1, gray2, cv2.TM_CCOEFF_NORMED)
    metrics['ncc'] = correlation.max()

    # 3. Structural Similarity Index (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)
    try:
        from skimage.metrics import structural_similarity as ssim
        metrics['ssim'] = ssim(gray1, gray2)
    except ImportError:
        logger.warning("SSIM calculation requires scikit-image")
        metrics['ssim'] = None

    # 4. Histogram correlation (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)
    hist1 = cv2.calcHist([gray1], [0], None, [256], [0, 1])
    hist2 = cv2.calcHist([gray2], [0], None, [256], [0, 1])
    metrics['hist_corr'] = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)

    return metrics


def analyze_shape_features(image):
    """ì´ë¯¸ì§€ì˜ í˜•ìƒ íŠ¹ì§• ë¶„ì„"""
    gray = convert_to_grayscale(image)

    # ì´ì§„í™”
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # ìœ¤ê³½ì„  ì°¾ê¸°
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    features = {
        'num_contours': len(contours),
        'total_area': 0,
        'perimeter': 0,
        'aspect_ratios': [],
        'solidity': []
    }

    if contours:
        # ê°€ì¥ í° ìœ¤ê³½ì„ ë“¤ ë¶„ì„
        contours_sorted = sorted(contours, key=cv2.contourArea, reverse=True)

        for i, contour in enumerate(contours_sorted[:5]):  # ìƒìœ„ 5ê°œ ìœ¤ê³½ì„ 
            area = cv2.contourArea(contour)
            perimeter = cv2.arcLength(contour, True)

            features['total_area'] += area
            features['perimeter'] += perimeter

            # ê²½ê³„ ìƒì
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = w / h if h > 0 else 0
            features['aspect_ratios'].append(aspect_ratio)

            # ë³¼ë¡ ê»ì§ˆ
            hull = cv2.convexHull(contour)
            hull_area = cv2.contourArea(hull)
            solidity = area / hull_area if hull_area > 0 else 0
            features['solidity'].append(solidity)

    return features


def perform_comprehensive_comparison(images):
    """ì¢…í•©ì ì¸ ì´ë¯¸ì§€ ë¹„êµ ë¶„ì„"""
    logger.info("Performing comprehensive image comparison")

    if 'annotation' not in images or 'xtf' not in images:
        logger.error("Both images are required for comparison")
        return None

    annotation_img = images['annotation']['image']
    xtf_img = images['xtf']['image']

    # ë³€í™˜ ì ìš©
    logger.info("Applying transformations to XTF image")
    xtf_transformations = apply_transformations(xtf_img)

    # ê° ë³€í™˜ì— ëŒ€í•´ ìœ ì‚¬ë„ ê³„ì‚°
    comparison_results = {}

    for transform_name, transformed_img in xtf_transformations.items():
        logger.info(f"Comparing with transformation: {transform_name}")

        # ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ ê³„ì‚°
        similarity_metrics = calculate_similarity_metrics(annotation_img, transformed_img)

        # í˜•ìƒ íŠ¹ì§• ë¶„ì„
        annotation_features = analyze_shape_features(annotation_img)
        transformed_features = analyze_shape_features(transformed_img)

        comparison_results[transform_name] = {
            'similarity_metrics': similarity_metrics,
            'annotation_features': annotation_features,
            'transformed_features': transformed_features,
            'transformed_image': transformed_img
        }

    return comparison_results


def create_comparison_visualization(images, comparison_results):
    """ë¹„êµ ê²°ê³¼ ì‹œê°í™”"""
    logger.info("Creating comparison visualization")

    if not comparison_results:
        logger.error("No comparison results to visualize")
        return

    # ì „ì²´ ë¹„êµ ì‹œê°í™”
    fig, axes = plt.subplots(3, 3, figsize=(20, 15))
    axes = axes.flatten()

    # ì›ë³¸ ì´ë¯¸ì§€ë“¤
    annotation_img = images['annotation']['image']
    xtf_img = images['xtf']['image']

    # ì›ë³¸ annotation ì´ë¯¸ì§€
    axes[0].imshow(annotation_img)
    axes[0].set_title('PH_annotation.bmp\n(Reference)', fontsize=12, fontweight='bold')
    axes[0].axis('off')

    # ì›ë³¸ XTF ì´ë¯¸ì§€
    axes[1].imshow(xtf_img)
    axes[1].set_title('XTF Original', fontsize=12)
    axes[1].axis('off')

    # ê° ë³€í™˜ ê²°ê³¼
    transform_names = ['rotate_180', 'flip_horizontal', 'flip_vertical', 'rotate_flip', 'rotate_90', 'rotate_270']

    for i, transform_name in enumerate(transform_names):
        if transform_name in comparison_results:
            ax_idx = i + 2
            if ax_idx < len(axes):
                transformed_img = comparison_results[transform_name]['transformed_image']
                metrics = comparison_results[transform_name]['similarity_metrics']

                axes[ax_idx].imshow(transformed_img)

                # ìœ ì‚¬ë„ ì •ë³´ í‘œì‹œ
                title = f'{transform_name.replace("_", " ").title()}\n'
                if metrics['ssim'] is not None:
                    title += f'SSIM: {metrics["ssim"]:.3f}\n'
                title += f'NCC: {metrics["ncc"]:.3f}'

                axes[ax_idx].set_title(title, fontsize=10)
                axes[ax_idx].axis('off')

    # ë‚¨ì€ ì¶• ìˆ¨ê¸°ê¸°
    for i in range(len(transform_names) + 2, len(axes)):
        axes[i].axis('off')

    plt.tight_layout()
    output_file = Path("analysis_results/image_comparison/comparison_visualization.png")
    output_file.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    plt.close()
    logger.info(f"Saved comparison visualization to: {output_file}")


def create_detailed_similarity_plot(comparison_results):
    """ìƒì„¸ ìœ ì‚¬ë„ ë¶„ì„ í”Œë¡¯"""
    logger.info("Creating detailed similarity analysis plot")

    # ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    transforms = list(comparison_results.keys())
    mse_values = [comparison_results[t]['similarity_metrics']['mse'] for t in transforms]
    ncc_values = [comparison_results[t]['similarity_metrics']['ncc'] for t in transforms]
    hist_corr_values = [comparison_results[t]['similarity_metrics']['hist_corr'] for t in transforms]
    ssim_values = [comparison_results[t]['similarity_metrics']['ssim'] for t in transforms if comparison_results[t]['similarity_metrics']['ssim'] is not None]

    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))

    # MSE (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
    bars1 = ax1.bar(transforms, mse_values, color='lightcoral')
    ax1.set_title('Mean Squared Error (Lower = More Similar)')
    ax1.set_ylabel('MSE')
    ax1.tick_params(axis='x', rotation=45)

    # ìµœì†Ÿê°’ í‘œì‹œ
    min_mse_idx = np.argmin(mse_values)
    bars1[min_mse_idx].set_color('darkred')
    ax1.text(min_mse_idx, mse_values[min_mse_idx], f'{mse_values[min_mse_idx]:.4f}',
             ha='center', va='bottom', fontweight='bold')

    # NCC (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
    bars2 = ax2.bar(transforms, ncc_values, color='lightblue')
    ax2.set_title('Normalized Cross-Correlation (Higher = More Similar)')
    ax2.set_ylabel('NCC')
    ax2.tick_params(axis='x', rotation=45)

    # ìµœëŒ“ê°’ í‘œì‹œ
    max_ncc_idx = np.argmax(ncc_values)
    bars2[max_ncc_idx].set_color('darkblue')
    ax2.text(max_ncc_idx, ncc_values[max_ncc_idx], f'{ncc_values[max_ncc_idx]:.4f}',
             ha='center', va='bottom', fontweight='bold')

    # Histogram Correlation (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
    bars3 = ax3.bar(transforms, hist_corr_values, color='lightgreen')
    ax3.set_title('Histogram Correlation (Higher = More Similar)')
    ax3.set_ylabel('Histogram Correlation')
    ax3.tick_params(axis='x', rotation=45)

    # ìµœëŒ“ê°’ í‘œì‹œ
    max_hist_idx = np.argmax(hist_corr_values)
    bars3[max_hist_idx].set_color('darkgreen')
    ax3.text(max_hist_idx, hist_corr_values[max_hist_idx], f'{hist_corr_values[max_hist_idx]:.4f}',
             ha='center', va='bottom', fontweight='bold')

    # SSIM (ìˆëŠ” ê²½ìš°)
    if ssim_values and len(ssim_values) == len(transforms):
        bars4 = ax4.bar(transforms, ssim_values, color='lightyellow')
        ax4.set_title('Structural Similarity Index (Higher = More Similar)')
        ax4.set_ylabel('SSIM')
        ax4.tick_params(axis='x', rotation=45)

        # ìµœëŒ“ê°’ í‘œì‹œ
        max_ssim_idx = np.argmax(ssim_values)
        bars4[max_ssim_idx].set_color('orange')
        ax4.text(max_ssim_idx, ssim_values[max_ssim_idx], f'{ssim_values[max_ssim_idx]:.4f}',
                 ha='center', va='bottom', fontweight='bold')
    else:
        ax4.text(0.5, 0.5, 'SSIM not available', ha='center', va='center', transform=ax4.transAxes)
        ax4.axis('off')

    plt.tight_layout()
    output_file = Path("analysis_results/image_comparison/similarity_metrics.png")
    output_file.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    plt.close()
    logger.info(f"Saved similarity metrics plot to: {output_file}")


def generate_comparison_report(images, comparison_results):
    """ì´ë¯¸ì§€ ë¹„êµ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
    logger.info("Generating comparison analysis report")

    report_lines = []
    report_lines.append("# ì´ë¯¸ì§€ ë¹„êµ ë¶„ì„ ë³´ê³ ì„œ")
    report_lines.append(f"**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append(f"**ë¶„ì„ì**: YMARX")
    report_lines.append("")

    # ê°œìš”
    report_lines.append("## ğŸ¯ **ë¶„ì„ ëª©ì **")
    report_lines.append("PH_annotation.bmpì™€ XTF ì´ë¯¸ì§€ê°€ ê°™ì€ ê¸°ë¢° ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ”ì§€ í™•ì¸")
    report_lines.append("180ë„ íšŒì „, ì¢Œìš° ë°˜ì „ ë“± ë‹¤ì–‘í•œ ë³€í™˜ì„ ì ìš©í•˜ì—¬ í˜•ìƒ ìœ ì‚¬ì„± ê²€ì¦")
    report_lines.append("")

    # ì´ë¯¸ì§€ ì •ë³´
    report_lines.append("## ğŸ“ **ë¶„ì„ ëŒ€ìƒ ì´ë¯¸ì§€**")
    report_lines.append("")

    for img_type, img_data in images.items():
        report_lines.append(f"### {img_type.title()} Image")
        report_lines.append(f"- **íŒŒì¼ ê²½ë¡œ**: `{img_data['path']}`")
        report_lines.append(f"- **ì´ë¯¸ì§€ í¬ê¸°**: {img_data['shape']}")
        report_lines.append(f"- **íŒŒì¼ í¬ê¸°**: {img_data['size_mb']:.1f} MB")
        report_lines.append("")

    # ë³€í™˜ ë° ìœ ì‚¬ë„ ë¶„ì„
    report_lines.append("## ğŸ”„ **ë³€í™˜ë³„ ìœ ì‚¬ë„ ë¶„ì„**")
    report_lines.append("")

    # ìµœê³  ìœ ì‚¬ë„ ì°¾ê¸°
    best_transform = None
    best_score = -1
    best_metric = None

    similarity_summary = []

    for transform_name, result in comparison_results.items():
        metrics = result['similarity_metrics']

        # ì¢…í•© ì ìˆ˜ ê³„ì‚° (NCC + Hist_Corr + (1-MSE) + SSIM)
        score = metrics['ncc'] + metrics['hist_corr'] + (1 - metrics['mse'])
        if metrics['ssim'] is not None:
            score += metrics['ssim']

        if score > best_score:
            best_score = score
            best_transform = transform_name
            best_metric = metrics

        similarity_summary.append({
            'transform': transform_name,
            'score': score,
            'metrics': metrics
        })

    # ìœ ì‚¬ë„ ê²°ê³¼ í…Œì´ë¸”
    report_lines.append("| ë³€í™˜ íƒ€ì… | MSE â†“ | NCC â†‘ | Hist Corr â†‘ | SSIM â†‘ | ì¢…í•© ì ìˆ˜ |")
    report_lines.append("|-----------|-------|-------|-------------|---------|----------|")

    for item in sorted(similarity_summary, key=lambda x: x['score'], reverse=True):
        transform = item['transform']
        metrics = item['metrics']
        score = item['score']

        ssim_str = f"{metrics['ssim']:.3f}" if metrics['ssim'] is not None else "N/A"

        # ìµœê³  ì ìˆ˜ í‘œì‹œ
        marker = "ğŸ¥‡" if transform == best_transform else ""

        report_lines.append(f"| {marker} {transform.replace('_', ' ').title()} | {metrics['mse']:.4f} | {metrics['ncc']:.3f} | {metrics['hist_corr']:.3f} | {ssim_str} | {score:.3f} |")

    report_lines.append("")

    # ë¶„ì„ ê²°ê³¼
    report_lines.append("## ğŸ“Š **ë¶„ì„ ê²°ê³¼**")
    report_lines.append("")

    if best_transform and best_metric:
        report_lines.append(f"### âœ… **ìµœì  ë³€í™˜**: `{best_transform.replace('_', ' ').title()}`")
        report_lines.append("")
        report_lines.append("**ìœ ì‚¬ë„ ì§€í‘œ**:")
        report_lines.append(f"- MSE (Mean Squared Error): {best_metric['mse']:.4f} (ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)")
        report_lines.append(f"- NCC (Normalized Cross-Correlation): {best_metric['ncc']:.3f} (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)")
        report_lines.append(f"- Histogram Correlation: {best_metric['hist_corr']:.3f} (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)")
        if best_metric['ssim'] is not None:
            report_lines.append(f"- SSIM (Structural Similarity): {best_metric['ssim']:.3f} (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)")
        report_lines.append(f"- **ì¢…í•© ì ìˆ˜**: {best_score:.3f}")
        report_lines.append("")

        # í˜•ìƒ íŠ¹ì§• ë¹„êµ
        if best_transform in comparison_results:
            ann_features = comparison_results[best_transform]['annotation_features']
            trans_features = comparison_results[best_transform]['transformed_features']

            report_lines.append("**í˜•ìƒ íŠ¹ì§• ë¹„êµ**:")
            report_lines.append(f"- ìœ¤ê³½ì„  ê°œìˆ˜: Annotation({ann_features['num_contours']}) vs Transformed({trans_features['num_contours']})")
            report_lines.append(f"- ì´ ë©´ì : Annotation({ann_features['total_area']:.0f}) vs Transformed({trans_features['total_area']:.0f})")

            if ann_features['aspect_ratios'] and trans_features['aspect_ratios']:
                ann_aspect = np.mean(ann_features['aspect_ratios'])
                trans_aspect = np.mean(trans_features['aspect_ratios'])
                report_lines.append(f"- í‰ê·  ì¢…íš¡ë¹„: Annotation({ann_aspect:.2f}) vs Transformed({trans_aspect:.2f})")

    report_lines.append("")

    # ê²°ë¡ 
    report_lines.append("## ğŸ¯ **ê²°ë¡ **")
    report_lines.append("")

    # ìœ ì‚¬ë„ ì„ê³„ê°’ ì„¤ì •
    similarity_threshold = {
        'ncc': 0.3,      # NCC > 0.3
        'hist_corr': 0.5, # Histogram correlation > 0.5
        'mse': 0.1,      # MSE < 0.1
        'ssim': 0.5      # SSIM > 0.5 (if available)
    }

    if best_metric:
        is_similar = (
            best_metric['ncc'] > similarity_threshold['ncc'] and
            best_metric['hist_corr'] > similarity_threshold['hist_corr'] and
            best_metric['mse'] < similarity_threshold['mse']
        )

        if best_metric['ssim'] is not None:
            is_similar = is_similar and best_metric['ssim'] > similarity_threshold['ssim']

        if is_similar:
            report_lines.append("### âœ… **ë‘ ì´ë¯¸ì§€ëŠ” ê°™ì€ ê¸°ë¢° ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤**")
            report_lines.append(f"**ìµœì  ë³€í™˜**: `{best_transform.replace('_', ' ').title()}`")
            report_lines.append("")
            report_lines.append("**ê·¼ê±°**:")
            report_lines.append(f"- ëª¨ë“  ìœ ì‚¬ë„ ì§€í‘œê°€ ì„ê³„ê°’ì„ ì¶©ì¡±")
            report_lines.append(f"- íŠ¹íˆ {best_transform.replace('_', ' ')} ë³€í™˜ ì ìš© ì‹œ ë†’ì€ ìœ ì‚¬ì„± í™•ì¸")
            report_lines.append("")
            report_lines.append("**ì˜ë¯¸**:")
            report_lines.append("- ì´ì „ì˜ \"180ë„ íšŒì „/ì¢Œìš° ë°˜ì „ìœ¼ë¡œ ë¬¸ì œ í•´ê²°\" ì£¼ì¥ì´ **ì‹¤ì œë¡œ ì •í™•í•¨**")
            report_lines.append("- XTF ì´ë¯¸ì§€ì™€ annotation ì´ë¯¸ì§€ê°€ ì‹¤ì œë¡œ ë™ì¼í•œ ì˜ì—­ì„ ë‚˜íƒ€ëƒ„")
            report_lines.append("- ì¢Œí‘œ ë§¤í•‘ ì‹œ í•´ë‹¹ ë³€í™˜ì„ ì ìš©í•˜ë©´ ì •í™•í•œ ë§¤í•‘ ê°€ëŠ¥")
        else:
            report_lines.append("### âŒ **ë‘ ì´ë¯¸ì§€ëŠ” ë‹¤ë¥¸ ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤**")
            report_lines.append("")
            report_lines.append("**ê·¼ê±°**:")
            report_lines.append(f"- ìµœê³  ìœ ì‚¬ë„ì—ì„œë„ ì„ê³„ê°’ ë¯¸ë‹¬")
            report_lines.append(f"- ìµœì  ë³€í™˜: {best_transform.replace('_', ' ').title()}")
            report_lines.append(f"- ìµœê³  NCC: {best_metric['ncc']:.3f} (ì„ê³„ê°’: {similarity_threshold['ncc']})")
            report_lines.append(f"- ìµœê³  Hist Corr: {best_metric['hist_corr']:.3f} (ì„ê³„ê°’: {similarity_threshold['hist_corr']})")
            report_lines.append("")
            report_lines.append("**ì˜ë¯¸**:")
            report_lines.append("- XTF ì´ë¯¸ì§€ì™€ annotation ì´ë¯¸ì§€ê°€ ì„œë¡œ ë‹¤ë¥¸ ì˜ì—­")
            report_lines.append("- ì´ì „ ì¢Œí‘œ ë¶„ì„ê³¼ ì¼ì¹˜: ì§€ë¦¬ì ìœ¼ë¡œ ë‹¤ë¥¸ ì§€ì—­ì˜ ë°ì´í„°")
            report_lines.append("- ì¢Œí‘œ ë³€í™˜ë§Œìœ¼ë¡œëŠ” í•´ê²°í•  ìˆ˜ ì—†ëŠ” ê·¼ë³¸ì ì¸ ë°ì´í„° ë¶ˆì¼ì¹˜")

    # ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­
    report_lines.append("")
    report_lines.append("## ğŸ› ï¸ **ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­**")
    report_lines.append("")
    report_lines.append("**ì ìš©ëœ ë³€í™˜**:")
    report_lines.append("- Original (ë³€í™˜ ì—†ìŒ)")
    report_lines.append("- 180ë„ íšŒì „")
    report_lines.append("- ì¢Œìš° ë°˜ì „")
    report_lines.append("- ìƒí•˜ ë°˜ì „")
    report_lines.append("- 180ë„ íšŒì „ + ì¢Œìš° ë°˜ì „")
    report_lines.append("- 90ë„ íšŒì „")
    report_lines.append("- 270ë„ íšŒì „")
    report_lines.append("")
    report_lines.append("**ìœ ì‚¬ë„ ì¸¡ì • ë°©ë²•**:")
    report_lines.append("- MSE (Mean Squared Error): í”½ì…€ ê°„ ì°¨ì´ì˜ ì œê³± í‰ê· ")
    report_lines.append("- NCC (Normalized Cross-Correlation): ì •ê·œí™”ëœ êµì°¨ ìƒê´€ê³„ìˆ˜")
    report_lines.append("- Histogram Correlation: íˆìŠ¤í† ê·¸ë¨ ê°„ ìƒê´€ê³„ìˆ˜")
    report_lines.append("- SSIM (Structural Similarity Index): êµ¬ì¡°ì  ìœ ì‚¬ì„± ì§€ìˆ˜")

    # ë³´ê³ ì„œ ì €ì¥
    output_file = Path("analysis_results/image_comparison/IMAGE_COMPARISON_REPORT.md")
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("\n".join(report_lines))

    logger.info(f"Saved comparison report to: {output_file}")

    # JSON ë°ì´í„° ì €ì¥
    json_data = {
        'images': images,
        'best_transform': best_transform,
        'best_score': best_score,
        'similarity_summary': similarity_summary,
        'analysis_timestamp': datetime.now().isoformat()
    }

    # numpy arraysëŠ” JSON ì§ë ¬í™”í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì œê±°
    for img_type in json_data['images']:
        json_data['images'][img_type].pop('image', None)

    json_file = Path("analysis_results/image_comparison/comparison_data.json")
    with open(json_file, 'w') as f:
        json.dump(json_data, f, indent=2, default=str)

    logger.info(f"Saved comparison data to: {json_file}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("Starting Image Comparison Analysis")

    try:
        # ì´ë¯¸ì§€ ë¡œë“œ
        images = load_images()

        if len(images) < 2:
            logger.error("Need both annotation and XTF images for comparison")
            return 1

        # ì¢…í•© ë¹„êµ ë¶„ì„
        comparison_results = perform_comprehensive_comparison(images)

        if not comparison_results:
            logger.error("Failed to perform comparison analysis")
            return 1

        # ì‹œê°í™” ìƒì„±
        create_comparison_visualization(images, comparison_results)
        create_detailed_similarity_plot(comparison_results)

        # ë³´ê³ ì„œ ìƒì„±
        generate_comparison_report(images, comparison_results)

        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print("\n" + "="*80)
        print("ì´ë¯¸ì§€ ë¹„êµ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("="*80)

        # ìµœê³  ìœ ì‚¬ë„ ì°¾ê¸°
        best_transform = None
        best_score = -1

        for transform_name, result in comparison_results.items():
            metrics = result['similarity_metrics']
            score = metrics['ncc'] + metrics['hist_corr'] + (1 - metrics['mse'])
            if metrics['ssim'] is not None:
                score += metrics['ssim']

            if score > best_score:
                best_score = score
                best_transform = transform_name

        print(f"ğŸ“ ë¶„ì„ëœ ì´ë¯¸ì§€:")
        print(f"   - PH_annotation.bmp: {images['annotation']['shape']}")
        print(f"   - XTF ì´ë¯¸ì§€: {images['xtf']['shape']}")

        print(f"\nğŸ”„ ìµœì  ë³€í™˜: {best_transform.replace('_', ' ').title()}")
        print(f"ğŸ“Š ì¢…í•© ìœ ì‚¬ë„ ì ìˆ˜: {best_score:.3f}")

        best_metrics = comparison_results[best_transform]['similarity_metrics']
        print(f"\nğŸ“ˆ ìƒì„¸ ìœ ì‚¬ë„ ì§€í‘œ:")
        print(f"   - MSE: {best_metrics['mse']:.4f} (ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)")
        print(f"   - NCC: {best_metrics['ncc']:.3f} (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)")
        print(f"   - Hist Corr: {best_metrics['hist_corr']:.3f} (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)")
        if best_metrics['ssim'] is not None:
            print(f"   - SSIM: {best_metrics['ssim']:.3f} (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)")

        # ìœ ì‚¬ì„± íŒë‹¨
        is_similar = (
            best_metrics['ncc'] > 0.3 and
            best_metrics['hist_corr'] > 0.5 and
            best_metrics['mse'] < 0.1
        )

        if best_metrics['ssim'] is not None:
            is_similar = is_similar and best_metrics['ssim'] > 0.5

        print(f"\nğŸ¯ **ìµœì¢… ê²°ë¡ **:")
        if is_similar:
            print("   âœ… ë‘ ì´ë¯¸ì§€ëŠ” **ë™ì¼í•œ ê¸°ë¢° ìœ„ì¹˜**ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤!")
            print(f"   â†’ {best_transform.replace('_', ' ')} ë³€í™˜ ì ìš© ì‹œ ë†’ì€ ìœ ì‚¬ì„± í™•ì¸")
            print("   â†’ ì´ì „ \"180ë„ íšŒì „/ì¢Œìš° ë°˜ì „ í•´ê²°\" ì£¼ì¥ì´ **ì‹¤ì œë¡œ ì •í™•í•¨**")
            print("   â†’ í•´ë‹¹ ë³€í™˜ì„ ì ìš©í•˜ë©´ ì •í™•í•œ ì¢Œí‘œ ë§¤í•‘ ê°€ëŠ¥")
        else:
            print("   âŒ ë‘ ì´ë¯¸ì§€ëŠ” **ë‹¤ë¥¸ ìœ„ì¹˜**ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤")
            print("   â†’ ì´ì „ ì¢Œí‘œ ë¶„ì„ê³¼ ì¼ì¹˜: ì§€ë¦¬ì ìœ¼ë¡œ ë‹¤ë¥¸ ì§€ì—­ì˜ ë°ì´í„°")
            print("   â†’ ì¢Œí‘œ ë³€í™˜ë§Œìœ¼ë¡œëŠ” í•´ê²°í•  ìˆ˜ ì—†ëŠ” ê·¼ë³¸ì ì¸ ë°ì´í„° ë¶ˆì¼ì¹˜")

        return 0

    except Exception as e:
        logger.error(f"Image comparison analysis failed: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 1


if __name__ == "__main__":
    exit(main())